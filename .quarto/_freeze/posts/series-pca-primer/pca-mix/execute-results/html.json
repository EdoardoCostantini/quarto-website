{
  "hash": "89d3512edaee21df005e88705866e08a",
  "result": {
    "markdown": "---\ndraft: true\ntitle: PCA with metrics, dimensionality reduction through PCA and MCA\nauthor: Edoardo Costantini\ndate: '2022-05-17'\nslug: pca-mix\ncategories: [\"Categorical data\"]\nbibliography: ../../resources/bibshelf.bib\n---\n\n\n# Introduction\n\n**Principal Component Analysis** (PCA) is a technique that finds a low-dimensional representation of a large set of variables contained in an $n \\times p$ data matrix $\\mathbf{X}$ with minimal loss of information.\nWe refer to this low-dimensional representation as the $n \\times r$ matrix $\\mathbf{Z}$, where $r < p$.\nThe columns of $\\mathbf{Z}$ are called principal components (PCs) of $\\mathbf{X}$.\nWe can write the relationship between all the PCs and $\\mathbf{X}$ in matrix notation:\n\\begin{equation} \\label{eq:PCAmatnot}\n    \\mathbf{Z} = \\mathbf{X} \\mathbf{\\Lambda}\n\\end{equation}\nwhere $\\mathbf{\\Lambda}$ is a $p \\times r$ matrix of coefficients, with columns $\\mathbf{\\lambda}_1, \\dots, \\mathbf{\\lambda}_r$.\nPCA can be thought of as the process of projecting the original data from a $p$-dimensional space to a lower $q$-dimensional space.\nThe coefficient vectors $\\mathbf{\\lambda}_1, \\dots, \\mathbf{\\lambda}_r$ define the directions in which we are projecting the $n$ observations of $\\mathbf{x}_1, \\dots, \\mathbf{x}_p$.\nThe projected values are the principal component scores $\\mathbf{Z}$.\n\nThe goal of PCA is to find the values of $\\mathbf{\\Lambda}$ that maximize the variance of the columns of $\\mathbf{Z}$.\nOne way to find the PCA solution for $\\mathbf{\\Lambda}$ is by taking the truncated [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition#Relation_to_eigenvalue_decomposition) (SVD) of $\\mathbf{X}$:\n\n\\begin{equation} \\label{eq:SVD}\n    \\mathbf{X} = \\mathbf{UDV}'\n\\end{equation}\n\nThe PCs scores are given by the $n \\times r$ matrix $\\mathbf{UD}$, and the weights $\\mathbf{\\Lambda}$ are given by the $p \\times r$ matrix $\\mathbf{V}$.\n\n**Multiple Correspondence Analysis** (MCA) is generally regarded as an equivalent tool that applies to discrete data.\nChavent et al. [-@chaventEtAl:2014] have shown how using weights on rows and columns of the input data matrix can define a general PCA framework that includes standard PCA and MCA as special cases.\nThis approach is often referred to as **PCA with metrics**, as metrics are used to introduce the weights.\nIn this post, I want to show how PCA and MCA are related through this framework.\n\n## Generalised Singular Value Decomposition\n\nConsider an $n \\times p$ matrix of input variables $\\mathbf{X}$ with row metric $\\mathbf{N}$ and column metric $\\mathbf{M}$.\nThe Generalized Singular Value Decomposition of $\\mathbf{X}$ can be written as:\n$$\n\\mathbf{X} = \\mathbf{U \\Lambda V}^T\n$$\nwhere:\n\n- $\\mathbf{\\Lambda}$ is the $r \\times r$ diagonal matrix with elements equal to the square root of the non-zero eigenvalues of $\\mathbf{XMX}^T\\mathbf{N}$ and $\\mathbf{X}^T\\mathbf{NXM}$;\n- $\\mathbf{U}$ is the $n \\times r$ matrix of the first $r$ eigenvectors of $\\mathbf{XMX}^T\\mathbf{N}$ such that $\\mathbf{U}^T\\mathbf{MU=I}$\n- $\\mathbf{V}$ is the $p \\times r$ matrix of the first $r$ eigenvectors of $\\mathbf{X}^T\\mathbf{NXM}$ such that $\\mathbf{V}^T\\mathbf{MV=I}$;\n\nThe GSVD of $\\mathbf{X}$ can be obtained by taking \n\n- first taking the standard SVD of the transformed matrix $\\tilde{\\mathbf{X}} = \\mathbf{N}^{1/2}\\mathbf{X}\\mathbf{M}^{1/2}$ which gives:\n$$\n\\tilde{\\mathbf{X}} = \\tilde{\\mathbf{U}}\\tilde{\\mathbf{\\Lambda}}\\tilde{\\mathbf{V}}^T\n$$\n- and then transforming each element back to the original scale\n$$\n\\mathbf{\\Lambda} = \\tilde{\\mathbf{\\Lambda}}\n$$\n$$\n\\mathbf{U} = \\mathbf{N}^{-1/2}\\tilde{\\mathbf{U}}\n$$\n$$\n\\mathbf{V} = \\mathbf{M}^{-1/2}\\tilde{\\mathbf{V}}\n$$\n\n\n## Relationship of GSVD to standard SVD\n\nIt's easy to see how this GSVD differs from the standard formulation of SVD simply by the presence of the metrics $\\mathbf{N}$ and $\\mathbf{M}$.\nAs you can see [here](https://en.wikipedia.org/wiki/Singular_value_decomposition#Relation_to_eigenvalue_decomposition), in the standard formulation of SVD:\n\n- $\\mathbf{\\Lambda}$ is the $r \\times r$ diagonal matrix with elements equal to the square root of the non-zero eigenvalues of $\\mathbf{XX}^T$ and $\\mathbf{X}^T\\mathbf{X}$;\n- $\\mathbf{U}$ is the $n \\times r$ matrix of the first $r$ eigenvectors of $\\mathbf{XX}^T$ such that $\\mathbf{U}^T\\mathbf{U=I}$\n- $\\mathbf{V}$ is the $p \\times r$ matrix of the first $r$ eigenvectors of $\\mathbf{X}^T\\mathbf{NXM}$ such that $\\mathbf{V}^T\\mathbf{V=I}$;\n\n## PCA and MCA as special cases of GSVD\n\nThe solutions for both PCA and MCA can be obtained as special cases of the GSVD approach described by setting $\\mathbf{X}$ equal to a preprocessed version of the original data $\\mathbf{X}$ and using $\\mathbf{N}$ and $\\mathbf{M}$ to appropriately weight the rows and columns.\n\n### PCA\n\nThe input data for standard PCA is the $n \\times p$ matrix $\\mathbf{X}$ of $n$ rows (observations) described by $p$ numerical variables.\nThe columns of this matrix are usually centered and standardized.\nThe GSVD can be used to find the solution to PCA by setting $\\mathbf{X}$ equal to the centered and standardized version of $\\mathbf{X}$ and weighting:\n\n- its rows by $1/n$, which is obtained by setting $\\mathbf{N} = \\frac{1}{n}I_n$\n- its columns by $1$, which is obtained by setting $\\mathbf{M} = I_p$.\nThis metric indicates that the distance between two observations is the standard euclidean distance between two rows of $\\mathbf{X}$\n\nBy setting these values for the metrics, it is easy to see how the GSVD of $\\mathbf{X}$ reduces to the standard SVD of $\\mathbf{X}$.\n\n### MCA\n\nFor an $n \\times p$ data matrix $\\mathbf{X}$ with $n$ observations (rows) and $p$ discrete predictors (columns).\nEach $j = 1, \\dots, p$ discrete variable has $k_j$ possible values.\nThe sum of the $p$ $k_j$ values is $k$. \n$\\mathbf{X}$ is preprocessed by coding each level of the discrete items as binary variables describing whether each observation takes a specific value for every discrete variable.\nThis results in an $n \\times k$ [complete disjunctive table](https://www.xlstat.com/en/solutions/features/complete-disjuncive-tables-creating-dummy-variables) $\\mathbf{G}$, sometimes also referred to as an indicator matrix.\n\nMCA is usually obtained by applying Correspondence Analysis to $\\mathbf{G}$, which means applying standard PCA to the matrices of the row profiles and the column profiles.\nIn particular, for the goal of obtaining a lower-dimensional representation of $\\mathbf{X}$ we are interested in the standard PCA of the row profiles.\nWithin the framework of PCA with metrics, MCA can be obtained by first setting:\n\n- $\\mathbf{X}$ to the centered $\\mathbf{G}$\n- $\\mathbf{N} = \\frac{1}{n}I_n$\n- $\\mathbf{M} = \\text{diag}(\\frac{n}{n_s}, s = 1, \\dots, k)$\n\nThe coordinates of the observations (the principal component scores) can be obtained by applying the GSVD of $\\mathbf{X}$ with the given metrics.\n\n# Learn by coding\n\nTo understand the relationship between SVD, GSVD, PCA, and MCA we will need two packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Packages\nlibrary(\"FactoMineR\") # for analysis\nlibrary(\"factoextra\") # for visualizarion1\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggplot2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n```\n:::\n:::\n\n\n## MCA\n\n### A standard MCA analysis according to FactoMineR\n\nWe will start by performing the MCA analysis.\nLet's start by loading, preparing, and summarising the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data Prep ---------------------------------------------------------------\n\n# Load data\ndata(\"poison\")\nhead(poison[, 1:7], 3) # survey style data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Age Time   Sick Sex   Nausea Vomiting Abdominals\n1   9   22 Sick_y   F Nausea_y  Vomit_n     Abdo_y\n2   5    0 Sick_n   F Nausea_n  Vomit_n     Abdo_n\n3   6   16 Sick_y   F Nausea_n  Vomit_y     Abdo_y\n```\n:::\n\n```{.r .cell-code}\n# Subset active individuals and variables\npoison.active <- poison[1:55, 5:15]\nhead(poison.active[, 1:6], 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Nausea Vomiting Abdominals   Fever   Diarrhae   Potato\n1 Nausea_y  Vomit_n     Abdo_y Fever_y Diarrhea_y Potato_y\n2 Nausea_n  Vomit_n     Abdo_n Fever_n Diarrhea_n Potato_y\n3 Nausea_n  Vomit_y     Abdo_y Fever_y Diarrhea_y Potato_y\n```\n:::\n\n```{.r .cell-code}\n# Summaries\nstr(poison.active)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t55 obs. of  11 variables:\n $ Nausea    : Factor w/ 2 levels \"Nausea_n\",\"Nausea_y\": 2 1 1 1 1 1 1 2 2 1 ...\n $ Vomiting  : Factor w/ 2 levels \"Vomit_n\",\"Vomit_y\": 1 1 2 1 2 1 2 2 1 2 ...\n $ Abdominals: Factor w/ 2 levels \"Abdo_n\",\"Abdo_y\": 2 1 2 1 2 2 2 2 2 1 ...\n $ Fever     : Factor w/ 2 levels \"Fever_n\",\"Fever_y\": 2 1 2 1 2 2 2 2 2 2 ...\n $ Diarrhae  : Factor w/ 2 levels \"Diarrhea_n\",\"Diarrhea_y\": 2 1 2 1 2 2 2 2 2 2 ...\n $ Potato    : Factor w/ 2 levels \"Potato_n\",\"Potato_y\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Fish      : Factor w/ 2 levels \"Fish_n\",\"Fish_y\": 2 2 2 2 2 1 2 2 2 2 ...\n $ Mayo      : Factor w/ 2 levels \"Mayo_n\",\"Mayo_y\": 2 2 2 1 2 2 2 2 2 2 ...\n $ Courgette : Factor w/ 2 levels \"Courg_n\",\"Courg_y\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Cheese    : Factor w/ 2 levels \"Cheese_n\",\"Cheese_y\": 2 1 2 2 2 2 2 2 2 2 ...\n $ Icecream  : Factor w/ 2 levels \"Icecream_n\",\"Icecream_y\": 2 2 2 2 2 2 2 2 2 2 ...\n```\n:::\n\n```{.r .cell-code}\nfor (i in 1:4) {\n    plot(poison.active[, i],\n        main = colnames(poison.active)[i],\n        ylab = \"Count\", col = \"steelblue\", las = 2\n    )\n}\n```\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n:::\n\n\nWe can then use the `MCA()` function from the `FactorMineR` package to perform a standard MCA analysis of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The analysis ------------------------------------------------------------\nres.mca <- FactoMineR::MCA(\n    X = poison.active,\n    ncp = 5,\n    graph = TRUE\n)\n```\n:::\n\n\nWe can now visualize different aspects of the analysis.\n\nWe extract the eigenvalues\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualization -----------------------------------------------------------\n\n# Eigenvalues / Variances\neig.val <- get_eigenvalue(res.mca)\neig.val # proportion of variances retained by dimensions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       eigenvalue variance.percent cumulative.variance.percent\nDim.1  0.33523140        33.523140                    33.52314\nDim.2  0.12913979        12.913979                    46.43712\nDim.3  0.10734849        10.734849                    57.17197\nDim.4  0.09587950         9.587950                    66.75992\nDim.5  0.07883277         7.883277                    74.64319\nDim.6  0.07108981         7.108981                    81.75217\nDim.7  0.06016580         6.016580                    87.76876\nDim.8  0.05577301         5.577301                    93.34606\nDim.9  0.04120578         4.120578                    97.46663\nDim.10 0.01304158         1.304158                    98.77079\nDim.11 0.01229208         1.229208                   100.00000\n```\n:::\n:::\n\n\nPercentages of inertia explained by MCA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Percentages of Inertia explained by MCA\nfviz_screeplot(res.mca, addlabels = TRUE, ylim = c(0, 45))\n```\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nBiplots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Biplot\nfviz_mca_biplot(res.mca,\n    repel = TRUE, # avoid text overlapping\n    ggtheme = theme_minimal()\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: ggrepel: 29 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n```\n:::\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Rows (individuals) are represented by blue points;\n# Columns (variable categories) by red triangles.\n```\n:::\n\n\nGraphs of variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Graph of variables\nvar <- get_mca_var(res.mca)\nvar\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMultiple Correspondence Analysis Results for variables\n ===================================================\n  Name       Description                  \n1 \"$coord\"   \"Coordinates for categories\" \n2 \"$cos2\"    \"Cos2 for categories\"        \n3 \"$contrib\" \"contributions of categories\"\n```\n:::\n\n```{.r .cell-code}\n# Coordinates\nhead(var$coord)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Dim 1       Dim 2        Dim 3       Dim 4       Dim 5\nNausea_n  0.2673909  0.12139029 -0.265583253  0.03376130  0.07370500\nNausea_y -0.9581506 -0.43498187  0.951673323 -0.12097801 -0.26410958\nVomit_n   0.4790279 -0.40919465  0.084492799  0.27361142  0.05245250\nVomit_y  -0.7185419  0.61379197 -0.126739198 -0.41041713 -0.07867876\nAbdo_n    1.3180221 -0.03574501 -0.005094243 -0.15360951 -0.06986987\nAbdo_y   -0.6411999  0.01738946  0.002478280  0.07472895  0.03399075\n```\n:::\n\n```{.r .cell-code}\n# Cos2: quality on the factore map\nhead(var$cos2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Dim 1        Dim 2        Dim 3       Dim 4       Dim 5\nNausea_n 0.2562007 0.0528025759 2.527485e-01 0.004084375 0.019466197\nNausea_y 0.2562007 0.0528025759 2.527485e-01 0.004084375 0.019466197\nVomit_n  0.3442016 0.2511603912 1.070855e-02 0.112294813 0.004126898\nVomit_y  0.3442016 0.2511603912 1.070855e-02 0.112294813 0.004126898\nAbdo_n   0.8451157 0.0006215864 1.262496e-05 0.011479077 0.002374929\nAbdo_y   0.8451157 0.0006215864 1.262496e-05 0.011479077 0.002374929\n```\n:::\n\n```{.r .cell-code}\n# Contributions to the principal components\nhead(var$contrib)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Dim 1       Dim 2        Dim 3      Dim 4      Dim 5\nNausea_n  1.515869  0.81100008 4.670018e+00 0.08449397 0.48977906\nNausea_y  5.431862  2.90608363 1.673423e+01 0.30277007 1.75504164\nVomit_n   3.733667  7.07226253 3.627455e-01 4.25893721 0.19036376\nVomit_y   5.600500 10.60839380 5.441183e-01 6.38840581 0.28554563\nAbdo_n   15.417637  0.02943661 7.192511e-04 0.73219636 0.18424268\nAbdo_y    7.500472  0.01432051 3.499060e-04 0.35620363 0.08963157\n```\n:::\n:::\n\n\nGraphs for individuals\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Graph of individuals\nind <- get_mca_ind(res.mca) # extract the results for individuals\nind\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMultiple Correspondence Analysis Results for individuals\n ===================================================\n  Name       Description                       \n1 \"$coord\"   \"Coordinates for the individuals\" \n2 \"$cos2\"    \"Cos2 for the individuals\"        \n3 \"$contrib\" \"contributions of the individuals\"\n```\n:::\n\n```{.r .cell-code}\n# Coordinates of column points\nhead(ind$coord)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Dim 1       Dim 2       Dim 3       Dim 4       Dim 5\n1 -0.4525811 -0.26415072  0.17151614  0.01369348 -0.11696806\n2  0.8361700 -0.03193457 -0.07208249 -0.08550351  0.51978710\n3 -0.4481892  0.13538726 -0.22484048 -0.14170168 -0.05004753\n4  0.8803694 -0.08536230 -0.02052044 -0.07275873 -0.22935022\n5 -0.4481892  0.13538726 -0.22484048 -0.14170168 -0.05004753\n6 -0.3594324 -0.43604390 -1.20932223  1.72464616  0.04348157\n```\n:::\n\n```{.r .cell-code}\n# Quality of representation\nhead(ind$cos2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Dim 1        Dim 2        Dim 3        Dim 4        Dim 5\n1 0.34652591 0.1180447167 0.0497683175 0.0003172275 0.0231460846\n2 0.55589562 0.0008108236 0.0041310808 0.0058126211 0.2148103098\n3 0.54813888 0.0500176790 0.1379484860 0.0547920948 0.0068349171\n4 0.74773962 0.0070299584 0.0004062504 0.0051072923 0.0507479873\n5 0.54813888 0.0500176790 0.1379484860 0.0547920948 0.0068349171\n6 0.02485357 0.0365775483 0.2813443706 0.5722083217 0.0003637178\n```\n:::\n\n```{.r .cell-code}\n# Contributions\nhead(ind$contrib)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Dim 1      Dim 2        Dim 3        Dim 4      Dim 5\n1 1.110927 0.98238297  0.498254685  0.003555817 0.31554778\n2 3.792117 0.01435818  0.088003703  0.138637089 6.23134138\n3 1.089470 0.25806722  0.856229950  0.380768961 0.05776914\n4 4.203611 0.10259105  0.007132055  0.100387990 1.21319013\n5 1.089470 0.25806722  0.856229950  0.380768961 0.05776914\n6 0.700692 2.67693398 24.769968729 56.404214518 0.04360547\n```\n:::\n\n```{.r .cell-code}\n# BIplot for individuals only (no vars)\nfviz_mca_ind(res.mca,\n    col.ind = \"cos2\",\n    gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n    repel = TRUE, ggtheme = theme_minimal()\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: ggrepel: 25 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n```\n:::\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfviz_mca_ind(res.mca,\n    label = \"none\",\n    habillage = \"Vomiting\", # color by groups defined by variable\n    palette = c(\"#00AFBB\", \"#E7B800\"),\n    addEllipses = TRUE, ellipse.type = \"confidence\",\n    repel = TRUE, ggtheme = theme_minimal()\n)\n```\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\nEllipses\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# More than 1 grouping variable\nfviz_ellipses(res.mca, c(\"Vomiting\", \"Fever\"),\n    geom = \"point\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `gather_()` was deprecated in tidyr 1.2.0.\nℹ Please use `gather()` instead.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at <https://github.com/kassambara/factoextra/issues>.\n```\n:::\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nBar plot for Cos2 of individuals:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bar plot for Cos2 of individuals\nfviz_cos2(res.mca, choice = \"ind\", axes = 1:2, top = 20)\n```\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nContribution of individuals to the dimensions \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Contribution of individuals to the dimensions\nfviz_contrib(res.mca, choice = \"ind\", axes = 1:2, top = 20)\n```\n\n::: {.cell-output-display}\n![](pca-mix_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### Perfomring MCA by hand\n\nLet's work with wine data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data\ndata(wine)\n```\n:::\n\n\nLet's keep only the variables that are facotrs\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Keep factors\nMCA.dt <- wine[, sapply(wine, is.factor)]\n\n# Look at data\nMCA.dt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Label      Soil\n2EL      Saumur      Env1\n1CHA     Saumur      Env1\n1FON Bourgueuil      Env1\n1VAU     Chinon      Env2\n1DAM     Saumur Reference\n2BOU Bourgueuil Reference\n1BOI Bourgueuil Reference\n3EL      Saumur      Env1\nDOM1     Chinon      Env1\n1TUR     Saumur      Env2\n4EL      Saumur      Env2\nPER1     Saumur      Env2\n2DAM     Saumur Reference\n1POY     Saumur Reference\n1ING Bourgueuil      Env1\n1BEN Bourgueuil Reference\n2BEA     Chinon Reference\n1ROC     Chinon      Env2\n2ING Bourgueuil      Env1\nT1       Saumur      Env4\nT2       Saumur      Env4\n```\n:::\n:::\n\n\nThe two variables involved have these number of levels:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count levels\nsapply(MCA.dt, nlevels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLabel  Soil \n    3     4 \n```\n:::\n:::\n\n\nLet's now perform a standard MCA analysis with FactoMineR. Let's say we are aiming for extracting 4 components:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define goal number of PCs\nnpcs <- 4\n\n# Perform MCA\nres.mca <- FactoMineR::MCA(\n    X = MCA.dt,\n    ncp = npcs,\n    graph = FALSE\n)\n```\n:::\n\n\nWe can now look at the coordinates of the individuals on the `npcs` dimensions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Coordinates of the individuals on the dimensions\nres.mca$ind$coord\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Dim 1       Dim 2         Dim 3       Dim 4\n2EL  -0.08524441 -0.36629820  8.660254e-01 -0.42338794\n1CHA -0.08524441 -0.36629820  8.660254e-01 -0.42338794\n1FON -1.13625682  0.13134188  8.660254e-01  0.07425214\n1VAU  1.19013068  1.42046767  2.646476e-16  0.44277818\n1DAM -0.08524441 -0.36629820 -8.660254e-01 -0.42338794\n2BOU -1.13625682  0.13134188 -8.660254e-01  0.07425214\n1BOI -1.13625682  0.13134188 -8.660254e-01  0.07425214\n3EL  -0.08524441 -0.36629820  8.660254e-01 -0.42338794\nDOM1  0.08871159  0.96016779  8.660254e-01  0.90307806\n1TUR  1.01617468  0.09400168  1.274326e-15 -0.88368782\n4EL   1.01617468  0.09400168  1.274326e-15 -0.88368782\nPER1  1.01617468  0.09400168  1.274326e-15 -0.88368782\n2DAM -0.08524441 -0.36629820 -8.660254e-01 -0.42338794\n1POY -0.08524441 -0.36629820 -8.660254e-01 -0.42338794\n1ING -1.13625682  0.13134188  8.660254e-01  0.07425214\n1BEN -1.13625682  0.13134188 -8.660254e-01  0.07425214\n2BEA  0.08871159  0.96016779 -8.660254e-01  0.90307806\n1ROC  1.19013068  1.42046767  3.995551e-16  0.44277818\n2ING -1.13625682  0.13134188  8.660254e-01  0.07425214\nT1    0.86139937 -1.81676901 -3.719373e-16  1.02708287\nT2    0.86139937 -1.81676901 -3.719373e-16  1.02708287\n```\n:::\n:::\n\n\nWe can also look at the right singular vectors of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# right singular vectors of data\nres.mca$svd$V\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           [,1]        [,2]          [,3]        [,4]\n[1,]  0.5343096 -0.78968614 -4.844048e-15 -0.78968614\n[2,] -1.5677152  0.20559402 -3.260525e-15  0.20559402\n[3,]  0.8822216  1.86324585 -6.725946e-15  1.86324585\n[4,] -0.7047984  0.05708973 -1.732051e+00 -0.05708973\n[5,] -0.7047984  0.05708973  1.732051e+00 -0.05708973\n[6,]  1.4980398  0.97768949  6.898331e-15 -0.97768949\n[7,]  1.1884892 -2.84385187  3.204282e-15  2.84385187\n```\n:::\n:::\n\n\nNow we can replicate the computations involved following a description of MCA I found in AudigierEtAl2016_MICAT.\nFirst, we need to extract a few objects we will need.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create required processing objects\nI <- nrow(MCA.dt)             # numebr of individuals\nK <- ncol(MCA.dt)             # number of categorical predictors\nqk <- sapply(MCA.dt, nlevels) # number of levels per categorical variable\nJ <- sum(qk)                  # total number of categories\n```\n:::\n\n\nThen, we can create the disjonctive table:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Disjunctive table\nZ <- tab.disjonctif(MCA.dt)\n\n# And look at it\nZ\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Saumur Bourgueuil Chinon Reference Env1 Env2 Env4\n2EL       1          0      0         0    1    0    0\n1CHA      1          0      0         0    1    0    0\n1FON      0          1      0         0    1    0    0\n1VAU      0          0      1         0    0    1    0\n1DAM      1          0      0         1    0    0    0\n2BOU      0          1      0         1    0    0    0\n1BOI      0          1      0         1    0    0    0\n3EL       1          0      0         0    1    0    0\nDOM1      0          0      1         0    1    0    0\n1TUR      1          0      0         0    0    1    0\n4EL       1          0      0         0    0    1    0\nPER1      1          0      0         0    0    1    0\n2DAM      1          0      0         1    0    0    0\n1POY      1          0      0         1    0    0    0\n1ING      0          1      0         0    1    0    0\n1BEN      0          1      0         1    0    0    0\n2BEA      0          0      1         1    0    0    0\n1ROC      0          0      1         0    0    1    0\n2ING      0          1      0         0    1    0    0\nT1        1          0      0         0    0    0    1\nT2        1          0      0         0    0    0    1\n```\n:::\n:::\n\n\nNotice the relationship of the disjunctive table with a standard contingency table:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Relationship between disjunctive table and contingency table\nN <- t(Z[, 1:3]) %*% Z[, 4:7]\nN - table(MCA.dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Reference Env1 Env2 Env4\nSaumur             0    0    0    0\nBourgueuil         0    0    0    0\nChinon             0    0    0    0\n```\n:::\n:::\n\n\nWe can compute the weighting matrices that are used to perform MCA.\nFirst, we want to compute the proportion of individuals taking a category value for each variable, which is known as a distance matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Distance Metric Matrix\npxkqk <- colSums(Z) / I\nD_Sigma <- diag(pxkqk)\n```\n:::\n\n\nThen we want to compute the individual weight matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Weight Matrix\nW_mat <- diag(rep(1, I))/I\n```\n:::\n\n\nand finally, we want to compute the center matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# M matrix (center matrix)\nM <- matrix((rep(colMeans(Z), nrow(Z))),\n    nrow = nrow(Z),\n    byrow = TRUE\n)\n```\n:::\n\n\nWe can now take the SVD of a centered version of the disjunctive table with an SVD triplet function form `FactoMineR`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# SVD of triplet (Z-M, D_Sigma, W_mat)\nSVD.trip <- FactoMineR::svd.triplet(\n    X = Z - M,\n    row.w = diag(W_mat),\n    col.w = diag(1 / K * solve(D_Sigma)),\n    ncp = npcs\n)\n```\n:::\n\n\nWe can also take the SVD of the same centered matrix using a thes standard `svd` R function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Manual SVD triplet\nSVD.man <- svd(sqrt(W_mat) %*% (Z - M) %*% sqrt(1 / K * solve(D_Sigma)))\n```\n:::\n\n\nWhen computing the SVD in this manual way, we need to convert the scale according to Chaven 2017 p. 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert back to correct scales (according to Chaven 2017 p. 3)\nV.man <- (solve(sqrt(1 / K * solve(D_Sigma))) %*% SVD.man$v)[, 1:npcs]\nU.man <- (solve(sqrt(W_mat)) %*% SVD.man$u)[, 1:npcs]\nL.man <- SVD.man$d[1:npcs]\n```\n:::\n\n\nDoing so, you will see that the computation obtained by `FactoMineR` approach is the same as the one done by hand\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Compare SVD triplet and manual SVD of weighted matrix\n  round(abs(SVD.trip$V) - abs(V.man), 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3] [,4]\n[1,]    0    0    0    0\n[2,]    0    0    0    0\n[3,]    0    0    0    0\n[4,]    0    0    0    0\n[5,]    0    0    0    0\n[6,]    0    0    0    0\n[7,]    0    0    0    0\n```\n:::\n\n```{.r .cell-code}\n  round(abs(SVD.trip$U) - abs(U.man), 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      [,1] [,2] [,3] [,4]\n [1,]    0    0    0    0\n [2,]    0    0    0    0\n [3,]    0    0    0    0\n [4,]    0    0    0    0\n [5,]    0    0    0    0\n [6,]    0    0    0    0\n [7,]    0    0    0    0\n [8,]    0    0    0    0\n [9,]    0    0    0    0\n[10,]    0    0    0    0\n[11,]    0    0    0    0\n[12,]    0    0    0    0\n[13,]    0    0    0    0\n[14,]    0    0    0    0\n[15,]    0    0    0    0\n[16,]    0    0    0    0\n[17,]    0    0    0    0\n[18,]    0    0    0    0\n[19,]    0    0    0    0\n[20,]    0    0    0    0\n[21,]    0    0    0    0\n```\n:::\n\n```{.r .cell-code}\n  round(abs(SVD.trip$vs[1:npcs]) - abs(L.man), 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0 0 0 0\n```\n:::\n\n```{.r .cell-code}\n  # Reconstruction Formula\n  d_hat <- SVD.trip$vs[1:npcs] # matrix of the singular values \n                            # (Squared would be eigenvalues of Z)\n  u_hat <- SVD.trip$U # Left singular vectors matrix\n  v_hat <- SVD.trip$V # Right singular vectors matrix\n  \n  z_hat <- u_hat %*% diag(d_hat) %*% t(v_hat) + M\n  colSums(z_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 11  6  4  7  7  5  2\n```\n:::\n\n```{.r .cell-code}\n  colSums(Z)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Saumur Bourgueuil     Chinon  Reference       Env1       Env2       Env4 \n        11          6          4          7          7          5          2 \n```\n:::\n\n```{.r .cell-code}\n  # Compare SVD matrices\n  # Matrix of singular values\n  res.mca$svd$vs[1:npcs] -\n    d_hat[1:npcs]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.000000e+00 0.000000e+00 1.110223e-16 2.220446e-16\n```\n:::\n\n```{.r .cell-code}\n  res.mca$svd$vs[1:npcs] -\n    L.man\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.000000e+00 0.000000e+00 2.220446e-16 6.661338e-16\n```\n:::\n\n```{.r .cell-code}\n  # Left Singular Vectors Matrix\n  round(\n    res.mca$svd$U - u_hat,\n    3\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      [,1] [,2]   [,3] [,4]\n [1,]    0    0  2.449    0\n [2,]    0    0  2.449    0\n [3,]    0    0  2.449    0\n [4,]    0    0  0.000    0\n [5,]    0    0 -2.449    0\n [6,]    0    0 -2.449    0\n [7,]    0    0 -2.449    0\n [8,]    0    0  2.449    0\n [9,]    0    0  2.449    0\n[10,]    0    0  0.000    0\n[11,]    0    0  0.000    0\n[12,]    0    0  0.000    0\n[13,]    0    0 -2.449    0\n[14,]    0    0 -2.449    0\n[15,]    0    0  2.449    0\n[16,]    0    0 -2.449    0\n[17,]    0    0 -2.449    0\n[18,]    0    0  0.000    0\n[19,]    0    0  2.449    0\n[20,]    0    0  0.000    0\n[21,]    0    0  0.000    0\n```\n:::\n\n```{.r .cell-code}\n  round(\n    res.mca$svd$U - U.man,\n    3\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        [,1]   [,2]   [,3] [,4]\n [1,] -0.200 -0.917  2.449    0\n [2,] -0.200 -0.917  2.449    0\n [3,] -2.669  0.329  2.449    0\n [4,]  2.796  3.554  0.000    0\n [5,] -0.200 -0.917 -2.449    0\n [6,] -2.669  0.329 -2.449    0\n [7,] -2.669  0.329 -2.449    0\n [8,] -0.200 -0.917  2.449    0\n [9,]  0.208  2.403  2.449    0\n[10,]  2.387  0.235  0.000    0\n[11,]  2.387  0.235  0.000    0\n[12,]  2.387  0.235  0.000    0\n[13,] -0.200 -0.917 -2.449    0\n[14,] -0.200 -0.917 -2.449    0\n[15,] -2.669  0.329  2.449    0\n[16,] -2.669  0.329 -2.449    0\n[17,]  0.208  2.403 -2.449    0\n[18,]  2.796  3.554  0.000    0\n[19,] -2.669  0.329  2.449    0\n[20,]  2.024 -4.546  0.000    0\n[21,]  2.024 -4.546  0.000    0\n```\n:::\n\n```{.r .cell-code}\n  # Right Singular Vectors Matrix\n  round(\n    res.mca$svd$V -\n      v_hat, \n    3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1]   [,2]   [,3]   [,4]\n[1,]  0.254 -0.376  0.000 -0.376\n[2,] -1.120  0.147  0.000  0.147\n[3,]  0.714  1.508  0.000  1.508\n[4,] -0.470  0.038 -2.309 -0.038\n[5,] -0.470  0.038  2.309 -0.038\n[6,]  1.141  0.745  0.000 -0.745\n[7,]  1.075 -2.573  0.000  2.573\n```\n:::\n\n```{.r .cell-code}\n  # Correlation between columns\n  # And look into the PCAmixdata package\n  round(cor(v_hat, res.mca$svd$V), 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3] [,4]\n[1,]  0.9  0.0    0  0.0\n[2,]  0.0  0.8    0  0.0\n[3,]  0.0  0.0   -1  0.0\n[4,]  0.0  0.0    0  0.9\n```\n:::\n\n```{.r .cell-code}\n  # Coordinates on Dimensions are recovered\n  round(\n    res.mca$ind$coord -\n      u_hat %*% diag(d_hat),\n    3\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Dim 1 Dim 2  Dim 3 Dim 4\n2EL      0     0  1.732     0\n1CHA     0     0  1.732     0\n1FON     0     0  1.732     0\n1VAU     0     0  0.000     0\n1DAM     0     0 -1.732     0\n2BOU     0     0 -1.732     0\n1BOI     0     0 -1.732     0\n3EL      0     0  1.732     0\nDOM1     0     0  1.732     0\n1TUR     0     0  0.000     0\n4EL      0     0  0.000     0\nPER1     0     0  0.000     0\n2DAM     0     0 -1.732     0\n1POY     0     0 -1.732     0\n1ING     0     0  1.732     0\n1BEN     0     0 -1.732     0\n2BEA     0     0 -1.732     0\n1ROC     0     0  0.000     0\n2ING     0     0  1.732     0\nT1       0     0  0.000     0\nT2       0     0  0.000     0\n```\n:::\n\n```{.r .cell-code}\n# Following JosseHusson2016 -----------------------------------------------\n\n  I <- nrow(MCA.dt)\n  J <- ncol(MCA.dt)\n  X <- tab.disjonctif(MCA.dt)\n  rowMarg <- rowSums(X) # = J\n  colMarg <- colSums(X) # = number of ids in a category\n  D_Sigma <- diag(colMarg)\n  D <- 1/I * diag(rep(1, I)) # rowMasses\n  SVD.trip <- svd.triplet(X = diag(rep(1, I)) %*% X %*% solve(D_Sigma),\n                          row.w = diag( D ),\n                          col.w = diag( 1/(I*J)*D_Sigma ),\n                          ncp=2\n                          )\n  svd(I * X %*% solve(D_Sigma))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$d\n[1] 1.514660e+01 1.236990e+01 1.054821e+01 7.978230e+00 7.937254e+00\n[6] 6.179826e+00 9.636589e-16\n\n$u\n             [,1]        [,2]        [,3]        [,4]          [,5]        [,6]\n [1,] 0.032591337 -0.07625736  0.13536164  0.10431026 -2.672612e-01 -0.33476464\n [2,] 0.032591337 -0.07625736  0.13536164  0.10431026 -2.672612e-01 -0.33476464\n [3,] 0.007760225 -0.10152263  0.35440169  0.02151024 -2.672612e-01  0.17388603\n [4,] 0.020375871 -0.49923872 -0.22465765 -0.05818667  8.885241e-17  0.17269077\n [5,] 0.032591337 -0.07625736  0.13536164  0.10431026  2.672612e-01 -0.33476464\n [6,] 0.007760225 -0.10152263  0.35440169  0.02151024  2.672612e-01  0.17388603\n [7,] 0.007760225 -0.10152263  0.35440169  0.02151024  2.672612e-01  0.17388603\n [8,] 0.032591337 -0.07625736  0.13536164  0.10431026 -2.672612e-01 -0.33476464\n [9,] 0.013386482 -0.36360489  0.01780574 -0.40099813 -2.672612e-01 -0.19957224\n[10,] 0.039580726 -0.21189120 -0.10710176  0.44712172 -1.379817e-16  0.03749837\n[11,] 0.039580726 -0.21189120 -0.10710176  0.44712172 -1.379817e-16  0.03749837\n[12,] 0.039580726 -0.21189120 -0.10710176  0.44712172 -1.379817e-16  0.03749837\n[13,] 0.032591337 -0.07625736  0.13536164  0.10431026  2.672612e-01 -0.33476464\n[14,] 0.032591337 -0.07625736  0.13536164  0.10431026  2.672612e-01 -0.33476464\n[15,] 0.007760225 -0.10152263  0.35440169  0.02151024 -2.672612e-01  0.17388603\n[16,] 0.007760225 -0.10152263  0.35440169  0.02151024  2.672612e-01  0.17388603\n[17,] 0.013386482 -0.36360489  0.01780574 -0.40099813  2.672612e-01 -0.19957224\n[18,] 0.020375871 -0.49923872 -0.22465765 -0.05818667  1.352292e-16  0.17269077\n[19,] 0.007760225 -0.10152263  0.35440169  0.02151024 -2.672612e-01  0.17388603\n[20,] 0.702629651  0.05328487 -0.01535314 -0.04368183  3.942058e-17  0.03644825\n[21,] 0.702629651  0.05328487 -0.01535314 -0.04368183  3.942058e-17  0.03644825\n               [,7]\n [1,]  4.208432e-01\n [2,]  4.991001e-01\n [3,] -3.618114e-02\n [4,] -1.518978e-01\n [5,] -2.291723e-01\n [6,]  4.197641e-01\n [7,]  4.193287e-03\n [8,] -3.900336e-01\n [9,] -1.017590e-01\n[10,] -2.744259e-02\n[11,] -2.744259e-02\n[12,] -2.744259e-02\n[13,] -1.092048e-01\n[14,] -1.092048e-01\n[15,] -1.959848e-01\n[16,]  4.193287e-03\n[17,]  1.943126e-02\n[18,]  2.342255e-01\n[19,] -1.959848e-01\n[20,] -2.270596e-17\n[21,] -2.270596e-17\n\n$v\n           [,1]        [,2]        [,3]         [,4]          [,5]        [,6]\n[1,] 0.21673353 -0.15227297  0.08328278  0.449827802  0.000000e+00 -0.56322741\n[2,] 0.01075916 -0.17235191  0.70556405  0.056618453 -5.143453e-16  0.59089151\n[3,] 0.02340490 -0.73241180 -0.20590657 -0.604324602  7.308978e-16 -0.04567368\n[4,] 0.02662799 -0.21753089  0.42294271 -0.008850321  7.071068e-01 -0.33117829\n[5,] 0.02662799 -0.21753089  0.42294271 -0.008850321 -7.071068e-01 -0.33117829\n[6,] 0.04422606 -0.55484980 -0.30683950  0.644875605  2.730638e-17  0.31118708\n[7,] 0.97416066  0.09046012 -0.03056595 -0.114977701 -1.236662e-16  0.12385678\n           [,7]\n[1,] -0.6350853\n[2,] -0.3464102\n[3,] -0.2309401\n[4,]  0.4041452\n[5,]  0.4041452\n[6,]  0.2886751\n[7,]  0.1154701\n```\n:::\n\n```{.r .cell-code}\n  SVD.trip$vs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.761905e-02 4.054015e-02 3.806073e-02 3.367175e-02 2.861739e-02\n[6] 2.498139e-02 6.677878e-18\n```\n:::\n\n```{.r .cell-code}\n  round(SVD.trip$vs[2:3] - res.mca$svd$vs[1:2], 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.811 -0.761\n```\n:::\n\n```{.r .cell-code}\n  SVD.trip$U\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      [,1]       [,2]\n [1,]    1 -0.1001293\n [2,]    1 -0.1001293\n [3,]    1 -1.3346637\n [4,]    1  1.3979447\n [5,]    1 -0.1001293\n [6,]    1 -1.3346637\n [7,]    1 -1.3346637\n [8,]    1 -0.1001293\n [9,]    1  0.1042019\n[10,]    1  1.1936135\n[11,]    1  1.1936135\n[12,]    1  1.1936135\n[13,]    1 -0.1001293\n[14,]    1 -0.1001293\n[15,]    1 -1.3346637\n[16,]    1 -1.3346637\n[17,]    1  0.1042019\n[18,]    1  1.3979447\n[19,]    1 -1.3346637\n[20,]    1  1.0118122\n[21,]    1  1.0118122\n```\n:::\n\n```{.r .cell-code}\n  res.mca$svd$U\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]       [,2]          [,3]       [,4]\n [1,] -0.1001293 -0.4582879  1.224745e+00 -0.7045133\n [2,] -0.1001293 -0.4582879  1.224745e+00 -0.7045133\n [3,] -1.3346637  0.1643262  1.224745e+00  0.1235548\n [4,]  1.3979447  1.7771946  3.742682e-16  0.7367785\n [5,] -0.1001293 -0.4582879 -1.224745e+00 -0.7045133\n [6,] -1.3346637  0.1643262 -1.224745e+00  0.1235548\n [7,] -1.3346637  0.1643262 -1.224745e+00  0.1235548\n [8,] -0.1001293 -0.4582879  1.224745e+00 -0.7045133\n [9,]  0.1042019  1.2012980  1.224745e+00  1.5027130\n[10,]  1.1936135  0.1176086  1.802169e-15 -1.4704478\n[11,]  1.1936135  0.1176086  1.802169e-15 -1.4704478\n[12,]  1.1936135  0.1176086  1.802169e-15 -1.4704478\n[13,] -0.1001293 -0.4582879 -1.224745e+00 -0.7045133\n[14,] -0.1001293 -0.4582879 -1.224745e+00 -0.7045133\n[15,] -1.3346637  0.1643262  1.224745e+00  0.1235548\n[16,] -1.3346637  0.1643262 -1.224745e+00  0.1235548\n[17,]  0.1042019  1.2012980 -1.224745e+00  1.5027130\n[18,]  1.3979447  1.7771946  5.650563e-16  0.7367785\n[19,] -1.3346637  0.1643262  1.224745e+00  0.1235548\n[20,]  1.0118122 -2.2730204 -5.259988e-16  1.7090557\n[21,]  1.0118122 -2.2730204 -5.259988e-16  1.7090557\n```\n:::\n\n```{.r .cell-code}\n#   round(SVD.trip$U[, 2:3] - res.mca$svd$U, 3)\n  res.mca$svd$U\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]       [,2]          [,3]       [,4]\n [1,] -0.1001293 -0.4582879  1.224745e+00 -0.7045133\n [2,] -0.1001293 -0.4582879  1.224745e+00 -0.7045133\n [3,] -1.3346637  0.1643262  1.224745e+00  0.1235548\n [4,]  1.3979447  1.7771946  3.742682e-16  0.7367785\n [5,] -0.1001293 -0.4582879 -1.224745e+00 -0.7045133\n [6,] -1.3346637  0.1643262 -1.224745e+00  0.1235548\n [7,] -1.3346637  0.1643262 -1.224745e+00  0.1235548\n [8,] -0.1001293 -0.4582879  1.224745e+00 -0.7045133\n [9,]  0.1042019  1.2012980  1.224745e+00  1.5027130\n[10,]  1.1936135  0.1176086  1.802169e-15 -1.4704478\n[11,]  1.1936135  0.1176086  1.802169e-15 -1.4704478\n[12,]  1.1936135  0.1176086  1.802169e-15 -1.4704478\n[13,] -0.1001293 -0.4582879 -1.224745e+00 -0.7045133\n[14,] -0.1001293 -0.4582879 -1.224745e+00 -0.7045133\n[15,] -1.3346637  0.1643262  1.224745e+00  0.1235548\n[16,] -1.3346637  0.1643262 -1.224745e+00  0.1235548\n[17,]  0.1042019  1.2012980 -1.224745e+00  1.5027130\n[18,]  1.3979447  1.7771946  5.650563e-16  0.7367785\n[19,] -1.3346637  0.1643262  1.224745e+00  0.1235548\n[20,]  1.0118122 -2.2730204 -5.259988e-16  1.7090557\n[21,]  1.0118122 -2.2730204 -5.259988e-16  1.7090557\n```\n:::\n\n```{.r .cell-code}\n#   SVD.trip$V\n#   round(SVD.trip$V[, 2:3] - res.mca$svd$V, 3)\n#   res.mca$svd$V\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare environment ----------------------------------------------------------\n\nlibrary(psych)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'psych'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n```\n:::\n\n```{.r .cell-code}\nlibrary(PCAmixdata)\n\nlibrary(\"FactoMineR\")\nlibrary(\"factoextra\")\n\ndata(tea)\n\nhead(tea)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      breakfast     tea.time     evening     lunch     dinner     always home\n1     breakfast Not.tea time Not.evening Not.lunch Not.dinner Not.always home\n2     breakfast Not.tea time Not.evening Not.lunch Not.dinner Not.always home\n3 Not.breakfast     tea time     evening Not.lunch     dinner Not.always home\n4 Not.breakfast Not.tea time Not.evening Not.lunch     dinner Not.always home\n5     breakfast Not.tea time     evening Not.lunch Not.dinner     always home\n6 Not.breakfast Not.tea time Not.evening Not.lunch     dinner Not.always home\n      work     tearoom     friends     resto     pub       Tea   How    sugar\n1 Not.work Not.tearoom Not.friends Not.resto Not.pub     black alone    sugar\n2 Not.work Not.tearoom Not.friends Not.resto Not.pub     black  milk No.sugar\n3     work Not.tearoom     friends     resto Not.pub Earl Grey alone No.sugar\n4 Not.work Not.tearoom Not.friends Not.resto Not.pub Earl Grey alone    sugar\n5 Not.work Not.tearoom Not.friends Not.resto Not.pub Earl Grey alone No.sugar\n6 Not.work Not.tearoom Not.friends Not.resto Not.pub Earl Grey alone No.sugar\n      how       where           price age sex          SPC         Sport age_Q\n1 tea bag chain store       p_unknown  39   M       middle     sportsman 35-44\n2 tea bag chain store      p_variable  45   F       middle     sportsman 45-59\n3 tea bag chain store      p_variable  47   F other worker     sportsman 45-59\n4 tea bag chain store      p_variable  23   M      student Not.sportsman 15-24\n5 tea bag chain store      p_variable  48   M     employee     sportsman 45-59\n6 tea bag chain store p_private label  21   M      student     sportsman 15-24\n  frequency     escape.exoticism     spirituality     healthy     diuretic\n1     1/day Not.escape-exoticism Not.spirituality     healthy Not.diuretic\n2     1/day     escape-exoticism Not.spirituality     healthy     diuretic\n3    +2/day Not.escape-exoticism Not.spirituality     healthy     diuretic\n4     1/day     escape-exoticism     spirituality     healthy Not.diuretic\n5    +2/day     escape-exoticism     spirituality Not.healthy     diuretic\n6     1/day Not.escape-exoticism Not.spirituality     healthy Not.diuretic\n      friendliness     iron.absorption     feminine     sophisticated\n1 Not.friendliness Not.iron absorption Not.feminine Not.sophisticated\n2 Not.friendliness Not.iron absorption Not.feminine Not.sophisticated\n3     friendliness Not.iron absorption Not.feminine Not.sophisticated\n4 Not.friendliness Not.iron absorption Not.feminine     sophisticated\n5     friendliness Not.iron absorption Not.feminine Not.sophisticated\n6 Not.friendliness Not.iron absorption Not.feminine Not.sophisticated\n     slimming    exciting    relaxing    effect.on.health\n1 No.slimming No.exciting No.relaxing No.effect on health\n2 No.slimming    exciting No.relaxing No.effect on health\n3 No.slimming No.exciting    relaxing No.effect on health\n4 No.slimming No.exciting    relaxing No.effect on health\n5 No.slimming No.exciting    relaxing No.effect on health\n6 No.slimming No.exciting    relaxing No.effect on health\n```\n:::\n\n```{.r .cell-code}\nlapply(tea[, c(\"where\", \"how\", \"SPC\")], nlevels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$where\n[1] 3\n\n$how\n[1] 3\n\n$SPC\n[1] 7\n```\n:::\n\n```{.r .cell-code}\nsapply(tea, nlevels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       breakfast         tea.time          evening            lunch \n               2                2                2                2 \n          dinner           always             home             work \n               2                2                2                2 \n         tearoom          friends            resto              pub \n               2                2                2                2 \n             Tea              How            sugar              how \n               3                4                2                3 \n           where            price              age              sex \n               3                6                0                2 \n             SPC            Sport            age_Q        frequency \n               7                2                5                4 \nescape.exoticism     spirituality          healthy         diuretic \n               2                2                2                2 \n    friendliness  iron.absorption         feminine    sophisticated \n               2                2                2                2 \n        slimming         exciting         relaxing effect.on.health \n               2                2                2                2 \n```\n:::\n\n```{.r .cell-code}\nx <- tea[, c(\"where\", \"how\", \"Tea\")]\n\nCTD <- tab.disjonctif(x)\npk <- colMeans(CTD)\n\nCTD[1, ] / pk\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         chain store chain store+tea shop             tea shop \n            1.562500             0.000000             0.000000 \n             tea bag   tea bag+unpackaged           unpackaged \n            1.764706             0.000000             0.000000 \n               black            Earl Grey                green \n            4.054054             0.000000             0.000000 \n```\n:::\n\n```{.r .cell-code}\nCTD[4, ] / pk\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         chain store chain store+tea shop             tea shop \n            1.562500             0.000000             0.000000 \n             tea bag   tea bag+unpackaged           unpackaged \n            1.764706             0.000000             0.000000 \n               black            Earl Grey                green \n            0.000000             1.554404             0.000000 \n```\n:::\n\n```{.r .cell-code}\n1/.64\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.5625\n```\n:::\n\n```{.r .cell-code}\n1/.56666667\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.764706\n```\n:::\n\n```{.r .cell-code}\nCTD_t <- t(apply(CTD, 1, function(r) {t(r)/pk} ))\ncolMeans(CTD_t)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 1 1 1 1 1 1 1 1\n```\n:::\n\n```{.r .cell-code}\nN <- tab.disjonctif(x)\n1/nrow(tea)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.003333333\n```\n:::\n\n```{.r .cell-code}\n# Correspondance analysis based on contingency table ---------------------------\nx <- tea[, c(\"SPC\", \"where\")]\nn <- nrow(x)\nr <- nlevels(x[, 1]) \nC <- nlevels(x[, 2]) \nN <- table(x)\n\n# Contingency table\nN\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              where\nSPC            chain store chain store+tea shop tea shop\n  employee              46                   11        2\n  middle                21                   12        7\n  non-worker            35                   22        7\n  other worker          14                    4        2\n  senior                16                   14        5\n  student               55                   12        3\n  workman                5                    3        4\n```\n:::\n\n```{.r .cell-code}\n# Indicator matrix\nZ <- tab.disjonctif(x)\nZ1 <- Z[, 1:r]\nZ2 <- Z[, -c(1:r)]\nN - t(Z1) %*% Z2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              where\nSPC            chain store chain store+tea shop tea shop\n  employee               0                    0        0\n  middle                 0                    0        0\n  non-worker             0                    0        0\n  other worker           0                    0        0\n  senior                 0                    0        0\n  student                0                    0        0\n  workman                0                    0        0\n```\n:::\n\n```{.r .cell-code}\n# Correspondance matrix\nP <- 1/n * N\n\n# From Greenacre1984\nN\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              where\nSPC            chain store chain store+tea shop tea shop\n  employee              46                   11        2\n  middle                21                   12        7\n  non-worker            35                   22        7\n  other worker          14                    4        2\n  senior                16                   14        5\n  student               55                   12        3\n  workman                5                    3        4\n```\n:::\n\n```{.r .cell-code}\n# Column and row sums\nr_bold <- rowSums(N)\nc_bold <- colSums(N)\n\ndrop(N %*% rep(1, ncol(N))) - r_bold\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    employee       middle   non-worker other worker       senior      student \n           0            0            0            0            0            0 \n     workman \n           0 \n```\n:::\n\n```{.r .cell-code}\ndrop(t(N) %*% rep(1, nrow(N))) - c_bold\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         chain store chain store+tea shop             tea shop \n                   0                    0                    0 \n```\n:::\n\n```{.r .cell-code}\nD_r <- diag(r_bold)\nD_c <- diag(c_bold)\n\n# Matrices of profiles\n\nR <- solve(D_r) %*% P\nC <- solve(D_c) %*% t(P)\n\n# Centroids\nr <- t(C) %*% c_bold\nc <- t(R) %*% r_bold\n\n# Generalized SVD of P - r_bold t(c_bold)\n\nP - r_bold %*% t(c_bold)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              where\nSPC            chain store chain store+tea shop    tea shop\n  employee     -11327.8467           -4601.9633  -1769.9933\n  middle        -7679.9300           -3119.9600  -1199.9767\n  non-worker   -12287.8833           -4991.9267  -1919.9767\n  other worker  -3839.9533           -1559.9867   -599.9933\n  senior        -6719.9467           -2729.9533  -1049.9833\n  student      -13439.8167           -5459.9600  -2099.9900\n  workman       -2303.9833            -935.9900   -359.9867\n```\n:::\n\n```{.r .cell-code}\nA <- svd(P - r %*% t(c))$u\nB <- svd(P - r %*% t(c))$v\n\nt(A) %*% solve(D_r) %*% A\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             [,1]         [,2]         [,3]\n[1,]  0.019696233  0.004907973 -0.002761302\n[2,]  0.004907973  0.042624633 -0.004062585\n[3,] -0.002761302 -0.004062585  0.017670747\n```\n:::\n\n```{.r .cell-code}\nt(B) %*% solve(D_c) %*% B\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]        [,2]        [,3]\n[1,] 0.009787727 0.004094881 0.007204504\n[2,] 0.004094881 0.024453726 0.009443356\n[3,] 0.007204504 0.009443356 0.017120726\n```\n:::\n\n```{.r .cell-code}\n# From Jolliffe p. 37\n# r_bold <- rep(1, r)\n# c_bold <- rep(1, C)\n# D_r <- diag(r_bold)\n# D_c <- diag(c_bold)\n# Omega <- solve(D_r)\n# Psi <- solve(D_c)\n# X <- P - r_bold %*% t(c_bold)\n\n# V <- svd(X)$u\n# M <- diag(svd(X)$d)\n# B <- svd(X)$v\n\n# round(t(V) %*% Omega %*% V, 3)\n# round(t(B) %*% Psi %*% B, 3)\n\n# X_til <- sqrt(Omega) %*% X %*% sqrt(Psi)\n\n# W <- svd(X_til)$u\n# K <- diag(svd(X_til)$d)\n# C <- svd(X_til)$v\n\n# solve(sqrt(Omega)) %*% W - V\n# solve(sqrt(Omega)) %*% C - B\n\n# W %*% K\n\n# # Row profiles\n# D_r\n\n# MCA based on Audigier et al 2017 p. 505 (p. 5 of pdf) ------------------------\n\n    # Work with categorical predictors from the tea dataset\n    x <- tea[, c(\"where\", \"how\", \"Tea\")]\n\n    # Define row weights\n    I <- nrow(x)\n    R <- diag(1 / I, I)\n\n    # Define Z (the disjunctive table)\n    Z <- tab.disjonctif(x)\n\n    # Define column weights\n    K <- ncol(x)\n    plxk <- colMeans(Z)\n    D_sigma <- diag(plxk)\n    1 / K * solve(D_sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           [,1]     [,2]     [,3]      [,4]    [,5]     [,6]     [,7]      [,8]\n [1,] 0.5208333 0.000000 0.000000 0.0000000 0.00000 0.000000 0.000000 0.0000000\n [2,] 0.0000000 1.282051 0.000000 0.0000000 0.00000 0.000000 0.000000 0.0000000\n [3,] 0.0000000 0.000000 3.333333 0.0000000 0.00000 0.000000 0.000000 0.0000000\n [4,] 0.0000000 0.000000 0.000000 0.5882353 0.00000 0.000000 0.000000 0.0000000\n [5,] 0.0000000 0.000000 0.000000 0.0000000 1.06383 0.000000 0.000000 0.0000000\n [6,] 0.0000000 0.000000 0.000000 0.0000000 0.00000 2.777778 0.000000 0.0000000\n [7,] 0.0000000 0.000000 0.000000 0.0000000 0.00000 0.000000 1.351351 0.0000000\n [8,] 0.0000000 0.000000 0.000000 0.0000000 0.00000 0.000000 0.000000 0.5181347\n [9,] 0.0000000 0.000000 0.000000 0.0000000 0.00000 0.000000 0.000000 0.0000000\n          [,9]\n [1,] 0.000000\n [2,] 0.000000\n [3,] 0.000000\n [4,] 0.000000\n [5,] 0.000000\n [6,] 0.000000\n [7,] 0.000000\n [8,] 0.000000\n [9,] 3.030303\n```\n:::\n\n```{.r .cell-code}\n    # Define M\n    M <- matrix(rep(plxk, I), nrow = I, byrow = TRUE)\n\n    # Centered matrix?\n    Z - M\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    chain store chain store+tea shop tea shop    tea bag tea bag+unpackaged\n1          0.36                -0.26     -0.1  0.4333333         -0.3133333\n2          0.36                -0.26     -0.1  0.4333333         -0.3133333\n3          0.36                -0.26     -0.1  0.4333333         -0.3133333\n4          0.36                -0.26     -0.1  0.4333333         -0.3133333\n5          0.36                -0.26     -0.1  0.4333333         -0.3133333\n6          0.36                -0.26     -0.1  0.4333333         -0.3133333\n7          0.36                -0.26     -0.1  0.4333333         -0.3133333\n8          0.36                -0.26     -0.1  0.4333333         -0.3133333\n9         -0.64                 0.74     -0.1 -0.5666667          0.6866667\n10        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n11         0.36                -0.26     -0.1  0.4333333         -0.3133333\n12         0.36                -0.26     -0.1  0.4333333         -0.3133333\n13        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n14         0.36                -0.26     -0.1  0.4333333         -0.3133333\n15        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n16        -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n17        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n18        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n19         0.36                -0.26     -0.1  0.4333333         -0.3133333\n20         0.36                -0.26     -0.1  0.4333333         -0.3133333\n21        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n22        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n23         0.36                -0.26     -0.1  0.4333333         -0.3133333\n24         0.36                -0.26     -0.1  0.4333333         -0.3133333\n25        -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n26        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n27         0.36                -0.26     -0.1  0.4333333         -0.3133333\n28         0.36                -0.26     -0.1 -0.5666667          0.6866667\n29         0.36                -0.26     -0.1  0.4333333         -0.3133333\n30         0.36                -0.26     -0.1  0.4333333         -0.3133333\n31        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n32        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n33        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n34         0.36                -0.26     -0.1  0.4333333         -0.3133333\n35        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n36         0.36                -0.26     -0.1  0.4333333         -0.3133333\n37         0.36                -0.26     -0.1 -0.5666667          0.6866667\n38         0.36                -0.26     -0.1  0.4333333         -0.3133333\n39        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n40        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n41         0.36                -0.26     -0.1  0.4333333         -0.3133333\n42         0.36                -0.26     -0.1  0.4333333         -0.3133333\n43         0.36                -0.26     -0.1  0.4333333         -0.3133333\n44        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n45         0.36                -0.26     -0.1  0.4333333         -0.3133333\n46         0.36                -0.26     -0.1  0.4333333         -0.3133333\n47         0.36                -0.26     -0.1  0.4333333         -0.3133333\n48        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n49         0.36                -0.26     -0.1 -0.5666667          0.6866667\n50        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n51        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n52         0.36                -0.26     -0.1 -0.5666667          0.6866667\n53        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n54         0.36                -0.26     -0.1  0.4333333         -0.3133333\n55         0.36                -0.26     -0.1  0.4333333         -0.3133333\n56         0.36                -0.26     -0.1 -0.5666667          0.6866667\n57         0.36                -0.26     -0.1  0.4333333         -0.3133333\n58        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n59        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n60         0.36                -0.26     -0.1 -0.5666667          0.6866667\n61        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n62        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n63         0.36                -0.26     -0.1  0.4333333         -0.3133333\n64        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n65         0.36                -0.26     -0.1 -0.5666667          0.6866667\n66        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n67        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n68        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n69         0.36                -0.26     -0.1  0.4333333         -0.3133333\n70         0.36                -0.26     -0.1  0.4333333         -0.3133333\n71         0.36                -0.26     -0.1  0.4333333         -0.3133333\n72        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n73         0.36                -0.26     -0.1  0.4333333         -0.3133333\n74        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n75         0.36                -0.26     -0.1  0.4333333         -0.3133333\n76         0.36                -0.26     -0.1  0.4333333         -0.3133333\n77         0.36                -0.26     -0.1  0.4333333         -0.3133333\n78         0.36                -0.26     -0.1 -0.5666667          0.6866667\n79        -0.64                -0.26      0.9  0.4333333         -0.3133333\n80         0.36                -0.26     -0.1 -0.5666667          0.6866667\n81         0.36                -0.26     -0.1  0.4333333         -0.3133333\n82         0.36                -0.26     -0.1 -0.5666667         -0.3133333\n83        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n84         0.36                -0.26     -0.1  0.4333333         -0.3133333\n85         0.36                -0.26     -0.1  0.4333333         -0.3133333\n86         0.36                -0.26     -0.1  0.4333333         -0.3133333\n87        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n88         0.36                -0.26     -0.1  0.4333333         -0.3133333\n89        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n90         0.36                -0.26     -0.1 -0.5666667          0.6866667\n91         0.36                -0.26     -0.1 -0.5666667          0.6866667\n92         0.36                -0.26     -0.1 -0.5666667          0.6866667\n93         0.36                -0.26     -0.1  0.4333333         -0.3133333\n94         0.36                -0.26     -0.1 -0.5666667         -0.3133333\n95        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n96         0.36                -0.26     -0.1 -0.5666667          0.6866667\n97         0.36                -0.26     -0.1  0.4333333         -0.3133333\n98         0.36                -0.26     -0.1  0.4333333         -0.3133333\n99        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n100       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n101        0.36                -0.26     -0.1  0.4333333         -0.3133333\n102        0.36                -0.26     -0.1 -0.5666667          0.6866667\n103       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n104        0.36                -0.26     -0.1  0.4333333         -0.3133333\n105        0.36                -0.26     -0.1  0.4333333         -0.3133333\n106        0.36                -0.26     -0.1  0.4333333         -0.3133333\n107        0.36                -0.26     -0.1  0.4333333         -0.3133333\n108        0.36                -0.26     -0.1 -0.5666667          0.6866667\n109       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n110       -0.64                -0.26      0.9 -0.5666667          0.6866667\n111        0.36                -0.26     -0.1  0.4333333         -0.3133333\n112       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n113       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n114        0.36                -0.26     -0.1  0.4333333         -0.3133333\n115        0.36                -0.26     -0.1  0.4333333         -0.3133333\n116        0.36                -0.26     -0.1  0.4333333         -0.3133333\n117        0.36                -0.26     -0.1  0.4333333         -0.3133333\n118        0.36                -0.26     -0.1  0.4333333         -0.3133333\n119        0.36                -0.26     -0.1 -0.5666667          0.6866667\n120       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n121        0.36                -0.26     -0.1  0.4333333         -0.3133333\n122       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n123        0.36                -0.26     -0.1  0.4333333         -0.3133333\n124        0.36                -0.26     -0.1  0.4333333         -0.3133333\n125        0.36                -0.26     -0.1  0.4333333         -0.3133333\n126        0.36                -0.26     -0.1  0.4333333         -0.3133333\n127       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n128        0.36                -0.26     -0.1 -0.5666667          0.6866667\n129        0.36                -0.26     -0.1  0.4333333         -0.3133333\n130        0.36                -0.26     -0.1  0.4333333         -0.3133333\n131        0.36                -0.26     -0.1  0.4333333         -0.3133333\n132        0.36                -0.26     -0.1  0.4333333         -0.3133333\n133       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n134        0.36                -0.26     -0.1  0.4333333         -0.3133333\n135        0.36                -0.26     -0.1  0.4333333         -0.3133333\n136       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n137        0.36                -0.26     -0.1  0.4333333         -0.3133333\n138        0.36                -0.26     -0.1  0.4333333         -0.3133333\n139        0.36                -0.26     -0.1  0.4333333         -0.3133333\n140        0.36                -0.26     -0.1  0.4333333         -0.3133333\n141        0.36                -0.26     -0.1  0.4333333         -0.3133333\n142        0.36                -0.26     -0.1  0.4333333         -0.3133333\n143        0.36                -0.26     -0.1  0.4333333         -0.3133333\n144        0.36                -0.26     -0.1  0.4333333         -0.3133333\n145        0.36                -0.26     -0.1  0.4333333         -0.3133333\n146        0.36                -0.26     -0.1  0.4333333         -0.3133333\n147        0.36                -0.26     -0.1  0.4333333         -0.3133333\n148       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n149       -0.64                -0.26      0.9  0.4333333         -0.3133333\n150        0.36                -0.26     -0.1  0.4333333         -0.3133333\n151        0.36                -0.26     -0.1 -0.5666667          0.6866667\n152        0.36                -0.26     -0.1  0.4333333         -0.3133333\n153        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n154        0.36                -0.26     -0.1  0.4333333         -0.3133333\n155        0.36                -0.26     -0.1  0.4333333         -0.3133333\n156        0.36                -0.26     -0.1  0.4333333         -0.3133333\n157        0.36                -0.26     -0.1  0.4333333         -0.3133333\n158        0.36                -0.26     -0.1  0.4333333         -0.3133333\n159       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n160       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n161        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n162        0.36                -0.26     -0.1  0.4333333         -0.3133333\n163        0.36                -0.26     -0.1 -0.5666667          0.6866667\n164        0.36                -0.26     -0.1 -0.5666667          0.6866667\n165        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n166        0.36                -0.26     -0.1  0.4333333         -0.3133333\n167        0.36                -0.26     -0.1  0.4333333         -0.3133333\n168       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n169        0.36                -0.26     -0.1  0.4333333         -0.3133333\n170        0.36                -0.26     -0.1  0.4333333         -0.3133333\n171       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n172       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n173        0.36                -0.26     -0.1 -0.5666667          0.6866667\n174        0.36                -0.26     -0.1  0.4333333         -0.3133333\n175        0.36                -0.26     -0.1  0.4333333         -0.3133333\n176        0.36                -0.26     -0.1  0.4333333         -0.3133333\n177        0.36                -0.26     -0.1  0.4333333         -0.3133333\n178        0.36                -0.26     -0.1 -0.5666667          0.6866667\n179        0.36                -0.26     -0.1  0.4333333         -0.3133333\n180        0.36                -0.26     -0.1 -0.5666667          0.6866667\n181        0.36                -0.26     -0.1  0.4333333         -0.3133333\n182       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n183        0.36                -0.26     -0.1  0.4333333         -0.3133333\n184        0.36                -0.26     -0.1  0.4333333         -0.3133333\n185        0.36                -0.26     -0.1 -0.5666667          0.6866667\n186        0.36                -0.26     -0.1  0.4333333         -0.3133333\n187        0.36                -0.26     -0.1  0.4333333         -0.3133333\n188        0.36                -0.26     -0.1  0.4333333         -0.3133333\n189        0.36                -0.26     -0.1 -0.5666667          0.6866667\n190       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n191       -0.64                -0.26      0.9 -0.5666667          0.6866667\n192        0.36                -0.26     -0.1 -0.5666667          0.6866667\n193        0.36                -0.26     -0.1  0.4333333         -0.3133333\n194        0.36                -0.26     -0.1 -0.5666667          0.6866667\n195       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n196        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n197        0.36                -0.26     -0.1  0.4333333         -0.3133333\n198       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n199       -0.64                -0.26      0.9  0.4333333         -0.3133333\n200        0.36                -0.26     -0.1  0.4333333         -0.3133333\n201       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n202       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n203       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n204        0.36                -0.26     -0.1  0.4333333         -0.3133333\n205        0.36                -0.26     -0.1  0.4333333         -0.3133333\n206        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n207       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n208       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n209        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n210        0.36                -0.26     -0.1  0.4333333         -0.3133333\n211       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n212       -0.64                -0.26      0.9  0.4333333         -0.3133333\n213        0.36                -0.26     -0.1  0.4333333         -0.3133333\n214       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n215        0.36                -0.26     -0.1  0.4333333         -0.3133333\n216        0.36                -0.26     -0.1  0.4333333         -0.3133333\n217        0.36                -0.26     -0.1 -0.5666667          0.6866667\n218        0.36                -0.26     -0.1  0.4333333         -0.3133333\n219        0.36                -0.26     -0.1  0.4333333         -0.3133333\n220       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n221        0.36                -0.26     -0.1 -0.5666667          0.6866667\n222       -0.64                -0.26      0.9 -0.5666667          0.6866667\n223        0.36                -0.26     -0.1  0.4333333         -0.3133333\n224       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n225       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n226        0.36                -0.26     -0.1  0.4333333         -0.3133333\n227       -0.64                -0.26      0.9 -0.5666667          0.6866667\n228        0.36                -0.26     -0.1  0.4333333         -0.3133333\n229       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n230        0.36                -0.26     -0.1  0.4333333         -0.3133333\n231        0.36                -0.26     -0.1 -0.5666667          0.6866667\n232        0.36                -0.26     -0.1  0.4333333         -0.3133333\n233       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n234       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n235        0.36                -0.26     -0.1 -0.5666667          0.6866667\n236        0.36                -0.26     -0.1  0.4333333         -0.3133333\n237        0.36                -0.26     -0.1  0.4333333         -0.3133333\n238       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n239       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n240       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n241       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n242        0.36                -0.26     -0.1 -0.5666667          0.6866667\n243       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n244       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n245        0.36                -0.26     -0.1  0.4333333         -0.3133333\n246       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n247        0.36                -0.26     -0.1  0.4333333         -0.3133333\n248       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n249       -0.64                -0.26      0.9 -0.5666667          0.6866667\n250        0.36                -0.26     -0.1  0.4333333         -0.3133333\n251       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n252       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n253       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n254        0.36                -0.26     -0.1  0.4333333         -0.3133333\n255        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n256        0.36                -0.26     -0.1  0.4333333         -0.3133333\n257        0.36                -0.26     -0.1  0.4333333         -0.3133333\n258        0.36                -0.26     -0.1  0.4333333         -0.3133333\n259       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n260        0.36                -0.26     -0.1 -0.5666667          0.6866667\n261       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n262        0.36                -0.26     -0.1  0.4333333         -0.3133333\n263        0.36                -0.26     -0.1  0.4333333         -0.3133333\n264       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n265       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n266        0.36                -0.26     -0.1 -0.5666667          0.6866667\n267        0.36                -0.26     -0.1 -0.5666667          0.6866667\n268       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n269       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n270       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n271       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n272       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n273       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n274        0.36                -0.26     -0.1  0.4333333         -0.3133333\n275        0.36                -0.26     -0.1  0.4333333         -0.3133333\n276        0.36                -0.26     -0.1  0.4333333         -0.3133333\n277       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n278       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n279        0.36                -0.26     -0.1 -0.5666667          0.6866667\n280        0.36                -0.26     -0.1  0.4333333         -0.3133333\n281        0.36                -0.26     -0.1  0.4333333         -0.3133333\n282        0.36                -0.26     -0.1  0.4333333         -0.3133333\n283       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n284        0.36                -0.26     -0.1  0.4333333         -0.3133333\n285        0.36                -0.26     -0.1  0.4333333         -0.3133333\n286        0.36                -0.26     -0.1  0.4333333         -0.3133333\n287       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n288        0.36                -0.26     -0.1  0.4333333         -0.3133333\n289       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n290        0.36                -0.26     -0.1  0.4333333         -0.3133333\n291        0.36                -0.26     -0.1 -0.5666667          0.6866667\n292        0.36                -0.26     -0.1  0.4333333         -0.3133333\n293        0.36                -0.26     -0.1  0.4333333         -0.3133333\n294        0.36                -0.26     -0.1  0.4333333         -0.3133333\n295       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n296        0.36                -0.26     -0.1  0.4333333         -0.3133333\n297       -0.64                -0.26      0.9 -0.5666667          0.6866667\n298        0.36                -0.26     -0.1  0.4333333         -0.3133333\n299       -0.64                -0.26      0.9  0.4333333         -0.3133333\n300        0.36                -0.26     -0.1  0.4333333         -0.3133333\n    unpackaged      black  Earl Grey green\n1        -0.12  0.7533333 -0.6433333 -0.11\n2        -0.12  0.7533333 -0.6433333 -0.11\n3        -0.12 -0.2466667  0.3566667 -0.11\n4        -0.12 -0.2466667  0.3566667 -0.11\n5        -0.12 -0.2466667  0.3566667 -0.11\n6        -0.12 -0.2466667  0.3566667 -0.11\n7        -0.12 -0.2466667  0.3566667 -0.11\n8        -0.12  0.7533333 -0.6433333 -0.11\n9        -0.12 -0.2466667  0.3566667 -0.11\n10       -0.12  0.7533333 -0.6433333 -0.11\n11       -0.12 -0.2466667  0.3566667 -0.11\n12       -0.12 -0.2466667  0.3566667 -0.11\n13       -0.12 -0.2466667  0.3566667 -0.11\n14       -0.12  0.7533333 -0.6433333 -0.11\n15       -0.12  0.7533333 -0.6433333 -0.11\n16        0.88 -0.2466667  0.3566667 -0.11\n17       -0.12  0.7533333 -0.6433333 -0.11\n18       -0.12 -0.2466667  0.3566667 -0.11\n19       -0.12  0.7533333 -0.6433333 -0.11\n20       -0.12  0.7533333 -0.6433333 -0.11\n21       -0.12 -0.2466667  0.3566667 -0.11\n22       -0.12  0.7533333 -0.6433333 -0.11\n23       -0.12 -0.2466667  0.3566667 -0.11\n24       -0.12  0.7533333 -0.6433333 -0.11\n25        0.88 -0.2466667  0.3566667 -0.11\n26       -0.12 -0.2466667  0.3566667 -0.11\n27       -0.12 -0.2466667  0.3566667 -0.11\n28       -0.12 -0.2466667  0.3566667 -0.11\n29       -0.12  0.7533333 -0.6433333 -0.11\n30       -0.12 -0.2466667  0.3566667 -0.11\n31        0.88 -0.2466667  0.3566667 -0.11\n32       -0.12 -0.2466667  0.3566667 -0.11\n33       -0.12 -0.2466667  0.3566667 -0.11\n34       -0.12  0.7533333 -0.6433333 -0.11\n35       -0.12  0.7533333 -0.6433333 -0.11\n36       -0.12 -0.2466667  0.3566667 -0.11\n37       -0.12 -0.2466667 -0.6433333  0.89\n38       -0.12 -0.2466667 -0.6433333  0.89\n39       -0.12 -0.2466667  0.3566667 -0.11\n40       -0.12 -0.2466667 -0.6433333  0.89\n41       -0.12 -0.2466667  0.3566667 -0.11\n42       -0.12 -0.2466667 -0.6433333  0.89\n43       -0.12 -0.2466667  0.3566667 -0.11\n44       -0.12  0.7533333 -0.6433333 -0.11\n45       -0.12 -0.2466667  0.3566667 -0.11\n46       -0.12 -0.2466667  0.3566667 -0.11\n47       -0.12 -0.2466667  0.3566667 -0.11\n48       -0.12 -0.2466667  0.3566667 -0.11\n49       -0.12 -0.2466667  0.3566667 -0.11\n50       -0.12  0.7533333 -0.6433333 -0.11\n51       -0.12 -0.2466667  0.3566667 -0.11\n52       -0.12  0.7533333 -0.6433333 -0.11\n53        0.88 -0.2466667  0.3566667 -0.11\n54       -0.12 -0.2466667  0.3566667 -0.11\n55       -0.12 -0.2466667 -0.6433333  0.89\n56       -0.12 -0.2466667  0.3566667 -0.11\n57       -0.12 -0.2466667 -0.6433333  0.89\n58       -0.12 -0.2466667  0.3566667 -0.11\n59       -0.12 -0.2466667 -0.6433333  0.89\n60       -0.12  0.7533333 -0.6433333 -0.11\n61       -0.12 -0.2466667  0.3566667 -0.11\n62        0.88 -0.2466667  0.3566667 -0.11\n63       -0.12 -0.2466667  0.3566667 -0.11\n64       -0.12  0.7533333 -0.6433333 -0.11\n65       -0.12 -0.2466667  0.3566667 -0.11\n66       -0.12  0.7533333 -0.6433333 -0.11\n67       -0.12 -0.2466667  0.3566667 -0.11\n68       -0.12 -0.2466667  0.3566667 -0.11\n69       -0.12 -0.2466667  0.3566667 -0.11\n70       -0.12 -0.2466667  0.3566667 -0.11\n71       -0.12 -0.2466667  0.3566667 -0.11\n72       -0.12 -0.2466667  0.3566667 -0.11\n73       -0.12 -0.2466667  0.3566667 -0.11\n74        0.88 -0.2466667  0.3566667 -0.11\n75       -0.12  0.7533333 -0.6433333 -0.11\n76       -0.12 -0.2466667  0.3566667 -0.11\n77       -0.12 -0.2466667  0.3566667 -0.11\n78       -0.12 -0.2466667  0.3566667 -0.11\n79       -0.12 -0.2466667  0.3566667 -0.11\n80       -0.12 -0.2466667  0.3566667 -0.11\n81       -0.12  0.7533333 -0.6433333 -0.11\n82        0.88 -0.2466667  0.3566667 -0.11\n83       -0.12 -0.2466667  0.3566667 -0.11\n84       -0.12 -0.2466667  0.3566667 -0.11\n85       -0.12 -0.2466667  0.3566667 -0.11\n86       -0.12 -0.2466667  0.3566667 -0.11\n87       -0.12 -0.2466667  0.3566667 -0.11\n88       -0.12 -0.2466667  0.3566667 -0.11\n89       -0.12 -0.2466667  0.3566667 -0.11\n90       -0.12 -0.2466667  0.3566667 -0.11\n91       -0.12  0.7533333 -0.6433333 -0.11\n92       -0.12 -0.2466667  0.3566667 -0.11\n93       -0.12  0.7533333 -0.6433333 -0.11\n94        0.88 -0.2466667  0.3566667 -0.11\n95        0.88 -0.2466667  0.3566667 -0.11\n96       -0.12  0.7533333 -0.6433333 -0.11\n97       -0.12 -0.2466667  0.3566667 -0.11\n98       -0.12 -0.2466667  0.3566667 -0.11\n99       -0.12  0.7533333 -0.6433333 -0.11\n100       0.88 -0.2466667  0.3566667 -0.11\n101      -0.12 -0.2466667  0.3566667 -0.11\n102      -0.12 -0.2466667 -0.6433333  0.89\n103      -0.12 -0.2466667  0.3566667 -0.11\n104      -0.12 -0.2466667  0.3566667 -0.11\n105      -0.12 -0.2466667  0.3566667 -0.11\n106      -0.12 -0.2466667  0.3566667 -0.11\n107      -0.12 -0.2466667  0.3566667 -0.11\n108      -0.12 -0.2466667  0.3566667 -0.11\n109      -0.12 -0.2466667  0.3566667 -0.11\n110      -0.12 -0.2466667  0.3566667 -0.11\n111      -0.12 -0.2466667  0.3566667 -0.11\n112      -0.12 -0.2466667  0.3566667 -0.11\n113      -0.12 -0.2466667  0.3566667 -0.11\n114      -0.12 -0.2466667  0.3566667 -0.11\n115      -0.12 -0.2466667  0.3566667 -0.11\n116      -0.12 -0.2466667  0.3566667 -0.11\n117      -0.12 -0.2466667  0.3566667 -0.11\n118      -0.12 -0.2466667  0.3566667 -0.11\n119      -0.12 -0.2466667  0.3566667 -0.11\n120      -0.12 -0.2466667  0.3566667 -0.11\n121      -0.12 -0.2466667  0.3566667 -0.11\n122      -0.12 -0.2466667  0.3566667 -0.11\n123      -0.12 -0.2466667  0.3566667 -0.11\n124      -0.12 -0.2466667  0.3566667 -0.11\n125      -0.12 -0.2466667  0.3566667 -0.11\n126      -0.12 -0.2466667  0.3566667 -0.11\n127      -0.12  0.7533333 -0.6433333 -0.11\n128      -0.12  0.7533333 -0.6433333 -0.11\n129      -0.12 -0.2466667  0.3566667 -0.11\n130      -0.12 -0.2466667  0.3566667 -0.11\n131      -0.12 -0.2466667  0.3566667 -0.11\n132      -0.12  0.7533333 -0.6433333 -0.11\n133      -0.12 -0.2466667  0.3566667 -0.11\n134      -0.12  0.7533333 -0.6433333 -0.11\n135      -0.12  0.7533333 -0.6433333 -0.11\n136      -0.12 -0.2466667  0.3566667 -0.11\n137      -0.12 -0.2466667  0.3566667 -0.11\n138      -0.12 -0.2466667  0.3566667 -0.11\n139      -0.12 -0.2466667  0.3566667 -0.11\n140      -0.12 -0.2466667  0.3566667 -0.11\n141      -0.12 -0.2466667  0.3566667 -0.11\n142      -0.12 -0.2466667  0.3566667 -0.11\n143      -0.12 -0.2466667  0.3566667 -0.11\n144      -0.12 -0.2466667  0.3566667 -0.11\n145      -0.12 -0.2466667  0.3566667 -0.11\n146      -0.12 -0.2466667  0.3566667 -0.11\n147      -0.12 -0.2466667  0.3566667 -0.11\n148      -0.12  0.7533333 -0.6433333 -0.11\n149      -0.12 -0.2466667  0.3566667 -0.11\n150      -0.12 -0.2466667  0.3566667 -0.11\n151      -0.12  0.7533333 -0.6433333 -0.11\n152      -0.12 -0.2466667  0.3566667 -0.11\n153       0.88  0.7533333 -0.6433333 -0.11\n154      -0.12 -0.2466667 -0.6433333  0.89\n155      -0.12 -0.2466667  0.3566667 -0.11\n156      -0.12  0.7533333 -0.6433333 -0.11\n157      -0.12 -0.2466667  0.3566667 -0.11\n158      -0.12 -0.2466667  0.3566667 -0.11\n159       0.88  0.7533333 -0.6433333 -0.11\n160      -0.12  0.7533333 -0.6433333 -0.11\n161       0.88  0.7533333 -0.6433333 -0.11\n162      -0.12  0.7533333 -0.6433333 -0.11\n163      -0.12 -0.2466667 -0.6433333  0.89\n164      -0.12  0.7533333 -0.6433333 -0.11\n165       0.88 -0.2466667 -0.6433333  0.89\n166      -0.12 -0.2466667  0.3566667 -0.11\n167      -0.12 -0.2466667 -0.6433333  0.89\n168       0.88  0.7533333 -0.6433333 -0.11\n169      -0.12 -0.2466667  0.3566667 -0.11\n170      -0.12 -0.2466667  0.3566667 -0.11\n171       0.88 -0.2466667  0.3566667 -0.11\n172      -0.12 -0.2466667  0.3566667 -0.11\n173      -0.12  0.7533333 -0.6433333 -0.11\n174      -0.12 -0.2466667  0.3566667 -0.11\n175      -0.12 -0.2466667  0.3566667 -0.11\n176      -0.12 -0.2466667  0.3566667 -0.11\n177      -0.12 -0.2466667  0.3566667 -0.11\n178      -0.12 -0.2466667  0.3566667 -0.11\n179      -0.12 -0.2466667  0.3566667 -0.11\n180      -0.12 -0.2466667 -0.6433333  0.89\n181      -0.12  0.7533333 -0.6433333 -0.11\n182       0.88  0.7533333 -0.6433333 -0.11\n183      -0.12  0.7533333 -0.6433333 -0.11\n184      -0.12 -0.2466667  0.3566667 -0.11\n185      -0.12 -0.2466667  0.3566667 -0.11\n186      -0.12 -0.2466667 -0.6433333  0.89\n187      -0.12 -0.2466667 -0.6433333  0.89\n188      -0.12 -0.2466667 -0.6433333  0.89\n189      -0.12 -0.2466667 -0.6433333  0.89\n190       0.88 -0.2466667 -0.6433333  0.89\n191      -0.12 -0.2466667  0.3566667 -0.11\n192      -0.12 -0.2466667  0.3566667 -0.11\n193      -0.12 -0.2466667  0.3566667 -0.11\n194      -0.12 -0.2466667  0.3566667 -0.11\n195       0.88 -0.2466667 -0.6433333  0.89\n196       0.88  0.7533333 -0.6433333 -0.11\n197      -0.12 -0.2466667  0.3566667 -0.11\n198      -0.12 -0.2466667  0.3566667 -0.11\n199      -0.12 -0.2466667 -0.6433333  0.89\n200      -0.12 -0.2466667 -0.6433333  0.89\n201      -0.12 -0.2466667  0.3566667 -0.11\n202       0.88  0.7533333 -0.6433333 -0.11\n203      -0.12 -0.2466667  0.3566667 -0.11\n204      -0.12 -0.2466667  0.3566667 -0.11\n205      -0.12 -0.2466667 -0.6433333  0.89\n206       0.88  0.7533333 -0.6433333 -0.11\n207      -0.12  0.7533333 -0.6433333 -0.11\n208       0.88  0.7533333 -0.6433333 -0.11\n209       0.88 -0.2466667 -0.6433333  0.89\n210      -0.12 -0.2466667  0.3566667 -0.11\n211       0.88  0.7533333 -0.6433333 -0.11\n212      -0.12 -0.2466667 -0.6433333  0.89\n213      -0.12  0.7533333 -0.6433333 -0.11\n214      -0.12 -0.2466667  0.3566667 -0.11\n215      -0.12 -0.2466667  0.3566667 -0.11\n216      -0.12  0.7533333 -0.6433333 -0.11\n217      -0.12  0.7533333 -0.6433333 -0.11\n218      -0.12 -0.2466667  0.3566667 -0.11\n219      -0.12 -0.2466667  0.3566667 -0.11\n220       0.88 -0.2466667  0.3566667 -0.11\n221      -0.12 -0.2466667  0.3566667 -0.11\n222      -0.12 -0.2466667 -0.6433333  0.89\n223      -0.12 -0.2466667  0.3566667 -0.11\n224      -0.12 -0.2466667  0.3566667 -0.11\n225      -0.12  0.7533333 -0.6433333 -0.11\n226      -0.12 -0.2466667 -0.6433333  0.89\n227      -0.12 -0.2466667 -0.6433333  0.89\n228      -0.12  0.7533333 -0.6433333 -0.11\n229       0.88 -0.2466667 -0.6433333  0.89\n230      -0.12 -0.2466667  0.3566667 -0.11\n231      -0.12  0.7533333 -0.6433333 -0.11\n232      -0.12 -0.2466667  0.3566667 -0.11\n233      -0.12 -0.2466667  0.3566667 -0.11\n234      -0.12 -0.2466667  0.3566667 -0.11\n235      -0.12 -0.2466667  0.3566667 -0.11\n236      -0.12 -0.2466667  0.3566667 -0.11\n237      -0.12 -0.2466667  0.3566667 -0.11\n238       0.88 -0.2466667  0.3566667 -0.11\n239      -0.12 -0.2466667  0.3566667 -0.11\n240      -0.12 -0.2466667  0.3566667 -0.11\n241      -0.12 -0.2466667  0.3566667 -0.11\n242      -0.12 -0.2466667  0.3566667 -0.11\n243      -0.12 -0.2466667 -0.6433333  0.89\n244      -0.12 -0.2466667  0.3566667 -0.11\n245      -0.12 -0.2466667  0.3566667 -0.11\n246      -0.12 -0.2466667  0.3566667 -0.11\n247      -0.12  0.7533333 -0.6433333 -0.11\n248       0.88 -0.2466667  0.3566667 -0.11\n249      -0.12 -0.2466667  0.3566667 -0.11\n250      -0.12 -0.2466667  0.3566667 -0.11\n251      -0.12 -0.2466667  0.3566667 -0.11\n252      -0.12 -0.2466667  0.3566667 -0.11\n253      -0.12 -0.2466667  0.3566667 -0.11\n254      -0.12 -0.2466667  0.3566667 -0.11\n255       0.88 -0.2466667  0.3566667 -0.11\n256      -0.12  0.7533333 -0.6433333 -0.11\n257      -0.12  0.7533333 -0.6433333 -0.11\n258      -0.12 -0.2466667 -0.6433333  0.89\n259      -0.12 -0.2466667  0.3566667 -0.11\n260      -0.12 -0.2466667  0.3566667 -0.11\n261       0.88  0.7533333 -0.6433333 -0.11\n262      -0.12 -0.2466667 -0.6433333  0.89\n263      -0.12  0.7533333 -0.6433333 -0.11\n264      -0.12 -0.2466667  0.3566667 -0.11\n265      -0.12 -0.2466667  0.3566667 -0.11\n266      -0.12 -0.2466667  0.3566667 -0.11\n267      -0.12  0.7533333 -0.6433333 -0.11\n268      -0.12 -0.2466667  0.3566667 -0.11\n269      -0.12  0.7533333 -0.6433333 -0.11\n270      -0.12 -0.2466667  0.3566667 -0.11\n271       0.88  0.7533333 -0.6433333 -0.11\n272       0.88  0.7533333 -0.6433333 -0.11\n273      -0.12 -0.2466667  0.3566667 -0.11\n274      -0.12 -0.2466667  0.3566667 -0.11\n275      -0.12  0.7533333 -0.6433333 -0.11\n276      -0.12 -0.2466667  0.3566667 -0.11\n277       0.88  0.7533333 -0.6433333 -0.11\n278       0.88  0.7533333 -0.6433333 -0.11\n279      -0.12  0.7533333 -0.6433333 -0.11\n280      -0.12 -0.2466667  0.3566667 -0.11\n281      -0.12 -0.2466667  0.3566667 -0.11\n282      -0.12 -0.2466667  0.3566667 -0.11\n283      -0.12 -0.2466667  0.3566667 -0.11\n284      -0.12  0.7533333 -0.6433333 -0.11\n285      -0.12 -0.2466667  0.3566667 -0.11\n286      -0.12 -0.2466667  0.3566667 -0.11\n287       0.88 -0.2466667  0.3566667 -0.11\n288      -0.12  0.7533333 -0.6433333 -0.11\n289      -0.12 -0.2466667  0.3566667 -0.11\n290      -0.12 -0.2466667  0.3566667 -0.11\n291      -0.12 -0.2466667  0.3566667 -0.11\n292      -0.12 -0.2466667  0.3566667 -0.11\n293      -0.12 -0.2466667  0.3566667 -0.11\n294      -0.12 -0.2466667  0.3566667 -0.11\n295      -0.12 -0.2466667  0.3566667 -0.11\n296      -0.12 -0.2466667 -0.6433333  0.89\n297      -0.12 -0.2466667 -0.6433333  0.89\n298      -0.12 -0.2466667  0.3566667 -0.11\n299      -0.12  0.7533333 -0.6433333 -0.11\n300      -0.12  0.7533333 -0.6433333 -0.11\n```\n:::\n\n```{.r .cell-code}\n# MCA based on Chavent Et Al 2017 et al 2017 p. 505 (p. 5 of pdf) -----------1  ---\n\n    # Work with categorical predictors from the tea dataset\n    x <- tea[, c(\"where\", \"how\", \"Tea\")]\n\n    # Define Z (the disjunctive table)\n    G <- tab.disjonctif(x)\n\n    # Define row weights\n    n <- nrow(x)\n    N <- diag(1 / n, n)\n\n    # Define column weights\n    M <- diag(n / colSums(G))\n    solve(D_sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        [,1]     [,2] [,3]     [,4]     [,5]     [,6]     [,7]     [,8]\n [1,] 1.5625 0.000000    0 0.000000 0.000000 0.000000 0.000000 0.000000\n [2,] 0.0000 3.846154    0 0.000000 0.000000 0.000000 0.000000 0.000000\n [3,] 0.0000 0.000000   10 0.000000 0.000000 0.000000 0.000000 0.000000\n [4,] 0.0000 0.000000    0 1.764706 0.000000 0.000000 0.000000 0.000000\n [5,] 0.0000 0.000000    0 0.000000 3.191489 0.000000 0.000000 0.000000\n [6,] 0.0000 0.000000    0 0.000000 0.000000 8.333333 0.000000 0.000000\n [7,] 0.0000 0.000000    0 0.000000 0.000000 0.000000 4.054054 0.000000\n [8,] 0.0000 0.000000    0 0.000000 0.000000 0.000000 0.000000 1.554404\n [9,] 0.0000 0.000000    0 0.000000 0.000000 0.000000 0.000000 0.000000\n          [,9]\n [1,] 0.000000\n [2,] 0.000000\n [3,] 0.000000\n [4,] 0.000000\n [5,] 0.000000\n [6,] 0.000000\n [7,] 0.000000\n [8,] 0.000000\n [9,] 9.090909\n```\n:::\n\n```{.r .cell-code}\n    # Create Z, the centered G?\n    plxk <- colMeans(G)\n    G - matrix(rep(plxk, I), nrow = I, byrow = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    chain store chain store+tea shop tea shop    tea bag tea bag+unpackaged\n1          0.36                -0.26     -0.1  0.4333333         -0.3133333\n2          0.36                -0.26     -0.1  0.4333333         -0.3133333\n3          0.36                -0.26     -0.1  0.4333333         -0.3133333\n4          0.36                -0.26     -0.1  0.4333333         -0.3133333\n5          0.36                -0.26     -0.1  0.4333333         -0.3133333\n6          0.36                -0.26     -0.1  0.4333333         -0.3133333\n7          0.36                -0.26     -0.1  0.4333333         -0.3133333\n8          0.36                -0.26     -0.1  0.4333333         -0.3133333\n9         -0.64                 0.74     -0.1 -0.5666667          0.6866667\n10        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n11         0.36                -0.26     -0.1  0.4333333         -0.3133333\n12         0.36                -0.26     -0.1  0.4333333         -0.3133333\n13        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n14         0.36                -0.26     -0.1  0.4333333         -0.3133333\n15        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n16        -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n17        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n18        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n19         0.36                -0.26     -0.1  0.4333333         -0.3133333\n20         0.36                -0.26     -0.1  0.4333333         -0.3133333\n21        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n22        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n23         0.36                -0.26     -0.1  0.4333333         -0.3133333\n24         0.36                -0.26     -0.1  0.4333333         -0.3133333\n25        -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n26        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n27         0.36                -0.26     -0.1  0.4333333         -0.3133333\n28         0.36                -0.26     -0.1 -0.5666667          0.6866667\n29         0.36                -0.26     -0.1  0.4333333         -0.3133333\n30         0.36                -0.26     -0.1  0.4333333         -0.3133333\n31        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n32        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n33        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n34         0.36                -0.26     -0.1  0.4333333         -0.3133333\n35        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n36         0.36                -0.26     -0.1  0.4333333         -0.3133333\n37         0.36                -0.26     -0.1 -0.5666667          0.6866667\n38         0.36                -0.26     -0.1  0.4333333         -0.3133333\n39        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n40        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n41         0.36                -0.26     -0.1  0.4333333         -0.3133333\n42         0.36                -0.26     -0.1  0.4333333         -0.3133333\n43         0.36                -0.26     -0.1  0.4333333         -0.3133333\n44        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n45         0.36                -0.26     -0.1  0.4333333         -0.3133333\n46         0.36                -0.26     -0.1  0.4333333         -0.3133333\n47         0.36                -0.26     -0.1  0.4333333         -0.3133333\n48        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n49         0.36                -0.26     -0.1 -0.5666667          0.6866667\n50        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n51        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n52         0.36                -0.26     -0.1 -0.5666667          0.6866667\n53        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n54         0.36                -0.26     -0.1  0.4333333         -0.3133333\n55         0.36                -0.26     -0.1  0.4333333         -0.3133333\n56         0.36                -0.26     -0.1 -0.5666667          0.6866667\n57         0.36                -0.26     -0.1  0.4333333         -0.3133333\n58        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n59        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n60         0.36                -0.26     -0.1 -0.5666667          0.6866667\n61        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n62        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n63         0.36                -0.26     -0.1  0.4333333         -0.3133333\n64        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n65         0.36                -0.26     -0.1 -0.5666667          0.6866667\n66        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n67        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n68        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n69         0.36                -0.26     -0.1  0.4333333         -0.3133333\n70         0.36                -0.26     -0.1  0.4333333         -0.3133333\n71         0.36                -0.26     -0.1  0.4333333         -0.3133333\n72        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n73         0.36                -0.26     -0.1  0.4333333         -0.3133333\n74        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n75         0.36                -0.26     -0.1  0.4333333         -0.3133333\n76         0.36                -0.26     -0.1  0.4333333         -0.3133333\n77         0.36                -0.26     -0.1  0.4333333         -0.3133333\n78         0.36                -0.26     -0.1 -0.5666667          0.6866667\n79        -0.64                -0.26      0.9  0.4333333         -0.3133333\n80         0.36                -0.26     -0.1 -0.5666667          0.6866667\n81         0.36                -0.26     -0.1  0.4333333         -0.3133333\n82         0.36                -0.26     -0.1 -0.5666667         -0.3133333\n83        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n84         0.36                -0.26     -0.1  0.4333333         -0.3133333\n85         0.36                -0.26     -0.1  0.4333333         -0.3133333\n86         0.36                -0.26     -0.1  0.4333333         -0.3133333\n87        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n88         0.36                -0.26     -0.1  0.4333333         -0.3133333\n89        -0.64                 0.74     -0.1  0.4333333         -0.3133333\n90         0.36                -0.26     -0.1 -0.5666667          0.6866667\n91         0.36                -0.26     -0.1 -0.5666667          0.6866667\n92         0.36                -0.26     -0.1 -0.5666667          0.6866667\n93         0.36                -0.26     -0.1  0.4333333         -0.3133333\n94         0.36                -0.26     -0.1 -0.5666667         -0.3133333\n95        -0.64                -0.26      0.9 -0.5666667         -0.3133333\n96         0.36                -0.26     -0.1 -0.5666667          0.6866667\n97         0.36                -0.26     -0.1  0.4333333         -0.3133333\n98         0.36                -0.26     -0.1  0.4333333         -0.3133333\n99        -0.64                 0.74     -0.1 -0.5666667          0.6866667\n100       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n101        0.36                -0.26     -0.1  0.4333333         -0.3133333\n102        0.36                -0.26     -0.1 -0.5666667          0.6866667\n103       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n104        0.36                -0.26     -0.1  0.4333333         -0.3133333\n105        0.36                -0.26     -0.1  0.4333333         -0.3133333\n106        0.36                -0.26     -0.1  0.4333333         -0.3133333\n107        0.36                -0.26     -0.1  0.4333333         -0.3133333\n108        0.36                -0.26     -0.1 -0.5666667          0.6866667\n109       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n110       -0.64                -0.26      0.9 -0.5666667          0.6866667\n111        0.36                -0.26     -0.1  0.4333333         -0.3133333\n112       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n113       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n114        0.36                -0.26     -0.1  0.4333333         -0.3133333\n115        0.36                -0.26     -0.1  0.4333333         -0.3133333\n116        0.36                -0.26     -0.1  0.4333333         -0.3133333\n117        0.36                -0.26     -0.1  0.4333333         -0.3133333\n118        0.36                -0.26     -0.1  0.4333333         -0.3133333\n119        0.36                -0.26     -0.1 -0.5666667          0.6866667\n120       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n121        0.36                -0.26     -0.1  0.4333333         -0.3133333\n122       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n123        0.36                -0.26     -0.1  0.4333333         -0.3133333\n124        0.36                -0.26     -0.1  0.4333333         -0.3133333\n125        0.36                -0.26     -0.1  0.4333333         -0.3133333\n126        0.36                -0.26     -0.1  0.4333333         -0.3133333\n127       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n128        0.36                -0.26     -0.1 -0.5666667          0.6866667\n129        0.36                -0.26     -0.1  0.4333333         -0.3133333\n130        0.36                -0.26     -0.1  0.4333333         -0.3133333\n131        0.36                -0.26     -0.1  0.4333333         -0.3133333\n132        0.36                -0.26     -0.1  0.4333333         -0.3133333\n133       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n134        0.36                -0.26     -0.1  0.4333333         -0.3133333\n135        0.36                -0.26     -0.1  0.4333333         -0.3133333\n136       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n137        0.36                -0.26     -0.1  0.4333333         -0.3133333\n138        0.36                -0.26     -0.1  0.4333333         -0.3133333\n139        0.36                -0.26     -0.1  0.4333333         -0.3133333\n140        0.36                -0.26     -0.1  0.4333333         -0.3133333\n141        0.36                -0.26     -0.1  0.4333333         -0.3133333\n142        0.36                -0.26     -0.1  0.4333333         -0.3133333\n143        0.36                -0.26     -0.1  0.4333333         -0.3133333\n144        0.36                -0.26     -0.1  0.4333333         -0.3133333\n145        0.36                -0.26     -0.1  0.4333333         -0.3133333\n146        0.36                -0.26     -0.1  0.4333333         -0.3133333\n147        0.36                -0.26     -0.1  0.4333333         -0.3133333\n148       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n149       -0.64                -0.26      0.9  0.4333333         -0.3133333\n150        0.36                -0.26     -0.1  0.4333333         -0.3133333\n151        0.36                -0.26     -0.1 -0.5666667          0.6866667\n152        0.36                -0.26     -0.1  0.4333333         -0.3133333\n153        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n154        0.36                -0.26     -0.1  0.4333333         -0.3133333\n155        0.36                -0.26     -0.1  0.4333333         -0.3133333\n156        0.36                -0.26     -0.1  0.4333333         -0.3133333\n157        0.36                -0.26     -0.1  0.4333333         -0.3133333\n158        0.36                -0.26     -0.1  0.4333333         -0.3133333\n159       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n160       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n161        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n162        0.36                -0.26     -0.1  0.4333333         -0.3133333\n163        0.36                -0.26     -0.1 -0.5666667          0.6866667\n164        0.36                -0.26     -0.1 -0.5666667          0.6866667\n165        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n166        0.36                -0.26     -0.1  0.4333333         -0.3133333\n167        0.36                -0.26     -0.1  0.4333333         -0.3133333\n168       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n169        0.36                -0.26     -0.1  0.4333333         -0.3133333\n170        0.36                -0.26     -0.1  0.4333333         -0.3133333\n171       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n172       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n173        0.36                -0.26     -0.1 -0.5666667          0.6866667\n174        0.36                -0.26     -0.1  0.4333333         -0.3133333\n175        0.36                -0.26     -0.1  0.4333333         -0.3133333\n176        0.36                -0.26     -0.1  0.4333333         -0.3133333\n177        0.36                -0.26     -0.1  0.4333333         -0.3133333\n178        0.36                -0.26     -0.1 -0.5666667          0.6866667\n179        0.36                -0.26     -0.1  0.4333333         -0.3133333\n180        0.36                -0.26     -0.1 -0.5666667          0.6866667\n181        0.36                -0.26     -0.1  0.4333333         -0.3133333\n182       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n183        0.36                -0.26     -0.1  0.4333333         -0.3133333\n184        0.36                -0.26     -0.1  0.4333333         -0.3133333\n185        0.36                -0.26     -0.1 -0.5666667          0.6866667\n186        0.36                -0.26     -0.1  0.4333333         -0.3133333\n187        0.36                -0.26     -0.1  0.4333333         -0.3133333\n188        0.36                -0.26     -0.1  0.4333333         -0.3133333\n189        0.36                -0.26     -0.1 -0.5666667          0.6866667\n190       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n191       -0.64                -0.26      0.9 -0.5666667          0.6866667\n192        0.36                -0.26     -0.1 -0.5666667          0.6866667\n193        0.36                -0.26     -0.1  0.4333333         -0.3133333\n194        0.36                -0.26     -0.1 -0.5666667          0.6866667\n195       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n196        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n197        0.36                -0.26     -0.1  0.4333333         -0.3133333\n198       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n199       -0.64                -0.26      0.9  0.4333333         -0.3133333\n200        0.36                -0.26     -0.1  0.4333333         -0.3133333\n201       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n202       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n203       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n204        0.36                -0.26     -0.1  0.4333333         -0.3133333\n205        0.36                -0.26     -0.1  0.4333333         -0.3133333\n206        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n207       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n208       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n209        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n210        0.36                -0.26     -0.1  0.4333333         -0.3133333\n211       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n212       -0.64                -0.26      0.9  0.4333333         -0.3133333\n213        0.36                -0.26     -0.1  0.4333333         -0.3133333\n214       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n215        0.36                -0.26     -0.1  0.4333333         -0.3133333\n216        0.36                -0.26     -0.1  0.4333333         -0.3133333\n217        0.36                -0.26     -0.1 -0.5666667          0.6866667\n218        0.36                -0.26     -0.1  0.4333333         -0.3133333\n219        0.36                -0.26     -0.1  0.4333333         -0.3133333\n220       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n221        0.36                -0.26     -0.1 -0.5666667          0.6866667\n222       -0.64                -0.26      0.9 -0.5666667          0.6866667\n223        0.36                -0.26     -0.1  0.4333333         -0.3133333\n224       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n225       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n226        0.36                -0.26     -0.1  0.4333333         -0.3133333\n227       -0.64                -0.26      0.9 -0.5666667          0.6866667\n228        0.36                -0.26     -0.1  0.4333333         -0.3133333\n229       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n230        0.36                -0.26     -0.1  0.4333333         -0.3133333\n231        0.36                -0.26     -0.1 -0.5666667          0.6866667\n232        0.36                -0.26     -0.1  0.4333333         -0.3133333\n233       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n234       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n235        0.36                -0.26     -0.1 -0.5666667          0.6866667\n236        0.36                -0.26     -0.1  0.4333333         -0.3133333\n237        0.36                -0.26     -0.1  0.4333333         -0.3133333\n238       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n239       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n240       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n241       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n242        0.36                -0.26     -0.1 -0.5666667          0.6866667\n243       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n244       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n245        0.36                -0.26     -0.1  0.4333333         -0.3133333\n246       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n247        0.36                -0.26     -0.1  0.4333333         -0.3133333\n248       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n249       -0.64                -0.26      0.9 -0.5666667          0.6866667\n250        0.36                -0.26     -0.1  0.4333333         -0.3133333\n251       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n252       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n253       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n254        0.36                -0.26     -0.1  0.4333333         -0.3133333\n255        0.36                -0.26     -0.1 -0.5666667         -0.3133333\n256        0.36                -0.26     -0.1  0.4333333         -0.3133333\n257        0.36                -0.26     -0.1  0.4333333         -0.3133333\n258        0.36                -0.26     -0.1  0.4333333         -0.3133333\n259       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n260        0.36                -0.26     -0.1 -0.5666667          0.6866667\n261       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n262        0.36                -0.26     -0.1  0.4333333         -0.3133333\n263        0.36                -0.26     -0.1  0.4333333         -0.3133333\n264       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n265       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n266        0.36                -0.26     -0.1 -0.5666667          0.6866667\n267        0.36                -0.26     -0.1 -0.5666667          0.6866667\n268       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n269       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n270       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n271       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n272       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n273       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n274        0.36                -0.26     -0.1  0.4333333         -0.3133333\n275        0.36                -0.26     -0.1  0.4333333         -0.3133333\n276        0.36                -0.26     -0.1  0.4333333         -0.3133333\n277       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n278       -0.64                 0.74     -0.1 -0.5666667         -0.3133333\n279        0.36                -0.26     -0.1 -0.5666667          0.6866667\n280        0.36                -0.26     -0.1  0.4333333         -0.3133333\n281        0.36                -0.26     -0.1  0.4333333         -0.3133333\n282        0.36                -0.26     -0.1  0.4333333         -0.3133333\n283       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n284        0.36                -0.26     -0.1  0.4333333         -0.3133333\n285        0.36                -0.26     -0.1  0.4333333         -0.3133333\n286        0.36                -0.26     -0.1  0.4333333         -0.3133333\n287       -0.64                -0.26      0.9 -0.5666667         -0.3133333\n288        0.36                -0.26     -0.1  0.4333333         -0.3133333\n289       -0.64                 0.74     -0.1  0.4333333         -0.3133333\n290        0.36                -0.26     -0.1  0.4333333         -0.3133333\n291        0.36                -0.26     -0.1 -0.5666667          0.6866667\n292        0.36                -0.26     -0.1  0.4333333         -0.3133333\n293        0.36                -0.26     -0.1  0.4333333         -0.3133333\n294        0.36                -0.26     -0.1  0.4333333         -0.3133333\n295       -0.64                 0.74     -0.1 -0.5666667          0.6866667\n296        0.36                -0.26     -0.1  0.4333333         -0.3133333\n297       -0.64                -0.26      0.9 -0.5666667          0.6866667\n298        0.36                -0.26     -0.1  0.4333333         -0.3133333\n299       -0.64                -0.26      0.9  0.4333333         -0.3133333\n300        0.36                -0.26     -0.1  0.4333333         -0.3133333\n    unpackaged      black  Earl Grey green\n1        -0.12  0.7533333 -0.6433333 -0.11\n2        -0.12  0.7533333 -0.6433333 -0.11\n3        -0.12 -0.2466667  0.3566667 -0.11\n4        -0.12 -0.2466667  0.3566667 -0.11\n5        -0.12 -0.2466667  0.3566667 -0.11\n6        -0.12 -0.2466667  0.3566667 -0.11\n7        -0.12 -0.2466667  0.3566667 -0.11\n8        -0.12  0.7533333 -0.6433333 -0.11\n9        -0.12 -0.2466667  0.3566667 -0.11\n10       -0.12  0.7533333 -0.6433333 -0.11\n11       -0.12 -0.2466667  0.3566667 -0.11\n12       -0.12 -0.2466667  0.3566667 -0.11\n13       -0.12 -0.2466667  0.3566667 -0.11\n14       -0.12  0.7533333 -0.6433333 -0.11\n15       -0.12  0.7533333 -0.6433333 -0.11\n16        0.88 -0.2466667  0.3566667 -0.11\n17       -0.12  0.7533333 -0.6433333 -0.11\n18       -0.12 -0.2466667  0.3566667 -0.11\n19       -0.12  0.7533333 -0.6433333 -0.11\n20       -0.12  0.7533333 -0.6433333 -0.11\n21       -0.12 -0.2466667  0.3566667 -0.11\n22       -0.12  0.7533333 -0.6433333 -0.11\n23       -0.12 -0.2466667  0.3566667 -0.11\n24       -0.12  0.7533333 -0.6433333 -0.11\n25        0.88 -0.2466667  0.3566667 -0.11\n26       -0.12 -0.2466667  0.3566667 -0.11\n27       -0.12 -0.2466667  0.3566667 -0.11\n28       -0.12 -0.2466667  0.3566667 -0.11\n29       -0.12  0.7533333 -0.6433333 -0.11\n30       -0.12 -0.2466667  0.3566667 -0.11\n31        0.88 -0.2466667  0.3566667 -0.11\n32       -0.12 -0.2466667  0.3566667 -0.11\n33       -0.12 -0.2466667  0.3566667 -0.11\n34       -0.12  0.7533333 -0.6433333 -0.11\n35       -0.12  0.7533333 -0.6433333 -0.11\n36       -0.12 -0.2466667  0.3566667 -0.11\n37       -0.12 -0.2466667 -0.6433333  0.89\n38       -0.12 -0.2466667 -0.6433333  0.89\n39       -0.12 -0.2466667  0.3566667 -0.11\n40       -0.12 -0.2466667 -0.6433333  0.89\n41       -0.12 -0.2466667  0.3566667 -0.11\n42       -0.12 -0.2466667 -0.6433333  0.89\n43       -0.12 -0.2466667  0.3566667 -0.11\n44       -0.12  0.7533333 -0.6433333 -0.11\n45       -0.12 -0.2466667  0.3566667 -0.11\n46       -0.12 -0.2466667  0.3566667 -0.11\n47       -0.12 -0.2466667  0.3566667 -0.11\n48       -0.12 -0.2466667  0.3566667 -0.11\n49       -0.12 -0.2466667  0.3566667 -0.11\n50       -0.12  0.7533333 -0.6433333 -0.11\n51       -0.12 -0.2466667  0.3566667 -0.11\n52       -0.12  0.7533333 -0.6433333 -0.11\n53        0.88 -0.2466667  0.3566667 -0.11\n54       -0.12 -0.2466667  0.3566667 -0.11\n55       -0.12 -0.2466667 -0.6433333  0.89\n56       -0.12 -0.2466667  0.3566667 -0.11\n57       -0.12 -0.2466667 -0.6433333  0.89\n58       -0.12 -0.2466667  0.3566667 -0.11\n59       -0.12 -0.2466667 -0.6433333  0.89\n60       -0.12  0.7533333 -0.6433333 -0.11\n61       -0.12 -0.2466667  0.3566667 -0.11\n62        0.88 -0.2466667  0.3566667 -0.11\n63       -0.12 -0.2466667  0.3566667 -0.11\n64       -0.12  0.7533333 -0.6433333 -0.11\n65       -0.12 -0.2466667  0.3566667 -0.11\n66       -0.12  0.7533333 -0.6433333 -0.11\n67       -0.12 -0.2466667  0.3566667 -0.11\n68       -0.12 -0.2466667  0.3566667 -0.11\n69       -0.12 -0.2466667  0.3566667 -0.11\n70       -0.12 -0.2466667  0.3566667 -0.11\n71       -0.12 -0.2466667  0.3566667 -0.11\n72       -0.12 -0.2466667  0.3566667 -0.11\n73       -0.12 -0.2466667  0.3566667 -0.11\n74        0.88 -0.2466667  0.3566667 -0.11\n75       -0.12  0.7533333 -0.6433333 -0.11\n76       -0.12 -0.2466667  0.3566667 -0.11\n77       -0.12 -0.2466667  0.3566667 -0.11\n78       -0.12 -0.2466667  0.3566667 -0.11\n79       -0.12 -0.2466667  0.3566667 -0.11\n80       -0.12 -0.2466667  0.3566667 -0.11\n81       -0.12  0.7533333 -0.6433333 -0.11\n82        0.88 -0.2466667  0.3566667 -0.11\n83       -0.12 -0.2466667  0.3566667 -0.11\n84       -0.12 -0.2466667  0.3566667 -0.11\n85       -0.12 -0.2466667  0.3566667 -0.11\n86       -0.12 -0.2466667  0.3566667 -0.11\n87       -0.12 -0.2466667  0.3566667 -0.11\n88       -0.12 -0.2466667  0.3566667 -0.11\n89       -0.12 -0.2466667  0.3566667 -0.11\n90       -0.12 -0.2466667  0.3566667 -0.11\n91       -0.12  0.7533333 -0.6433333 -0.11\n92       -0.12 -0.2466667  0.3566667 -0.11\n93       -0.12  0.7533333 -0.6433333 -0.11\n94        0.88 -0.2466667  0.3566667 -0.11\n95        0.88 -0.2466667  0.3566667 -0.11\n96       -0.12  0.7533333 -0.6433333 -0.11\n97       -0.12 -0.2466667  0.3566667 -0.11\n98       -0.12 -0.2466667  0.3566667 -0.11\n99       -0.12  0.7533333 -0.6433333 -0.11\n100       0.88 -0.2466667  0.3566667 -0.11\n101      -0.12 -0.2466667  0.3566667 -0.11\n102      -0.12 -0.2466667 -0.6433333  0.89\n103      -0.12 -0.2466667  0.3566667 -0.11\n104      -0.12 -0.2466667  0.3566667 -0.11\n105      -0.12 -0.2466667  0.3566667 -0.11\n106      -0.12 -0.2466667  0.3566667 -0.11\n107      -0.12 -0.2466667  0.3566667 -0.11\n108      -0.12 -0.2466667  0.3566667 -0.11\n109      -0.12 -0.2466667  0.3566667 -0.11\n110      -0.12 -0.2466667  0.3566667 -0.11\n111      -0.12 -0.2466667  0.3566667 -0.11\n112      -0.12 -0.2466667  0.3566667 -0.11\n113      -0.12 -0.2466667  0.3566667 -0.11\n114      -0.12 -0.2466667  0.3566667 -0.11\n115      -0.12 -0.2466667  0.3566667 -0.11\n116      -0.12 -0.2466667  0.3566667 -0.11\n117      -0.12 -0.2466667  0.3566667 -0.11\n118      -0.12 -0.2466667  0.3566667 -0.11\n119      -0.12 -0.2466667  0.3566667 -0.11\n120      -0.12 -0.2466667  0.3566667 -0.11\n121      -0.12 -0.2466667  0.3566667 -0.11\n122      -0.12 -0.2466667  0.3566667 -0.11\n123      -0.12 -0.2466667  0.3566667 -0.11\n124      -0.12 -0.2466667  0.3566667 -0.11\n125      -0.12 -0.2466667  0.3566667 -0.11\n126      -0.12 -0.2466667  0.3566667 -0.11\n127      -0.12  0.7533333 -0.6433333 -0.11\n128      -0.12  0.7533333 -0.6433333 -0.11\n129      -0.12 -0.2466667  0.3566667 -0.11\n130      -0.12 -0.2466667  0.3566667 -0.11\n131      -0.12 -0.2466667  0.3566667 -0.11\n132      -0.12  0.7533333 -0.6433333 -0.11\n133      -0.12 -0.2466667  0.3566667 -0.11\n134      -0.12  0.7533333 -0.6433333 -0.11\n135      -0.12  0.7533333 -0.6433333 -0.11\n136      -0.12 -0.2466667  0.3566667 -0.11\n137      -0.12 -0.2466667  0.3566667 -0.11\n138      -0.12 -0.2466667  0.3566667 -0.11\n139      -0.12 -0.2466667  0.3566667 -0.11\n140      -0.12 -0.2466667  0.3566667 -0.11\n141      -0.12 -0.2466667  0.3566667 -0.11\n142      -0.12 -0.2466667  0.3566667 -0.11\n143      -0.12 -0.2466667  0.3566667 -0.11\n144      -0.12 -0.2466667  0.3566667 -0.11\n145      -0.12 -0.2466667  0.3566667 -0.11\n146      -0.12 -0.2466667  0.3566667 -0.11\n147      -0.12 -0.2466667  0.3566667 -0.11\n148      -0.12  0.7533333 -0.6433333 -0.11\n149      -0.12 -0.2466667  0.3566667 -0.11\n150      -0.12 -0.2466667  0.3566667 -0.11\n151      -0.12  0.7533333 -0.6433333 -0.11\n152      -0.12 -0.2466667  0.3566667 -0.11\n153       0.88  0.7533333 -0.6433333 -0.11\n154      -0.12 -0.2466667 -0.6433333  0.89\n155      -0.12 -0.2466667  0.3566667 -0.11\n156      -0.12  0.7533333 -0.6433333 -0.11\n157      -0.12 -0.2466667  0.3566667 -0.11\n158      -0.12 -0.2466667  0.3566667 -0.11\n159       0.88  0.7533333 -0.6433333 -0.11\n160      -0.12  0.7533333 -0.6433333 -0.11\n161       0.88  0.7533333 -0.6433333 -0.11\n162      -0.12  0.7533333 -0.6433333 -0.11\n163      -0.12 -0.2466667 -0.6433333  0.89\n164      -0.12  0.7533333 -0.6433333 -0.11\n165       0.88 -0.2466667 -0.6433333  0.89\n166      -0.12 -0.2466667  0.3566667 -0.11\n167      -0.12 -0.2466667 -0.6433333  0.89\n168       0.88  0.7533333 -0.6433333 -0.11\n169      -0.12 -0.2466667  0.3566667 -0.11\n170      -0.12 -0.2466667  0.3566667 -0.11\n171       0.88 -0.2466667  0.3566667 -0.11\n172      -0.12 -0.2466667  0.3566667 -0.11\n173      -0.12  0.7533333 -0.6433333 -0.11\n174      -0.12 -0.2466667  0.3566667 -0.11\n175      -0.12 -0.2466667  0.3566667 -0.11\n176      -0.12 -0.2466667  0.3566667 -0.11\n177      -0.12 -0.2466667  0.3566667 -0.11\n178      -0.12 -0.2466667  0.3566667 -0.11\n179      -0.12 -0.2466667  0.3566667 -0.11\n180      -0.12 -0.2466667 -0.6433333  0.89\n181      -0.12  0.7533333 -0.6433333 -0.11\n182       0.88  0.7533333 -0.6433333 -0.11\n183      -0.12  0.7533333 -0.6433333 -0.11\n184      -0.12 -0.2466667  0.3566667 -0.11\n185      -0.12 -0.2466667  0.3566667 -0.11\n186      -0.12 -0.2466667 -0.6433333  0.89\n187      -0.12 -0.2466667 -0.6433333  0.89\n188      -0.12 -0.2466667 -0.6433333  0.89\n189      -0.12 -0.2466667 -0.6433333  0.89\n190       0.88 -0.2466667 -0.6433333  0.89\n191      -0.12 -0.2466667  0.3566667 -0.11\n192      -0.12 -0.2466667  0.3566667 -0.11\n193      -0.12 -0.2466667  0.3566667 -0.11\n194      -0.12 -0.2466667  0.3566667 -0.11\n195       0.88 -0.2466667 -0.6433333  0.89\n196       0.88  0.7533333 -0.6433333 -0.11\n197      -0.12 -0.2466667  0.3566667 -0.11\n198      -0.12 -0.2466667  0.3566667 -0.11\n199      -0.12 -0.2466667 -0.6433333  0.89\n200      -0.12 -0.2466667 -0.6433333  0.89\n201      -0.12 -0.2466667  0.3566667 -0.11\n202       0.88  0.7533333 -0.6433333 -0.11\n203      -0.12 -0.2466667  0.3566667 -0.11\n204      -0.12 -0.2466667  0.3566667 -0.11\n205      -0.12 -0.2466667 -0.6433333  0.89\n206       0.88  0.7533333 -0.6433333 -0.11\n207      -0.12  0.7533333 -0.6433333 -0.11\n208       0.88  0.7533333 -0.6433333 -0.11\n209       0.88 -0.2466667 -0.6433333  0.89\n210      -0.12 -0.2466667  0.3566667 -0.11\n211       0.88  0.7533333 -0.6433333 -0.11\n212      -0.12 -0.2466667 -0.6433333  0.89\n213      -0.12  0.7533333 -0.6433333 -0.11\n214      -0.12 -0.2466667  0.3566667 -0.11\n215      -0.12 -0.2466667  0.3566667 -0.11\n216      -0.12  0.7533333 -0.6433333 -0.11\n217      -0.12  0.7533333 -0.6433333 -0.11\n218      -0.12 -0.2466667  0.3566667 -0.11\n219      -0.12 -0.2466667  0.3566667 -0.11\n220       0.88 -0.2466667  0.3566667 -0.11\n221      -0.12 -0.2466667  0.3566667 -0.11\n222      -0.12 -0.2466667 -0.6433333  0.89\n223      -0.12 -0.2466667  0.3566667 -0.11\n224      -0.12 -0.2466667  0.3566667 -0.11\n225      -0.12  0.7533333 -0.6433333 -0.11\n226      -0.12 -0.2466667 -0.6433333  0.89\n227      -0.12 -0.2466667 -0.6433333  0.89\n228      -0.12  0.7533333 -0.6433333 -0.11\n229       0.88 -0.2466667 -0.6433333  0.89\n230      -0.12 -0.2466667  0.3566667 -0.11\n231      -0.12  0.7533333 -0.6433333 -0.11\n232      -0.12 -0.2466667  0.3566667 -0.11\n233      -0.12 -0.2466667  0.3566667 -0.11\n234      -0.12 -0.2466667  0.3566667 -0.11\n235      -0.12 -0.2466667  0.3566667 -0.11\n236      -0.12 -0.2466667  0.3566667 -0.11\n237      -0.12 -0.2466667  0.3566667 -0.11\n238       0.88 -0.2466667  0.3566667 -0.11\n239      -0.12 -0.2466667  0.3566667 -0.11\n240      -0.12 -0.2466667  0.3566667 -0.11\n241      -0.12 -0.2466667  0.3566667 -0.11\n242      -0.12 -0.2466667  0.3566667 -0.11\n243      -0.12 -0.2466667 -0.6433333  0.89\n244      -0.12 -0.2466667  0.3566667 -0.11\n245      -0.12 -0.2466667  0.3566667 -0.11\n246      -0.12 -0.2466667  0.3566667 -0.11\n247      -0.12  0.7533333 -0.6433333 -0.11\n248       0.88 -0.2466667  0.3566667 -0.11\n249      -0.12 -0.2466667  0.3566667 -0.11\n250      -0.12 -0.2466667  0.3566667 -0.11\n251      -0.12 -0.2466667  0.3566667 -0.11\n252      -0.12 -0.2466667  0.3566667 -0.11\n253      -0.12 -0.2466667  0.3566667 -0.11\n254      -0.12 -0.2466667  0.3566667 -0.11\n255       0.88 -0.2466667  0.3566667 -0.11\n256      -0.12  0.7533333 -0.6433333 -0.11\n257      -0.12  0.7533333 -0.6433333 -0.11\n258      -0.12 -0.2466667 -0.6433333  0.89\n259      -0.12 -0.2466667  0.3566667 -0.11\n260      -0.12 -0.2466667  0.3566667 -0.11\n261       0.88  0.7533333 -0.6433333 -0.11\n262      -0.12 -0.2466667 -0.6433333  0.89\n263      -0.12  0.7533333 -0.6433333 -0.11\n264      -0.12 -0.2466667  0.3566667 -0.11\n265      -0.12 -0.2466667  0.3566667 -0.11\n266      -0.12 -0.2466667  0.3566667 -0.11\n267      -0.12  0.7533333 -0.6433333 -0.11\n268      -0.12 -0.2466667  0.3566667 -0.11\n269      -0.12  0.7533333 -0.6433333 -0.11\n270      -0.12 -0.2466667  0.3566667 -0.11\n271       0.88  0.7533333 -0.6433333 -0.11\n272       0.88  0.7533333 -0.6433333 -0.11\n273      -0.12 -0.2466667  0.3566667 -0.11\n274      -0.12 -0.2466667  0.3566667 -0.11\n275      -0.12  0.7533333 -0.6433333 -0.11\n276      -0.12 -0.2466667  0.3566667 -0.11\n277       0.88  0.7533333 -0.6433333 -0.11\n278       0.88  0.7533333 -0.6433333 -0.11\n279      -0.12  0.7533333 -0.6433333 -0.11\n280      -0.12 -0.2466667  0.3566667 -0.11\n281      -0.12 -0.2466667  0.3566667 -0.11\n282      -0.12 -0.2466667  0.3566667 -0.11\n283      -0.12 -0.2466667  0.3566667 -0.11\n284      -0.12  0.7533333 -0.6433333 -0.11\n285      -0.12 -0.2466667  0.3566667 -0.11\n286      -0.12 -0.2466667  0.3566667 -0.11\n287       0.88 -0.2466667  0.3566667 -0.11\n288      -0.12  0.7533333 -0.6433333 -0.11\n289      -0.12 -0.2466667  0.3566667 -0.11\n290      -0.12 -0.2466667  0.3566667 -0.11\n291      -0.12 -0.2466667  0.3566667 -0.11\n292      -0.12 -0.2466667  0.3566667 -0.11\n293      -0.12 -0.2466667  0.3566667 -0.11\n294      -0.12 -0.2466667  0.3566667 -0.11\n295      -0.12 -0.2466667  0.3566667 -0.11\n296      -0.12 -0.2466667 -0.6433333  0.89\n297      -0.12 -0.2466667 -0.6433333  0.89\n298      -0.12 -0.2466667  0.3566667 -0.11\n299      -0.12  0.7533333 -0.6433333 -0.11\n300      -0.12  0.7533333 -0.6433333 -0.11\n```\n:::\n\n```{.r .cell-code}\n    Z <- t(t(G) - plxk)\n\n    # SVD of Z\n    u_til <- svd(Z)$u\n    lambda_til <- svd(Z)$d\n\n    # Principal Compoent Scores (factor coordinates of the rows)\n    u_til[, 1:3] %*% diag(lambda_til[1:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               [,1]       [,2]         [,3]\n  [1,] -0.613096145 -0.9538928  0.120541074\n  [2,] -0.613096145 -0.9538928  0.120541074\n  [3,] -0.744174103  0.3861053 -0.009621709\n  [4,] -0.744174103  0.3861053 -0.009621709\n  [5,] -0.744174103  0.3861053 -0.009621709\n  [6,] -0.744174103  0.3861053 -0.009621709\n  [7,] -0.744174103  0.3861053 -0.009621709\n  [8,] -0.613096145 -0.9538928  0.120541074\n  [9,]  1.216425166  0.6443304  0.164938880\n [10,]  1.347503124 -0.6956677  0.295101663\n [11,] -0.744174103  0.3861053 -0.009621709\n [12,] -0.744174103  0.3861053 -0.009621709\n [13,]  1.216425166  0.6443304  0.164938880\n [14,] -0.613096145 -0.9538928  0.120541074\n [15,]  0.328572730 -0.7268964 -0.484310700\n [16,]  0.863719636  0.4129066 -0.882496815\n [17,]  1.347503124 -0.6956677  0.295101663\n [18,]  0.197494772  0.6131018 -0.614473483\n [19,] -0.613096145 -0.9538928  0.120541074\n [20,] -0.613096145 -0.9538928  0.120541074\n [21,]  0.197494772  0.6131018 -0.614473483\n [22,]  1.347503124 -0.6956677  0.295101663\n [23,] -0.744174103  0.3861053 -0.009621709\n [24,] -0.613096145 -0.9538928  0.120541074\n [25,]  0.863719636  0.4129066 -0.882496815\n [26,]  0.197494772  0.6131018 -0.614473483\n [27,] -0.744174103  0.3861053 -0.009621709\n [28,]  0.274756291  0.4173340  0.769790654\n [29,] -0.613096145 -0.9538928  0.120541074\n [30,] -0.744174103  0.3861053 -0.009621709\n [31,]  0.530060157  0.1605672 -1.149342708\n [32,]  1.216425166  0.6443304  0.164938880\n [33,]  1.216425166  0.6443304  0.164938880\n [34,] -0.613096145 -0.9538928  0.120541074\n [35,]  1.347503124 -0.6956677  0.295101663\n [36,] -0.744174103  0.3861053 -0.009621709\n [37,]  0.338345859 -0.4719277  0.859727411\n [38,] -0.680584535 -0.5031564  0.080315048\n [39,]  0.197494772  0.6131018 -0.614473483\n [40,]  1.280014734 -0.2449313  0.254875636\n [41,] -0.744174103  0.3861053 -0.009621709\n [42,] -0.680584535 -0.5031564  0.080315048\n [43,] -0.744174103  0.3861053 -0.009621709\n [44,]  0.328572730 -0.7268964 -0.484310700\n [45,] -0.744174103  0.3861053 -0.009621709\n [46,] -0.744174103  0.3861053 -0.009621709\n [47,] -0.744174103  0.3861053 -0.009621709\n [48,]  1.216425166  0.6443304  0.164938880\n [49,]  0.274756291  0.4173340  0.769790654\n [50,]  1.347503124 -0.6956677  0.295101663\n [51,]  1.216425166  0.6443304  0.164938880\n [52,]  0.405834249 -0.9226642  0.899953437\n [53,]  0.530060157  0.1605672 -1.149342708\n [54,] -0.744174103  0.3861053 -0.009621709\n [55,] -0.680584535 -0.5031564  0.080315048\n [56,]  0.274756291  0.4173340  0.769790654\n [57,] -0.680584535 -0.5031564  0.080315048\n [58,]  1.216425166  0.6443304  0.164938880\n [59,]  1.280014734 -0.2449313  0.254875636\n [60,]  0.405834249 -0.9226642  0.899953437\n [61,]  1.216425166  0.6443304  0.164938880\n [62,]  0.530060157  0.1605672 -1.149342708\n [63,] -0.744174103  0.3861053 -0.009621709\n [64,]  0.328572730 -0.7268964 -0.484310700\n [65,]  0.274756291  0.4173340  0.769790654\n [66,]  1.347503124 -0.6956677  0.295101663\n [67,]  1.216425166  0.6443304  0.164938880\n [68,]  1.216425166  0.6443304  0.164938880\n [69,] -0.744174103  0.3861053 -0.009621709\n [70,] -0.744174103  0.3861053 -0.009621709\n [71,] -0.744174103  0.3861053 -0.009621709\n [72,]  1.216425166  0.6443304  0.164938880\n [73,] -0.744174103  0.3861053 -0.009621709\n [74,]  0.530060157  0.1605672 -1.149342708\n [75,] -0.613096145 -0.9538928  0.120541074\n [76,] -0.744174103  0.3861053 -0.009621709\n [77,] -0.744174103  0.3861053 -0.009621709\n [78,]  0.274756291  0.4173340  0.769790654\n [79,] -0.136164706  0.3607624 -0.881319377\n [80,]  0.274756291  0.4173340  0.769790654\n [81,] -0.613096145 -0.9538928  0.120541074\n [82,] -0.077949240  0.1859101 -0.277645040\n [83,]  0.197494772  0.6131018 -0.614473483\n [84,] -0.744174103  0.3861053 -0.009621709\n [85,] -0.744174103  0.3861053 -0.009621709\n [86,] -0.744174103  0.3861053 -0.009621709\n [87,]  1.216425166  0.6443304  0.164938880\n [88,] -0.744174103  0.3861053 -0.009621709\n [89,]  0.197494772  0.6131018 -0.614473483\n [90,]  0.274756291  0.4173340  0.769790654\n [91,]  0.405834249 -0.9226642  0.899953437\n [92,]  0.274756291  0.4173340  0.769790654\n [93,] -0.613096145 -0.9538928  0.120541074\n [94,] -0.077949240  0.1859101 -0.277645040\n [95,]  0.530060157  0.1605672 -1.149342708\n [96,]  0.405834249 -0.9226642  0.899953437\n [97,] -0.744174103  0.3861053 -0.009621709\n [98,] -0.744174103  0.3861053 -0.009621709\n [99,]  1.347503124 -0.6956677  0.295101663\n[100,]  0.530060157  0.1605672 -1.149342708\n[101,] -0.744174103  0.3861053 -0.009621709\n[102,]  0.338345859 -0.4719277  0.859727411\n[103,]  1.216425166  0.6443304  0.164938880\n[104,] -0.744174103  0.3861053 -0.009621709\n[105,] -0.744174103  0.3861053 -0.009621709\n[106,] -0.744174103  0.3861053 -0.009621709\n[107,] -0.744174103  0.3861053 -0.009621709\n[108,]  0.274756291  0.4173340  0.769790654\n[109,]  0.197494772  0.6131018 -0.614473483\n[110,]  0.882765688  0.3919911 -0.101907014\n[111,] -0.744174103  0.3861053 -0.009621709\n[112,]  1.216425166  0.6443304  0.164938880\n[113,]  0.197494772  0.6131018 -0.614473483\n[114,] -0.744174103  0.3861053 -0.009621709\n[115,] -0.744174103  0.3861053 -0.009621709\n[116,] -0.744174103  0.3861053 -0.009621709\n[117,] -0.744174103  0.3861053 -0.009621709\n[118,] -0.744174103  0.3861053 -0.009621709\n[119,]  0.274756291  0.4173340  0.769790654\n[120,]  0.197494772  0.6131018 -0.614473483\n[121,] -0.744174103  0.3861053 -0.009621709\n[122,]  1.216425166  0.6443304  0.164938880\n[123,] -0.744174103  0.3861053 -0.009621709\n[124,] -0.744174103  0.3861053 -0.009621709\n[125,] -0.744174103  0.3861053 -0.009621709\n[126,] -0.744174103  0.3861053 -0.009621709\n[127,]  1.347503124 -0.6956677  0.295101663\n[128,]  0.405834249 -0.9226642  0.899953437\n[129,] -0.744174103  0.3861053 -0.009621709\n[130,] -0.744174103  0.3861053 -0.009621709\n[131,] -0.744174103  0.3861053 -0.009621709\n[132,] -0.613096145 -0.9538928  0.120541074\n[133,]  1.216425166  0.6443304  0.164938880\n[134,] -0.613096145 -0.9538928  0.120541074\n[135,] -0.613096145 -0.9538928  0.120541074\n[136,]  0.197494772  0.6131018 -0.614473483\n[137,] -0.744174103  0.3861053 -0.009621709\n[138,] -0.744174103  0.3861053 -0.009621709\n[139,] -0.744174103  0.3861053 -0.009621709\n[140,] -0.744174103  0.3861053 -0.009621709\n[141,] -0.744174103  0.3861053 -0.009621709\n[142,] -0.744174103  0.3861053 -0.009621709\n[143,] -0.744174103  0.3861053 -0.009621709\n[144,] -0.744174103  0.3861053 -0.009621709\n[145,] -0.744174103  0.3861053 -0.009621709\n[146,] -0.744174103  0.3861053 -0.009621709\n[147,] -0.744174103  0.3861053 -0.009621709\n[148,]  0.328572730 -0.7268964 -0.484310700\n[149,] -0.136164706  0.3607624 -0.881319377\n[150,] -0.744174103  0.3861053 -0.009621709\n[151,]  0.405834249 -0.9226642  0.899953437\n[152,] -0.744174103  0.3861053 -0.009621709\n[153,]  0.053128719 -1.1540881 -0.147482257\n[154,] -0.680584535 -0.5031564  0.080315048\n[155,] -0.744174103  0.3861053 -0.009621709\n[156,] -0.613096145 -0.9538928  0.120541074\n[157,] -0.744174103  0.3861053 -0.009621709\n[158,] -0.744174103  0.3861053 -0.009621709\n[159,]  0.994797594 -0.9270916 -0.752334032\n[160,]  0.328572730 -0.7268964 -0.484310700\n[161,]  0.053128719 -1.1540881 -0.147482257\n[162,] -0.613096145 -0.9538928  0.120541074\n[163,]  0.338345859 -0.4719277  0.859727411\n[164,]  0.405834249 -0.9226642  0.899953437\n[165,] -0.014359672 -0.7033516 -0.187708284\n[166,] -0.744174103  0.3861053 -0.009621709\n[167,] -0.680584535 -0.5031564  0.080315048\n[168,]  0.661138116 -1.1794310 -1.019179925\n[169,] -0.744174103  0.3861053 -0.009621709\n[170,] -0.744174103  0.3861053 -0.009621709\n[171,]  0.863719636  0.4129066 -0.882496815\n[172,]  1.216425166  0.6443304  0.164938880\n[173,]  0.405834249 -0.9226642  0.899953437\n[174,] -0.744174103  0.3861053 -0.009621709\n[175,] -0.744174103  0.3861053 -0.009621709\n[176,] -0.744174103  0.3861053 -0.009621709\n[177,] -0.744174103  0.3861053 -0.009621709\n[178,]  0.274756291  0.4173340  0.769790654\n[179,] -0.744174103  0.3861053 -0.009621709\n[180,]  0.338345859 -0.4719277  0.859727411\n[181,] -0.613096145 -0.9538928  0.120541074\n[182,]  0.661138116 -1.1794310 -1.019179925\n[183,] -0.613096145 -0.9538928  0.120541074\n[184,] -0.744174103  0.3861053 -0.009621709\n[185,]  0.274756291  0.4173340  0.769790654\n[186,] -0.680584535 -0.5031564  0.080315048\n[187,] -0.680584535 -0.5031564  0.080315048\n[188,] -0.680584535 -0.5031564  0.080315048\n[189,]  0.338345859 -0.4719277  0.859727411\n[190,]  0.593649725 -0.7286945 -1.059405952\n[191,]  0.882765688  0.3919911 -0.101907014\n[192,]  0.274756291  0.4173340  0.769790654\n[193,] -0.744174103  0.3861053 -0.009621709\n[194,]  0.274756291  0.4173340  0.769790654\n[195,]  0.593649725 -0.7286945 -1.059405952\n[196,]  0.053128719 -1.1540881 -0.147482257\n[197,] -0.744174103  0.3861053 -0.009621709\n[198,]  0.197494772  0.6131018 -0.614473483\n[199,] -0.072575138 -0.5284993 -0.791382620\n[200,] -0.680584535 -0.5031564  0.080315048\n[201,]  1.216425166  0.6443304  0.164938880\n[202,]  0.661138116 -1.1794310 -1.019179925\n[203,]  1.216425166  0.6443304  0.164938880\n[204,] -0.744174103  0.3861053 -0.009621709\n[205,] -0.680584535 -0.5031564  0.080315048\n[206,]  0.053128719 -1.1540881 -0.147482257\n[207,]  1.347503124 -0.6956677  0.295101663\n[208,]  0.661138116 -1.1794310 -1.019179925\n[209,] -0.014359672 -0.7033516 -0.187708284\n[210,] -0.744174103  0.3861053 -0.009621709\n[211,]  0.661138116 -1.1794310 -1.019179925\n[212,] -0.072575138 -0.5284993 -0.791382620\n[213,] -0.613096145 -0.9538928  0.120541074\n[214,]  0.197494772  0.6131018 -0.614473483\n[215,] -0.744174103  0.3861053 -0.009621709\n[216,] -0.613096145 -0.9538928  0.120541074\n[217,]  0.405834249 -0.9226642  0.899953437\n[218,] -0.744174103  0.3861053 -0.009621709\n[219,] -0.744174103  0.3861053 -0.009621709\n[220,]  0.530060157  0.1605672 -1.149342708\n[221,]  0.274756291  0.4173340  0.769790654\n[222,]  0.946355256 -0.4972707 -0.011970257\n[223,] -0.744174103  0.3861053 -0.009621709\n[224,]  1.216425166  0.6443304  0.164938880\n[225,]  1.347503124 -0.6956677  0.295101663\n[226,] -0.680584535 -0.5031564  0.080315048\n[227,]  0.946355256 -0.4972707 -0.011970257\n[228,] -0.613096145 -0.9538928  0.120541074\n[229,]  0.593649725 -0.7286945 -1.059405952\n[230,] -0.744174103  0.3861053 -0.009621709\n[231,]  0.405834249 -0.9226642  0.899953437\n[232,] -0.744174103  0.3861053 -0.009621709\n[233,]  1.216425166  0.6443304  0.164938880\n[234,]  1.216425166  0.6443304  0.164938880\n[235,]  0.274756291  0.4173340  0.769790654\n[236,] -0.744174103  0.3861053 -0.009621709\n[237,] -0.744174103  0.3861053 -0.009621709\n[238,]  0.863719636  0.4129066 -0.882496815\n[239,]  0.197494772  0.6131018 -0.614473483\n[240,]  1.216425166  0.6443304  0.164938880\n[241,]  1.216425166  0.6443304  0.164938880\n[242,]  0.274756291  0.4173340  0.769790654\n[243,]  1.280014734 -0.2449313  0.254875636\n[244,]  1.216425166  0.6443304  0.164938880\n[245,] -0.744174103  0.3861053 -0.009621709\n[246,]  1.216425166  0.6443304  0.164938880\n[247,] -0.613096145 -0.9538928  0.120541074\n[248,]  0.530060157  0.1605672 -1.149342708\n[249,]  0.882765688  0.3919911 -0.101907014\n[250,] -0.744174103  0.3861053 -0.009621709\n[251,]  1.216425166  0.6443304  0.164938880\n[252,]  1.216425166  0.6443304  0.164938880\n[253,]  1.216425166  0.6443304  0.164938880\n[254,] -0.744174103  0.3861053 -0.009621709\n[255,] -0.077949240  0.1859101 -0.277645040\n[256,] -0.613096145 -0.9538928  0.120541074\n[257,] -0.613096145 -0.9538928  0.120541074\n[258,] -0.680584535 -0.5031564  0.080315048\n[259,]  1.216425166  0.6443304  0.164938880\n[260,]  0.274756291  0.4173340  0.769790654\n[261,]  0.661138116 -1.1794310 -1.019179925\n[262,] -0.680584535 -0.5031564  0.080315048\n[263,] -0.613096145 -0.9538928  0.120541074\n[264,]  1.216425166  0.6443304  0.164938880\n[265,]  1.216425166  0.6443304  0.164938880\n[266,]  0.274756291  0.4173340  0.769790654\n[267,]  0.405834249 -0.9226642  0.899953437\n[268,]  1.216425166  0.6443304  0.164938880\n[269,]  1.347503124 -0.6956677  0.295101663\n[270,]  1.216425166  0.6443304  0.164938880\n[271,]  0.994797594 -0.9270916 -0.752334032\n[272,]  0.661138116 -1.1794310 -1.019179925\n[273,]  1.216425166  0.6443304  0.164938880\n[274,] -0.744174103  0.3861053 -0.009621709\n[275,] -0.613096145 -0.9538928  0.120541074\n[276,] -0.744174103  0.3861053 -0.009621709\n[277,]  0.994797594 -0.9270916 -0.752334032\n[278,]  0.994797594 -0.9270916 -0.752334032\n[279,]  0.405834249 -0.9226642  0.899953437\n[280,] -0.744174103  0.3861053 -0.009621709\n[281,] -0.744174103  0.3861053 -0.009621709\n[282,] -0.744174103  0.3861053 -0.009621709\n[283,]  1.216425166  0.6443304  0.164938880\n[284,] -0.613096145 -0.9538928  0.120541074\n[285,] -0.744174103  0.3861053 -0.009621709\n[286,] -0.744174103  0.3861053 -0.009621709\n[287,]  0.530060157  0.1605672 -1.149342708\n[288,] -0.613096145 -0.9538928  0.120541074\n[289,]  0.197494772  0.6131018 -0.614473483\n[290,] -0.744174103  0.3861053 -0.009621709\n[291,]  0.274756291  0.4173340  0.769790654\n[292,] -0.744174103  0.3861053 -0.009621709\n[293,] -0.744174103  0.3861053 -0.009621709\n[294,] -0.744174103  0.3861053 -0.009621709\n[295,]  1.216425166  0.6443304  0.164938880\n[296,] -0.680584535 -0.5031564  0.080315048\n[297,]  0.946355256 -0.4972707 -0.011970257\n[298,] -0.744174103  0.3861053 -0.009621709\n[299,] -0.005086748 -0.9792358 -0.751156594\n[300,] -0.613096145 -0.9538928  0.120541074\n```\n:::\n:::\n\n\n\n# TL;DR, just give me the code!\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Packages\nlibrary(\"FactoMineR\") # for analysis\nlibrary(\"factoextra\") # for visualizarion1\n# Data Prep ---------------------------------------------------------------\n\n# Load data\ndata(\"poison\")\nhead(poison[, 1:7], 3) # survey style data\n\n# Subset active individuals and variables\npoison.active <- poison[1:55, 5:15]\nhead(poison.active[, 1:6], 3)\n\n# Summaries\nstr(poison.active)\nfor (i in 1:4) {\n    plot(poison.active[, i],\n        main = colnames(poison.active)[i],\n        ylab = \"Count\", col = \"steelblue\", las = 2\n    )\n}\n\n# The analysis ------------------------------------------------------------\nres.mca <- FactoMineR::MCA(\n    X = poison.active,\n    ncp = 5,\n    graph = TRUE\n)\n\n# Visualization -----------------------------------------------------------\n\n# Eigenvalues / Variances\neig.val <- get_eigenvalue(res.mca)\neig.val # proportion of variances retained by dimensions\n# Percentages of Inertia explained by MCA\nfviz_screeplot(res.mca, addlabels = TRUE, ylim = c(0, 45))\n# Biplot\nfviz_mca_biplot(res.mca,\n    repel = TRUE, # avoid text overlapping\n    ggtheme = theme_minimal()\n)\n# Rows (individuals) are represented by blue points;\n# Columns (variable categories) by red triangles.\n\n# Graph of variables\nvar <- get_mca_var(res.mca)\nvar\n# Coordinates\nhead(var$coord)\n# Cos2: quality on the factore map\nhead(var$cos2)\n# Contributions to the principal components\nhead(var$contrib)\n\n# Graph of individuals\nind <- get_mca_ind(res.mca) # extract the results for individuals\nind\n# Coordinates of column points\nhead(ind$coord)\n# Quality of representation\nhead(ind$cos2)\n# Contributions\nhead(ind$contrib)\n\n# BIplot for individuals only (no vars)\nfviz_mca_ind(res.mca,\n    col.ind = \"cos2\",\n    gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n    repel = TRUE, ggtheme = theme_minimal()\n)\nfviz_mca_ind(res.mca,\n    label = \"none\",\n    habillage = \"Vomiting\", # color by groups defined by variable\n    palette = c(\"#00AFBB\", \"#E7B800\"),\n    addEllipses = TRUE, ellipse.type = \"confidence\",\n    repel = TRUE, ggtheme = theme_minimal()\n)\n\n\n# More than 1 grouping variable\nfviz_ellipses(res.mca, c(\"Vomiting\", \"Fever\"),\n    geom = \"point\"\n)\n\n# Bar plot for Cos2 of individuals\nfviz_cos2(res.mca, choice = \"ind\", axes = 1:2, top = 20)\n# Contribution of individuals to the dimensions\nfviz_contrib(res.mca, choice = \"ind\", axes = 1:2, top = 20)\n# Data\ndata(wine)\n\n# Keep factors\nMCA.dt <- wine[, sapply(wine, is.factor)]\n\n# Look at data\nMCA.dt\n\n# Count levels\nsapply(MCA.dt, nlevels)\n\n# Define goal number of PCs\nnpcs <- 4\n\n# Perform MCA\nres.mca <- FactoMineR::MCA(\n    X = MCA.dt,\n    ncp = npcs,\n    graph = FALSE\n)\n\n# Coordinates of the individuals on the dimensions\nres.mca$ind$coord\n\n# right singular vectors of data\nres.mca$svd$V\n\n# Create required processing objects\nI <- nrow(MCA.dt)             # numebr of individuals\nK <- ncol(MCA.dt)             # number of categorical predictors\nqk <- sapply(MCA.dt, nlevels) # number of levels per categorical variable\nJ <- sum(qk)                  # total number of categories\n\n# Disjunctive table\nZ <- tab.disjonctif(MCA.dt)\n\n# And look at it\nZ\n\n# Relationship between disjunctive table and contingency table\nN <- t(Z[, 1:3]) %*% Z[, 4:7]\nN - table(MCA.dt)\n\n# Distance Metric Matrix\npxkqk <- colSums(Z) / I\nD_Sigma <- diag(pxkqk)\n\n# Weight Matrix\nW_mat <- diag(rep(1, I))/I\n\n# M matrix (center matrix)\nM <- matrix((rep(colMeans(Z), nrow(Z))),\n    nrow = nrow(Z),\n    byrow = TRUE\n)\n\n# SVD of triplet (Z-M, D_Sigma, W_mat)\nSVD.trip <- FactoMineR::svd.triplet(\n    X = Z - M,\n    row.w = diag(W_mat),\n    col.w = diag(1 / K * solve(D_Sigma)),\n    ncp = npcs\n)\n\n# Manual SVD triplet\nSVD.man <- svd(sqrt(W_mat) %*% (Z - M) %*% sqrt(1 / K * solve(D_Sigma)))\n\n# Convert back to correct scales (according to Chaven 2017 p. 3)\nV.man <- (solve(sqrt(1 / K * solve(D_Sigma))) %*% SVD.man$v)[, 1:npcs]\nU.man <- (solve(sqrt(W_mat)) %*% SVD.man$u)[, 1:npcs]\nL.man <- SVD.man$d[1:npcs]\n\n  \n  # Compare SVD triplet and manual SVD of weighted matrix\n  round(abs(SVD.trip$V) - abs(V.man), 5)\n  round(abs(SVD.trip$U) - abs(U.man), 5)\n  round(abs(SVD.trip$vs[1:npcs]) - abs(L.man), 5)\n  \n  # Reconstruction Formula\n  d_hat <- SVD.trip$vs[1:npcs] # matrix of the singular values \n                            # (Squared would be eigenvalues of Z)\n  u_hat <- SVD.trip$U # Left singular vectors matrix\n  v_hat <- SVD.trip$V # Right singular vectors matrix\n  \n  z_hat <- u_hat %*% diag(d_hat) %*% t(v_hat) + M\n  colSums(z_hat)\n  colSums(Z)\n  \n  # Compare SVD matrices\n  # Matrix of singular values\n  res.mca$svd$vs[1:npcs] -\n    d_hat[1:npcs]\n\n  res.mca$svd$vs[1:npcs] -\n    L.man\n  \n  # Left Singular Vectors Matrix\n  round(\n    res.mca$svd$U - u_hat,\n    3\n  )\n\n  round(\n    res.mca$svd$U - U.man,\n    3\n  )\n\n  # Right Singular Vectors Matrix\n  round(\n    res.mca$svd$V -\n      v_hat, \n    3)\n  # Correlation between columns\n  # And look into the PCAmixdata package\n  round(cor(v_hat, res.mca$svd$V), 1)\n  \n  # Coordinates on Dimensions are recovered\n  round(\n    res.mca$ind$coord -\n      u_hat %*% diag(d_hat),\n    3\n  )\n\n# Following JosseHusson2016 -----------------------------------------------\n\n  I <- nrow(MCA.dt)\n  J <- ncol(MCA.dt)\n  X <- tab.disjonctif(MCA.dt)\n  rowMarg <- rowSums(X) # = J\n  colMarg <- colSums(X) # = number of ids in a category\n  D_Sigma <- diag(colMarg)\n  D <- 1/I * diag(rep(1, I)) # rowMasses\n  SVD.trip <- svd.triplet(X = diag(rep(1, I)) %*% X %*% solve(D_Sigma),\n                          row.w = diag( D ),\n                          col.w = diag( 1/(I*J)*D_Sigma ),\n                          ncp=2\n                          )\n  svd(I * X %*% solve(D_Sigma))\n  \n  SVD.trip$vs\n  round(SVD.trip$vs[2:3] - res.mca$svd$vs[1:2], 3)\n  \n  SVD.trip$U\n  res.mca$svd$U\n#   round(SVD.trip$U[, 2:3] - res.mca$svd$U, 3)\n  res.mca$svd$U\n  \n#   SVD.trip$V\n#   round(SVD.trip$V[, 2:3] - res.mca$svd$V, 3)\n#   res.mca$svd$V\n\n# Prepare environment ----------------------------------------------------------\n\nlibrary(psych)\nlibrary(PCAmixdata)\n\nlibrary(\"FactoMineR\")\nlibrary(\"factoextra\")\n\ndata(tea)\n\nhead(tea)\n\nlapply(tea[, c(\"where\", \"how\", \"SPC\")], nlevels)\n\nsapply(tea, nlevels)\n\nx <- tea[, c(\"where\", \"how\", \"Tea\")]\n\nCTD <- tab.disjonctif(x)\npk <- colMeans(CTD)\n\nCTD[1, ] / pk\nCTD[4, ] / pk\n1/.64\n1/.56666667\n\nCTD_t <- t(apply(CTD, 1, function(r) {t(r)/pk} ))\ncolMeans(CTD_t)\n\n\nN <- tab.disjonctif(x)\n1/nrow(tea)\n\n# Correspondance analysis based on contingency table ---------------------------\nx <- tea[, c(\"SPC\", \"where\")]\nn <- nrow(x)\nr <- nlevels(x[, 1]) \nC <- nlevels(x[, 2]) \nN <- table(x)\n\n# Contingency table\nN\n\n# Indicator matrix\nZ <- tab.disjonctif(x)\nZ1 <- Z[, 1:r]\nZ2 <- Z[, -c(1:r)]\nN - t(Z1) %*% Z2\n\n# Correspondance matrix\nP <- 1/n * N\n\n# From Greenacre1984\nN\n\n# Column and row sums\nr_bold <- rowSums(N)\nc_bold <- colSums(N)\n\ndrop(N %*% rep(1, ncol(N))) - r_bold\ndrop(t(N) %*% rep(1, nrow(N))) - c_bold\n\nD_r <- diag(r_bold)\nD_c <- diag(c_bold)\n\n# Matrices of profiles\n\nR <- solve(D_r) %*% P\nC <- solve(D_c) %*% t(P)\n\n# Centroids\nr <- t(C) %*% c_bold\nc <- t(R) %*% r_bold\n\n# Generalized SVD of P - r_bold t(c_bold)\n\nP - r_bold %*% t(c_bold)\nA <- svd(P - r %*% t(c))$u\nB <- svd(P - r %*% t(c))$v\n\nt(A) %*% solve(D_r) %*% A\nt(B) %*% solve(D_c) %*% B\n\n# From Jolliffe p. 37\n# r_bold <- rep(1, r)\n# c_bold <- rep(1, C)\n# D_r <- diag(r_bold)\n# D_c <- diag(c_bold)\n# Omega <- solve(D_r)\n# Psi <- solve(D_c)\n# X <- P - r_bold %*% t(c_bold)\n\n# V <- svd(X)$u\n# M <- diag(svd(X)$d)\n# B <- svd(X)$v\n\n# round(t(V) %*% Omega %*% V, 3)\n# round(t(B) %*% Psi %*% B, 3)\n\n# X_til <- sqrt(Omega) %*% X %*% sqrt(Psi)\n\n# W <- svd(X_til)$u\n# K <- diag(svd(X_til)$d)\n# C <- svd(X_til)$v\n\n# solve(sqrt(Omega)) %*% W - V\n# solve(sqrt(Omega)) %*% C - B\n\n# W %*% K\n\n# # Row profiles\n# D_r\n\n# MCA based on Audigier et al 2017 p. 505 (p. 5 of pdf) ------------------------\n\n    # Work with categorical predictors from the tea dataset\n    x <- tea[, c(\"where\", \"how\", \"Tea\")]\n\n    # Define row weights\n    I <- nrow(x)\n    R <- diag(1 / I, I)\n\n    # Define Z (the disjunctive table)\n    Z <- tab.disjonctif(x)\n\n    # Define column weights\n    K <- ncol(x)\n    plxk <- colMeans(Z)\n    D_sigma <- diag(plxk)\n    1 / K * solve(D_sigma)\n\n    # Define M\n    M <- matrix(rep(plxk, I), nrow = I, byrow = TRUE)\n\n    # Centered matrix?\n    Z - M\n\n# MCA based on Chavent Et Al 2017 et al 2017 p. 505 (p. 5 of pdf) -----------1  ---\n\n    # Work with categorical predictors from the tea dataset\n    x <- tea[, c(\"where\", \"how\", \"Tea\")]\n\n    # Define Z (the disjunctive table)\n    G <- tab.disjonctif(x)\n\n    # Define row weights\n    n <- nrow(x)\n    N <- diag(1 / n, n)\n\n    # Define column weights\n    M <- diag(n / colSums(G))\n    solve(D_sigma)\n\n    # Create Z, the centered G?\n    plxk <- colMeans(G)\n    G - matrix(rep(plxk, I), nrow = I, byrow = TRUE)\n    Z <- t(t(G) - plxk)\n\n    # SVD of Z\n    u_til <- svd(Z)$u\n    lambda_til <- svd(Z)$d\n\n    # Principal Compoent Scores (factor coordinates of the rows)\n    u_til[, 1:3] %*% diag(lambda_til[1:3])\n```\n:::\n",
    "supporting": [
      "pca-mix_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}