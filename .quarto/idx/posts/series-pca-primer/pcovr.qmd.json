{"title":"Principal covariates regression in R","markdown":{"yaml":{"draft":true,"title":"Principal covariates regression in R","author":"Edoardo Costantini","date":"2022-08-04","slug":"pcovr","categories":["Supervised learning"],"bibliography":"../../resources/bibshelf.bib"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nPrincipal covariates regression is a method to analyze the relationship between sets of multivariate data in the presence of highly-collinear variables.\nCompared to regular principal component regression, principal covariates regression PCovR extracts components that account for much of the variability in a set of $X$ variables and that correlated well with a set of $Y$ variables.\nFor more information, I recommend reading [@vervloet2015pcovr, @vervloet2015pcovr] and [@de1992principal, @de1992principal].\nIn this post, you can find my R code notes on this method.\nIn these notes, I show the computations used by the `PCovR` R-package to perform the method.\n\n# R code notes\n\nThis are some R notes:\n\n```{r code-notes}\n# Set up environment -----------------------------------------------------------\n\n    # Load pacakge that implements this method\n    library(\"PCovR\", verbose = FALSE, quietly = TRUE)\n\n    # Load example data from PCovR package\n    data(alexithymia)\n\n    # Explore its scale\n    colMeans(alexithymia$X)\n    colMeans(alexithymia$Y)\n\n    apply(alexithymia$X, 2, var)\n    apply(alexithymia$Y, 2, var)\n\n    # Subset data\n    X_raw <- alexithymia$X\n    y_raw <- alexithymia$Y[, 1, drop = FALSE]\n\n    # Define paramters that can be useful\n    n <- nrow(X_raw)\n    p <- ncol(X_raw)\n\n    # Scale data\n    X <- scale(X_raw)# * (n - 1) / n\n    y <- scale(y_raw)# * (n - 1) / n\n\n    # Define parameters\n    alpha <- .5 # weighting parameter\n    npcs <- 5\n\n# Estimation -------------------------------------------------------------------\n\n    # Estimate with PCovR function\n    out <- PCovR::pcovr_est(\n        X = X,\n        Y = y,\n        a = alpha,\n        r = npcs # fixed number of components\n    )\n\n    # Estimate manually (Vervolet version)\n    Hx <- X %*% solve(t(X) %*% X) %*% t(X)\n    G_vv <- alpha * X %*% t(X) / sum(X^2) + (1 - alpha) * Hx %*% y %*% t(y) %*% Hx / sum(y^2)\n    EG_vv <- eigen(G_vv) # eigen-decomposition of matrix\n    T_vv <- EG_vv$vectors[, 1:npcs]\n\n# Compare results --------------------------------------------------------------\n\n    # T scores\n    Ts <- list(\n        PCovR = head(out$Te),\n        PCovR_man = head(X %*% out$W),\n        Vervolet = head(T_vv)\n    )\n\n    # Weights\n    W <- list(\n        PCovR = out$W,\n        Vervolet = solve(t(X) %*% X) %*% t(X) %*% T_vv\n    )\n\n    # Px\n    ( t(out$Te) %*% X )[, 1:5]\n    ( t(out$W) %*% t(X) %*% X )[, 1:5]\n    out$Px[, 1:5]\n\n    # Py\n    cbind(\n        Py = out$Py,\n        TtY = t(out$Te) %*% y,\n        WtXtY = t(out$W) %*% t(X) %*% y\n    )\n\n    # B\n    cbind(\n        B = drop(out$B),\n        WPY = drop(out$W %*% out$Py),\n        WWtXtY = drop(out$W %*% t(out$W) %*% t(X) %*% y)\n    )\n\n# Maximum likelihood tuning of alpha -------------------------------------------\n\n    # Fit PCovR\n    pcovr_out <- pcovr(\n        X = X_raw,\n        Y = y_raw,\n        rot = \"none\",\n        R = npcs, # fixed number of components\n        modsel = \"seq\" # fastest option\n    )\n\n    # Compute error ratio with function\n    err <- ErrorRatio(\n        X = X,\n        Y = y,\n        Rmin = npcs,\n        Rmax = npcs\n    )\n\n    # Compute error ratio components\n    lm_mod <- lm(y ~ -1 + X)\n    ery <- 1 - summary(lm_mod)$r.squared\n\n    Rmin <- npcs\n    Rmax <- npcs\n    sing <- svd(X)\n    vec <- Rmin:Rmax\n    vec <- c(vec[1] - 1, vec, vec[length(vec)] + 1)\n    VAF <- c(0, cumsum(sing$d^2) / sum(sing$d^2))\n    VAF <- VAF[vec + 1]\n    scr <- array(NA, c(1, length(vec)))\n    for (u in 2:(length(vec) - 1)) {\n        scr[, u] <- (VAF[u] - VAF[u - 1]) / (VAF[u + 1] - VAF[u])\n    }\n    erx <- 1 - VAF[which.max(scr)]\n\n    # Find alpha ML\n    alpha_ML <- sum(X^2) / (sum(X^2) + sum(y^2) * erx / ery)\n\n    # Compare to one found by package\n    pcovr_out$a - alpha_ML\n```\n\n# TL;DR, just give me the code!\n```{r TLDR, ref.label = knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n# References"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"pcovr.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","theme":{"light":["flatly","light.scss"],"dark":["darkly","dark.scss"]},"title-block-banner":true,"draft":true,"title":"Principal covariates regression in R","author":"Edoardo Costantini","date":"2022-08-04","slug":"pcovr","categories":["Supervised learning"],"bibliography":["../../resources/bibshelf.bib"]},"extensions":{"book":{"multiFile":true}}}}}