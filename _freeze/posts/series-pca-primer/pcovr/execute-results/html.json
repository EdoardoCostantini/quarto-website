{
  "hash": "fddf0324cb867205b521c913a4ae1dee",
  "result": {
    "markdown": "---\ndraft: true\ntitle: Principal covariates regression in R\nauthor: Edoardo Costantini\ndate: '2022-08-04'\nslug: pcovr\ncategories: [\"Supervised learning\"]\nbibliography: ../../resources/bibshelf.bib\n---\n\n\n# Introduction\n\nPrincipal covariates regression is a method to analyze the relationship between sets of multivariate data in the presence of highly-collinear variables.\nCompared to regular principal component regression, principal covariates regression PCovR extracts components that account for much of the variability in a set of $X$ variables and that correlated well with a set of $Y$ variables.\nFor more information, I recommend reading [@vervloet2015pcovr, @vervloet2015pcovr] and [@de1992principal, @de1992principal].\nIn this post, you can find my R code notes on this method.\nIn these notes, I show the computations used by the `PCovR` R-package to perform the method.\n\n# R code notes\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up environment -----------------------------------------------------------\n\n    # Load pacakge that implements this method\n    library(\"PCovR\", verbose = FALSE, quietly = TRUE)\n\n    # Load example data from PCovR package\n    data(alexithymia)\n\n    # Explore its scale\n    colMeans(alexithymia$X)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         confused       right words        sensations          describe \n        1.8196721         1.7950820         0.5983607         2.2213115 \n analyze problems             upset           puzzled        let happen \n        2.5081967         1.6065574         1.1393443         1.2622951 \n         identify         essential feel about people     describe more \n        1.6393443         2.7131148         1.7213115         1.0081967 \n         going on         why angry  daily activities     entertainment \n        0.9836066         1.2540984         1.6639344         1.6967213 \n  reveal feelings             close            useful   hidden meanings \n        1.6475410         2.8442623         2.4672131         1.2131148 \n```\n:::\n\n```{.r .cell-code}\n    colMeans(alexithymia$Y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   CES-D      RSE \n16.46721 31.37295 \n```\n:::\n\n```{.r .cell-code}\n    apply(alexithymia$X, 2, var)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         confused       right words        sensations          describe \n         1.388701          1.635348          1.151402          1.479542 \n analyze problems             upset           puzzled        let happen \n         1.161089          1.678634          1.294472          1.302534 \n         identify         essential feel about people     describe more \n         1.620919          1.231066          1.475410          1.363569 \n         going on         why angry  daily activities     entertainment \n         1.470803          1.496884          1.514226          1.601477 \n  reveal feelings             close            useful   hidden meanings \n         2.097886          1.240008          1.193131          1.045116 \n```\n:::\n\n```{.r .cell-code}\n    apply(alexithymia$Y, 2, var)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    CES-D       RSE \n118.35016  37.24199 \n```\n:::\n\n```{.r .cell-code}\n    # Subset data\n    X_raw <- alexithymia$X\n    y_raw <- alexithymia$Y[, 1, drop = FALSE]\n\n    # Define paramters that can be useful\n    n <- nrow(X_raw)\n    p <- ncol(X_raw)\n\n    # Scale data\n    X <- scale(X_raw)# * (n - 1) / n\n    y <- scale(y_raw)# * (n - 1) / n\n\n    # Define parameters\n    alpha <- .5 # weighting parameter\n    npcs <- 5\n\n# Estimation -------------------------------------------------------------------\n\n    # Estimate with PCovR function\n    out <- PCovR::pcovr_est(\n        X = X,\n        Y = y,\n        a = alpha,\n        r = npcs # fixed number of components\n    )\n\n    # Estimate manually (Vervolet version)\n    Hx <- X %*% solve(t(X) %*% X) %*% t(X)\n    G_vv <- alpha * X %*% t(X) / sum(X^2) + (1 - alpha) * Hx %*% y %*% t(y) %*% Hx / sum(y^2)\n    EG_vv <- eigen(G_vv) # eigen-decomposition of matrix\n    T_vv <- EG_vv$vectors[, 1:npcs]\n\n# Compare results --------------------------------------------------------------\n\n    # T scores\n    Ts <- list(\n        PCovR = head(out$Te),\n        PCovR_man = head(X %*% out$W),\n        Vervolet = head(T_vv)\n    )\n\n    # Weights\n    W <- list(\n        PCovR = out$W,\n        Vervolet = solve(t(X) %*% X) %*% t(X) %*% T_vv\n    )\n\n    # Px\n    ( t(out$Te) %*% X )[, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       confused right words sensations   describe analyze problems\n[1,] -8.4662585  -7.3375812 -2.2012950  6.1597661        0.4271093\n[2,]  3.3642487  -2.5380829 -0.2684529  4.9595077        6.2443158\n[3,] -1.4118650  -4.4348404  1.4484525  1.8944371       -3.1435113\n[4,]  1.1136577   1.0030862  2.0443923 -3.5188316        0.5622115\n[5,]  0.8172586   0.7913444  5.2341517  0.5130866       -5.2948505\n```\n:::\n\n```{.r .cell-code}\n    ( t(out$W) %*% t(X) %*% X )[, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       confused right words sensations   describe analyze problems\n[1,] -8.4662585  -7.3375812 -2.2012950  6.1597661        0.4271093\n[2,]  3.3642487  -2.5380829 -0.2684529  4.9595077        6.2443158\n[3,] -1.4118650  -4.4348404  1.4484525  1.8944371       -3.1435113\n[4,]  1.1136577   1.0030862  2.0443923 -3.5188316        0.5622115\n[5,]  0.8172586   0.7913444  5.2341517  0.5130866       -5.2948505\n```\n:::\n\n```{.r .cell-code}\n    out$Px[, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       confused right words sensations   describe analyze problems\n[1,] -8.4662585  -7.3375812 -2.2012950  6.1597661        0.4271093\n[2,]  3.3642487  -2.5380829 -0.2684529  4.9595077        6.2443158\n[3,] -1.4118650  -4.4348404  1.4484525  1.8944371       -3.1435113\n[4,]  1.1136577   1.0030862  2.0443923 -3.5188316        0.5622115\n[5,]  0.8172586   0.7913444  5.2341517  0.5130866       -5.2948505\n```\n:::\n\n```{.r .cell-code}\n    # Py\n    cbind(\n        Py = out$Py,\n        TtY = t(out$Te) %*% y,\n        WtXtY = t(out$W) %*% t(X) %*% y\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          CES-D      CES-D      CES-D\n[1,] -6.9315017 -6.9315017 -6.9315017\n[2,]  0.7212995  0.7212995  0.7212995\n[3,]  1.1114400  1.1114400  1.1114400\n[4,] -0.2349069 -0.2349069 -0.2349069\n[5,] -0.5126823 -0.5126823 -0.5126823\n```\n:::\n\n```{.r .cell-code}\n    # B\n    cbind(\n        B = drop(out$B),\n        WPY = drop(out$W %*% out$Py),\n        WWtXtY = drop(out$W %*% t(out$W) %*% t(X) %*% y)\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 B          WPY       WWtXtY\n [1,]  0.383110912  0.383110912  0.383110912\n [2,]  0.019216602  0.019216602  0.019216602\n [3,] -0.032288901 -0.032288901 -0.032288901\n [4,] -0.016670641 -0.016670641 -0.016670641\n [5,]  0.086442108  0.086442108  0.086442108\n [6,] -0.185643598 -0.185643598 -0.185643598\n [7,]  0.145228530  0.145228530  0.145228530\n [8,] -0.016889454 -0.016889454 -0.016889454\n [9,]  0.019540943  0.019540943  0.019540943\n[10,] -0.129790008 -0.129790008 -0.129790008\n[11,]  0.011837598  0.011837598  0.011837598\n[12,] -0.060783224 -0.060783224 -0.060783224\n[13,]  0.214728328  0.214728328  0.214728328\n[14,]  0.182671533  0.182671533  0.182671533\n[15,]  0.044201180  0.044201180  0.044201180\n[16,] -0.002997744 -0.002997744 -0.002997744\n[17,]  0.041239398  0.041239398  0.041239398\n[18,]  0.035879278  0.035879278  0.035879278\n[19,] -0.131120013 -0.131120013 -0.131120013\n[20,] -0.049644574 -0.049644574 -0.049644574\n```\n:::\n\n```{.r .cell-code}\n# Maximum likelihood tuning of alpha -------------------------------------------\n\n    # Fit PCovR\n    pcovr_out <- pcovr(\n        X = X_raw,\n        Y = y_raw,\n        rot = \"none\",\n        R = npcs, # fixed number of components\n        modsel = \"seq\" # fastest option\n    )\n\n    # Compute error ratio with function\n    err <- ErrorRatio(\n        X = X,\n        Y = y,\n        Rmin = npcs,\n        Rmax = npcs\n    )\n\n    # Compute error ratio components\n    lm_mod <- lm(y ~ -1 + X)\n    ery <- 1 - summary(lm_mod)$r.squared\n\n    Rmin <- npcs\n    Rmax <- npcs\n    sing <- svd(X)\n    vec <- Rmin:Rmax\n    vec <- c(vec[1] - 1, vec, vec[length(vec)] + 1)\n    VAF <- c(0, cumsum(sing$d^2) / sum(sing$d^2))\n    VAF <- VAF[vec + 1]\n    scr <- array(NA, c(1, length(vec)))\n    for (u in 2:(length(vec) - 1)) {\n        scr[, u] <- (VAF[u] - VAF[u - 1]) / (VAF[u + 1] - VAF[u])\n    }\n    erx <- 1 - VAF[which.max(scr)]\n\n    # Find alpha ML\n    alpha_ML <- sum(X^2) / (sum(X^2) + sum(y^2) * erx / ery)\n\n    # Compare to one found by package\n    pcovr_out$a - alpha_ML\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n# TL;DR, just give me the code!\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up environment -----------------------------------------------------------\n\n    # Load pacakge that implements this method\n    library(\"PCovR\", verbose = FALSE, quietly = TRUE)\n\n    # Load example data from PCovR package\n    data(alexithymia)\n\n    # Explore its scale\n    colMeans(alexithymia$X)\n    colMeans(alexithymia$Y)\n\n    apply(alexithymia$X, 2, var)\n    apply(alexithymia$Y, 2, var)\n\n    # Subset data\n    X_raw <- alexithymia$X\n    y_raw <- alexithymia$Y[, 1, drop = FALSE]\n\n    # Define paramters that can be useful\n    n <- nrow(X_raw)\n    p <- ncol(X_raw)\n\n    # Scale data\n    X <- scale(X_raw)# * (n - 1) / n\n    y <- scale(y_raw)# * (n - 1) / n\n\n    # Define parameters\n    alpha <- .5 # weighting parameter\n    npcs <- 5\n\n# Estimation -------------------------------------------------------------------\n\n    # Estimate with PCovR function\n    out <- PCovR::pcovr_est(\n        X = X,\n        Y = y,\n        a = alpha,\n        r = npcs # fixed number of components\n    )\n\n    # Estimate manually (Vervolet version)\n    Hx <- X %*% solve(t(X) %*% X) %*% t(X)\n    G_vv <- alpha * X %*% t(X) / sum(X^2) + (1 - alpha) * Hx %*% y %*% t(y) %*% Hx / sum(y^2)\n    EG_vv <- eigen(G_vv) # eigen-decomposition of matrix\n    T_vv <- EG_vv$vectors[, 1:npcs]\n\n# Compare results --------------------------------------------------------------\n\n    # T scores\n    Ts <- list(\n        PCovR = head(out$Te),\n        PCovR_man = head(X %*% out$W),\n        Vervolet = head(T_vv)\n    )\n\n    # Weights\n    W <- list(\n        PCovR = out$W,\n        Vervolet = solve(t(X) %*% X) %*% t(X) %*% T_vv\n    )\n\n    # Px\n    ( t(out$Te) %*% X )[, 1:5]\n    ( t(out$W) %*% t(X) %*% X )[, 1:5]\n    out$Px[, 1:5]\n\n    # Py\n    cbind(\n        Py = out$Py,\n        TtY = t(out$Te) %*% y,\n        WtXtY = t(out$W) %*% t(X) %*% y\n    )\n\n    # B\n    cbind(\n        B = drop(out$B),\n        WPY = drop(out$W %*% out$Py),\n        WWtXtY = drop(out$W %*% t(out$W) %*% t(X) %*% y)\n    )\n\n# Maximum likelihood tuning of alpha -------------------------------------------\n\n    # Fit PCovR\n    pcovr_out <- pcovr(\n        X = X_raw,\n        Y = y_raw,\n        rot = \"none\",\n        R = npcs, # fixed number of components\n        modsel = \"seq\" # fastest option\n    )\n\n    # Compute error ratio with function\n    err <- ErrorRatio(\n        X = X,\n        Y = y,\n        Rmin = npcs,\n        Rmax = npcs\n    )\n\n    # Compute error ratio components\n    lm_mod <- lm(y ~ -1 + X)\n    ery <- 1 - summary(lm_mod)$r.squared\n\n    Rmin <- npcs\n    Rmax <- npcs\n    sing <- svd(X)\n    vec <- Rmin:Rmax\n    vec <- c(vec[1] - 1, vec, vec[length(vec)] + 1)\n    VAF <- c(0, cumsum(sing$d^2) / sum(sing$d^2))\n    VAF <- VAF[vec + 1]\n    scr <- array(NA, c(1, length(vec)))\n    for (u in 2:(length(vec) - 1)) {\n        scr[, u] <- (VAF[u] - VAF[u - 1]) / (VAF[u + 1] - VAF[u])\n    }\n    erx <- 1 - VAF[which.max(scr)]\n\n    # Find alpha ML\n    alpha_ML <- sum(X^2) / (sum(X^2) + sum(y^2) * erx / ery)\n\n    # Compare to one found by package\n    pcovr_out$a - alpha_ML\n```\n:::\n\n\n# References",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}