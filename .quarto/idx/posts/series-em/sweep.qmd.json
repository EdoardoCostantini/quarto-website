{"title":"The sweep operator","markdown":{"yaml":{"title":"The sweep operator","author":"Edoardo Costantini","date":"2021-11-17","slug":"sweep","categories":["The EM algorithm","Matrix algebra","Statistics"],"bibliography":"../../resources/bibshelf.bib","format":{"html":{"code-tools":true}}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nThe sweep operator is a matrix transformation commonly used to estimate regression models.\nIt performs elementary row operations on a $p \\times p$ matrix which happens to be particularly useful to estimate multivariate linear models.\nLittle and Rubin [-@littleRubin:2002 p148] defined it as follows:\n\n> The sweep operator is defined for symmetric matrices as follows. A $p \\times p$ symmetric matrix G is said to be swept on row and column k if it is replaced by another symmetric $p \\times p$ matrix H with elements defined as follows:\n> $$\n> h_{kk} = -1/g_{kk}\n> $$\n> $$\n> h_{jk} = h_{kj} = \\frac{g_{jk}}{g_{kk}}, j \\neq k\n> $$\n> $$\n> h_{jl} = g_{jl} - \\frac{g_{jk}g_{kl}}{g_{kk}}, j \\neq k, l \\neq k\n> $$\n\nThe notation indicating this transformation is usually a variation of $\\text{SWEEP}[k]G$, which can be read as sweeping matrix $G$ on column (and row) $k$.\nIt is important to know that:\n\n- Any symmetric matrix $G$ can be swept over $l$ multiple positions.\nThe notation $\\text{SWEEP}[k_1, k_2, ..., k_l]G$ indicates successive applications of $\\text{SWEEP}[k]G$ with $k = k_1, \\dots, k_l$.\n- The sweep operator is commutative.\nSweeps on multiple positions do not need to be carried out in any particular order:\n\n$$\n\\text{SWEEP}[k_2]\\text{SWEEP}[k_1]G = \\text{SWEEP}[k_1]\\text{SWEEP}[k_2]G\n$$\n\n- The $l$ sweeping positions do not need to be consecutive.\nFor example, $k_1$ could indicate the third column and $k_2$ could indicate the sixth column.\n\nIn this post, I want to show how the sweep operator can be used to estimate the parameters of any linear regressions model.\nIf you are interested in the mathematical details, I recommend reading the full sweep operator description in Goodnight [-@goodnight:1979 p154], Schafer [-@schafer:1997], or Little and Rubin [-@littleRubin:2002 p148].\n\nGoodnight [-@goodnight:1979 p150] is a particularly helpful paper as it describes an easy implementation of the sweep operator.\nFollowing Goodnight, given an originally symmetric positive definite matrix G, $\\text{SWEEP}[k]G$ modifies a matrix G as follows:\n\n- Step 1: Let $D = g_{kk}$\n- Step 2: Divide row $k$ by $D$.\n- Step 3: For every other row $i \\neq k$, let $B = g_{ik}$. Subtract $B \\times \\text{row } k$ from row $i$. Set $g_{ik} = -B/D$.\n- Step 4: Set $g_{kk} = 1/D$.\n\n# Learn by coding\n\n## Coding a sweep function in R\n\nLet's start by coding a simple function that performs the operations described by Goodnight [-@goodnight:1979 p150].\nWe want a function that takes as inputs a symmetric matrix (argument `G`) and a vector of positions to sweep over (argument `K`).\nThe function below takes these two inputs and performs the four sweep steps for every element of `K`.\n\n```{r sweep function}\n# Write an R function implementing SWEEP(k)[G] according to Goodnight ----------\n\nsweepGoodnight <- function (G, K){\n\n  for(k in K){\n    # Step 1: Let D = g_kk\n    D <- G[k, k]\n\n    # Step 2: Divide row k by D.\n    G[k, ] <- G[k, ] / D\n\n    # Step 3:\n    # - For every other row i != k, let B = g_ik\n    # - Subtract B \\times row k from row i.\n    # - set g_ik = -B/D.\n    for(i in 1:nrow(G)){\n      if(i != k){\n        B <- G[i, k]\n        G[i, ] <- G[i, ] - B * G[k, ]\n        G[i, k] <- -1 * B / D\n      }\n    }\n    # Step 4: Set g_kk = 1/D\n    G[k, k] = 1/D\n  }\n\n  # Output\n  return(G)\n}\n\n```\n\nLet's check that this function returns what we want by comparing it with a function implemented by someone else.\n\n```{r compare sweeps, warning = FALSE}\n# Compare sweepGoodnight with other implementations ----------------------------\n\n# Install the `fastmatrix` package (run if you don't have it yet)\n# install.packages(\"fastmatrix\")\n\n# Load fastmatrix\nlibrary(fastmatrix)\n\n# Define an example dataset\nX <- matrix(c(1, 1, 1, 1,\n              1, 2, 1, 3,\n              1, 3, 1, 3,\n              1, 1,-1, 2,\n              1, 2,-1, 2,\n              1, 3,-1, 1), ncol = 4, byrow = TRUE)\n\n# Define the G matrix\nG <- crossprod(X)\n\n# Define a vector of positions to sweep over\nK <- 1:3\n\n# Perform SWEEP[K]G with fastmatrix sweep.operator\nH_fm <- sweep.operator(G, k = K)\n\n# Perform SWEEP[K]G with our sweepGoodnight implementation\nH_sg <- sweepGoodnight(G, K = K)\n\n# Compare the two\nall.equal(H_fm, H_sg)\n\n```\n\nThe functions `fastmatrix::sweep.operator()` and `sweepGoodnight()` return the same `H` matrix by sweeping matrix `G` over the positions defined in `K`.\n\n## Using the sweep operator to estimate regression models\n\nTo understand how the sweep operator relates to the estimation of multivariate linear models, we will work with a data set used by Little and Rubin [-@littleRubin:2002 p152].\n\n```{r load data}\n# Load Little Rubin data -------------------------------------------------------\n\n# Create data\n  X <- as.data.frame(\n          matrix(\n                  data = c(7, 1, 11, 11, 7, 11, 3, 1, 2, 21, 1, 11, 10, 26,\n                           29, 56, 31, 52, 55, 71 ,31, 54, 47, 40, 66, 68,\n                           6, 15, 8, 8, 6, 9, 17, 22, 18, 4, 23, 9, 8,\n                           60, 52, 20, 47, 33, 22,6,44,22,26,34,12,12,\n                           78.5, 74.3, 104.3, 87.6, 95.9, 109.2, 102.7,\n                           72.5, 93.1, 115.9, 83.8, 113.3, 109.4),\n                  ncol = 5\n          )\n  )\n\n# Store useful information\n  n <- nrow(X)\n  p <- ncol(X)\n\n```\n\nLet's take a quick look at the first rows of the data to get an idea of what we are working with.\n\n```{r check X}\n# Glance at the first 6 rows of the data\n  head(X)\n\n```\n\n### Compute the augmented covariance matrix\n\nTo obtain the estimates of the regression coefficients of a multivariate linear model, we need to sweep the augmented covariance matrix of the data ($\\Theta$) over the positions of the predictors.\nThis is a $(p+1) \\times (p+1)$ matrix storing the covariance matrix and the means of the dataset.\nIt usually looks like this:\n\n$$\n\\Theta =\n\\begin{bmatrix}\n1 & \\mu_1 & ... &\\mu_p\\\\\n\\mu_1 & \\sigma^2_1 & ... & \\sigma_{1p}\\\\\n... & ... & ... & ...\\\\\n\\mu_p & \\sigma_{1p} & ... & \\sigma^2_{p}\n\\end{bmatrix}\n$$\n\nwith $\\mu_1, \\dots, \\mu_p$, $\\sigma^2_1, \\dots, \\sigma^2_p$, and $\\sigma_{jk}$ being the means, variances, and covariances of the variables in our dataset, respectively.\n\nIn R, we can obtain this matrix in just a few steps starting from our dataset `X`:\n\n- **Augment the original data** with a column of 1s on the left.\n\n  We can use the `cbind()` function to append a column of 1s to the left of X.\n  Keep in mind that we need to perform matrix operations with the resulting object.\n  Therefore, we need to make sure we are working with an R object of the class `matrix` instead of `data.frame`.\n\n  ```{r augment X}\n  # Obtain the augmented covariance matrix ---------------------------------------\n\n  # Augment X\n    X_aug <- cbind(int = 1, as.matrix(X))\n\n  # Glance at the first 6 rows of X_aug\n    head(X_aug)\n\n  ```\n\n- Compute the **augmented matrix of [sufficient statistics](https://en.wikipedia.org/wiki/Sufficient_statistic) $T$**.\n\n  $T$ is the matrix having as elements the sum of the cross-products of the columns of `X_aug`.\n\n  $$\n  T =\n  \\begin{bmatrix}\n  n & \\sum{x_1} & ... & \\sum{x_p}\\\\\n  \\sum{x_1} & \\sum{x_1^2} & ... & \\sum{x_1 x_p}\\\\\n  ... & ... & ... & ...\\\\\n  \\sum{x_p} & \\sum{x_1 x_p} & ... & \\sum{x_p^2}\n  \\end{bmatrix}\n  $$\n\n  Since the first column of `X_aug` is a column of 1s, the first element of T is the number of rows in the data, the first column and rows store the sum of scores on each variable (sufficient statistics for the mean), and the other elements store the sum of products between the columns of `X` (sufficient statistics for the covariance matrix of `X`).\n\n  In R, we can compute it easily with the cross-product function:\n\n  ```{r compute T}\n  # Compute the matrix of sufficient statistics (T matrix)\n    Tmat <- crossprod(X_aug)\n\n  ```\n\n- **Transform T to G**\n\n  $G$ is simply $T / n$\n\n  $$\n  G =\n  \\begin{bmatrix}\n   1 & \\mu_1 & ... &\\mu_p\\\\\n   \\mu_1 & \\frac{\\sum{x_1^2}}{n} & ... & \\frac{\\sum{x_1 x_p}}{n}\\\\\n   ... & ... & ... & ...\\\\\n   \\mu_p & \\frac{\\sum{x_1 x_p}}{n} & ... & \\frac{\\sum{x_p^2}}{n}\n  \\end{bmatrix}\n  $$\n\n  ```{r compute G}\n  # Compute G\n    G <- Tmat / n\n\n  ```\n\n- **Compute $\\Theta$** by sweeping G over the first row and column.\n\n  Let's use our `sweepGoodnight()` function to perform SWEEP[1]G and obtain $\\Theta$\n\n  $$\n  \\Theta =\n  \\begin{bmatrix}\n  1 & \\mu_1 & ... &\\mu_p\\\\\n  \\mu_1 & \\sigma^2_1 & ... & \\sigma_{1p}\\\\\n  ... & ... & ... & ...\\\\\n  \\mu_p & \\sigma_{1p} & ... & \\sigma^2_{p}\n  \\end{bmatrix}\n  $$\n\n  In R:\n  ```{r compute Theta}\n  # Sweep G over the first position\n    Theta <- sweepGoodnight(G, 1)\n\n  # Check how it looks\n    Theta\n\n  # Check Theta is storing the means in the first row and column\n    colMeans(X)\n\n  # Check Theta is storing the ML covariance matrix everywhere else\n    cov(X) * (n-1) / n\n\n  ```\n\n  Pay attention to a couple of things:\n  - The covariance matrix stored in $\\Theta$ is the Maximum Likelihood version (denominator should be `n` instead of the default `n-1`)\n  - We could have constructed the object `Theta` just by using `colMeans(X)` and `cov(X) * (n-1) / n` directly.\n    However, it is important to note the relationship between `Tmat`, `G`, and `Theta`.\n    In particular, pay attention to the fact that `Theta` is the result of sweeping `G` in the first position.\n    When I started looking into this topic I did not understand this, and I kept sweeping `Theta` over the first position, resulting in a confusing double sweeping of the first column and row.\n    I will get back to this point in a sec.\n\n### Estimate multivariate linear models\n\nNow let's see how we can use $\\Theta$ to estimate any multivariate linear model involving the variables in our dataset.\nFirst, let's see how we would obtain these linear models in R with standard procedures.\nSay we want to regress V1 and V3 on V2, V4, and V5 from the `X` dataset.\nWe will start by creating a formula for an `lm` function to estimate the model we want.\n\n```{r mlm definition}\n# Fit some multivariate linear models ------------------------------------------\n\n  # Define the dependent variables (dvs) of the multivairate linear models\n  dvs <- c(\"V1\", \"V3\")\n\n  # Define the predictors (ivs) of the multivairate linear models\n  ivs <- c(\"V2\", \"V4\", \"V5\")\n\n  # Create the formula (complicated but flexible way)\n  formula_mlm <- paste0(\"cbind(\",\n                       paste0(dvs, collapse = \", \"),\n                       \") ~ \",\n                       paste0(ivs, collapse = \" + \"))\n\n  # Check the formula\n  formula_mlm\n\n```\n\n  Next, we will fit the multivariate linear model with the `lm()` function:\n\n```{r mlm estimation}\n  # Fit the model with the lm function\n  mlm0 <- lm(formula_mlm, data = X)\n  coef(mlm0)\n\n```\n\n  These are our intercepts, and regression coefficients for the multivariate linear model.\n  We can sweep $\\Theta$ over the positions of the independent variables to obtain the the same intercept and regression coefficients.\n  First, let's define a vector of positions to sweep over based on the variable names we stored in `ivs`.\n\n```{r define sweep over}\n# Fit some multivariate linear models using sweep ------------------------------\n\n  # Define positions to sweep over\n  sweep_over <- which(colnames(Theta) %in% ivs)\n\n```\n\nThen, let's simply sweep our $\\Theta$ over these positions.\n\n```{r sweep theta}\n  # Sweep theta\n  H <- sweepGoodnight(Theta, K = sweep_over)\n\n  # Check out the result\n  H\n\n```\n\nOur regression coefficients are here in this new matrix.\nWe just need to find them.\nWe know that the dependent variables are V1 and V3, and that the independent variables are V2, V4, and V5.\nLet's index the rows of `H` with the names of the ivs (and the name of the intercept row), and the columns of `H` with the names of the dvs.\n\n```{r index H}\n  # Extract the regression coefficients from H\n  H[c(\"int\", ivs), dvs]\n\n  # Compare with coefficients from lm function\n  coef(mlm0)\n\n```\n\nNote that, we are sweeping $\\Theta$ only over the predictors, but we also get the estimate of the intercept.\nRemember that $\\Theta$ is the result of sweeping G over the first position, which is the position where the intercept estimate appears.\nYou could obtain the same result by directly sweeping G over position 1, and the position of the predictors.\nIn code:\n\n```{r sweeping G as theta}\n  # Sweep G\n  sweepGoodnight(G, c(1, sweep_over))[c(\"int\", ivs), dvs]\n\n```\n\nTherefore, you can think of finding the coefficients of a multivariate linear model using the sweep operator as:\n\n- SWEEP(1, $k_1, \\dots, k_l$)[G] or as,\n- SWEEP($k_1, \\dots, k_l$)[SWEEP(1)[G]] or as,\n- SWEEP($k_1, \\dots, k_l$)[$\\Theta$]\n\nwith $k_1, \\dots, k_l$ being the positions of the $K$ predictors in matrix $G$.\n\nFinally, just play around with what variables you consider as dvs and ivs.\nYou will discover the magic of the sweep operator.\n\n```{r variable roles}\n# Play around with variable roles ------------------------------------------\n\n  # Define different dependent variables (dvs) for the multivairate linear models\n  dvs <- c(\"V1\", \"V2\", \"V5\")\n\n  # Define different predictors (ivs) for the multivairate linear models\n  ivs <- c(\"V3\", \"V4\")\n\n  # Create the formula (complicated but flexible way)\n  formula_mlm <- paste0(\"cbind(\",\n                       paste0(dvs, collapse = \", \"),\n                       \") ~ \",\n                       paste0(ivs, collapse = \" + \"))\n\n  # Fit the model with the MLM\n  mlm1 <- lm(formula_mlm, data = X)\n  coef(mlm1)\n\n  # Define positions to sweep over\n  sweep_over <- which(colnames(Theta) %in% ivs)\n\n  # Sweep Theta over new positions\n  sweepGoodnight(Theta, K = sweep_over)[c(\"int\", ivs), dvs]\n\n```\n\n# TL;DR, just give me the code!\n```{r TLDR, ref.label = knitr::all_labels(), echo=TRUE, eval=FALSE}\n```\n\n# References"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"sweep.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","theme":{"light":["flatly","light.scss"],"dark":["darkly","dark.scss"]},"title-block-banner":true,"title":"The sweep operator","author":"Edoardo Costantini","date":"2021-11-17","slug":"sweep","categories":["The EM algorithm","Matrix algebra","Statistics"],"bibliography":["../../resources/bibshelf.bib"]},"extensions":{"book":{"multiFile":true}}}}}