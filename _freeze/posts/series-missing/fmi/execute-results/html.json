{
  "hash": "01d806cec3497d14e637fd1e5fbe1724",
  "result": {
    "markdown": "---\ndraft: true\ntitle: Fraction of missing information\nauthor: Edoardo Costantini\ndate: '2022-09-20'\nslug: fmi\ncategories: [\"missing values\"]\nbibliography: ../../resources/bibshelf.bib\ntoc-location: left\ncode-tools: true\ntoc-depth: 4\n---\n\n\n# Fraction of missing information\n\nThe **fraction of missing information** (FMI) is a measure used to quantify the impact of missing data on the estimation of a parameter $(Q)$.\n\n> More specifically, it measures the inï¬‚ation in the variance of the parameter estimate relative to what this variance would have been had all the data been observed.\n>\n> @savaleiRhemtulla:2012 [p478]\n\nAs a measure, it is the function of the proportion of missing data, the missing data mechanism, and the imputation procedure. When applying multiple imputation, the FMI is usually estimated as:\n\n$$\n\\lambda = \\frac{B + \\frac{B}{m}}{T}\n$$\n\nwhere:\n\n- $m$ is the number of imputations\n- $B$, or between imputation variation, is the variance of the parameter estimate across the $m$ imputations\n    $$\n    B = \\frac{1}{m - 1} \\sum^{m}_{l=1} (\\hat{Q}_{l} - \\bar{Q}) (\\hat{Q}_{l} - \\bar{Q})'\n    $$\n    where:\n    - $\\hat{Q}_{l}$ is the estimate of the parameter of interest in the $l$-th imputed data\n    - $\\bar{Q} = \\frac{1}{m} \\sum^{m}_{l=1} \\hat{Q}_{l}$\n- $T$ is the total variation around the parameter estimate (as a result of the sum of the within and between imputation variation)\n    $$\n    T = \\bar{U} + B + \\frac{B}{m}\n    $$\n    where:\n    - $\\bar{U}$ is the average of the standard errors of $Q$ ($\\bar{U}_{l}$) computed on the $m$ different datasets.\n    $$\n    \\bar{U} = \\frac{1}{m} \\sum^{m}_{l = 1} \\bar{U}_{l}\n    $$\n\nAs the proportion of variation attributable to the missing data, the FMI can be interpreted as follow:\n\n- $\\lambda = 0$, the missing data do not add extra variation to parameter sampling variance;\n- $\\lambda = 1$, the missing data cause all of the variation in the parameter estimate;\n- $\\lambda > 0.5$, the influence of the imputation model on the final result is larger than that of the complete-data\n\n### Relative increase in variance due to nonresponse\n\nBy replacing the denominator used in the estimation of $\\lambda$ with $\\bar{Q}$ we obtained a similar measure called **relative increase in variance due to nonresponse** ($riv$ or $r$):\n\n$$\nr = \\frac{B + \\frac{B}{m}}{\\bar{Q}}\n$$\n\nThis quantity is related to $\\lambda$ by:\n\n$$\nr = \\frac{\\lambda}{1 - \\lambda}\n$$\n\n### Fraction of information about Q missing due to nonresponse\n\nFinally, a related measure is the **fraction of information about $Q$ missing due to nonresponse**:\n\n$$\n\\gamma = \\frac{r + \\frac{2}{\\nu + 3}}{1+r}\n$$\n\nwhere $\\nu$ refers to the degrees of freedom, or the number of observations after accounting for the number of parameters in the model.\nThis quantity is related to $\\lambda$ by:\n\n$$\n\\gamma = \\frac{\\nu + 1}{\\nu + 3} \\lambda + \\frac{2}{\\nu + 3}\n$$\n\nThe interpretation of $\\gamma$ is the same as $\\lambda$, but adjusted for the finite number of imputations.\n\n## Degrees of freedom\n\nThe computation of the degrees of freedom is not the same as in a complete case analysis. There are actually a few different ways of computing $\\nu$ for the multiple imputation of missing values.\n\n- old formula for degrees of freedom [@rubin:1987, eq. 3.1.6]\n    $$\n    \\nu_{old} = (m -1)(1+ \\frac{1}{r^2}) = \\frac{m-1}{\\lambda^2}\n    $$\n    To think about these measure, consider:\n    - if $\\lambda \\approx 1$, then $\\nu_{old} \\approx m - 1$, which occurs if close to all variation is due to nonresponse\n    - if $\\lambda \\approx 0$, then $\\nu_{old} \\approx \\infty$, which occurs if close to all variation is due to sampling variation\n- observed data degrees of freedom\n    $$\n    \\nu_{obs} = \\frac{\\nu_{com}+1}{\\nu_{com}+3} \\nu_{com}(1-\\lambda)\n    $$\n    where $\\nu_{com} = n - k$, the difference between the sample size and the number of parameters estimated.\n- adjusted degrees of freedom\n    $$\n    \\nu = \\frac{\\nu_{old}\\nu_{obs}}{\\nu_{old} + \\nu_{obs}}\n    $$\n    This is the measure that should be used for statistical testing of estimates after applying multiple imputation. Note the following:\n    - $\\nu \\le \\nu_{com}$  always!\n    - $\\nu = \\nu_{old}$ if $\\nu_{com} = \\infty$\n    - $\\nu = \\nu_{com}$ if $\\lambda = 0$\n    - $\\nu < 1$ you should refrain from testing due to lack of information in the data\n    - $\\nu = 0$ if $\\lambda = 1$\n\n# Learn by coding\n\nLet's generate some fictitious data on which to try out the computations I described above.\n\n## Data generation\n\nFirst, let's load the `mice` package we will use to perform multiple imputations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Environment set up -----------------------------------------------------------\n\n# Load mice package\nlibrary(mice)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mice'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n```\n:::\n:::\n\n\nThen, let's sample three random variables from a multivariate normal distribution and use them to generate a dependent variable $y$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data generation --------------------------------------------------------------\n\n# Set seed\nset.seed(20230308)\n\n# Define data generation model parameters\nn <- 50     # sample size\n\n# Sample X data from a multivariate normal distribution\nX <- MASS::mvrnorm(\n    n = n,\n    mu = rep(0, 3),\n    Sigma = matrix(c(\n        1, .5, 0,\n        .5, 1, 0,\n        0, 0, 1\n    ), nrow = 3)\n)\n\n# Data generation model parameter values\nb0 <- 10    # intercept\nb1 <- 5     # regression coefficients\nb2 <- 5\nb3 <- 0\n\n# Sample Y from DGM\ny <- b0 + b1 * X[, 1] + b2 * X[, 2] + b3 * X[, 3] + rnorm(n)\n\n# Put together in a data frame\ndt <- data.frame(y = y, X = X)\n```\n:::\n\n\nFinally, impose missing values by defining a vector of response probabilities based on the second column of $X$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute the probabilities of nonresponse:\nprobs <- plogis(X[, 2])\n\n# Return a logical nonresponse vector:\nwy <- (as.logical(rbinom(n = n, size = 1, prob = probs)))\n\n# Impose missingness\ndt$y[wy] <- NA\n```\n:::\n\n\nWe can now impute the data with the mice algorithm as implemented in the `mice()` R function. Let's obtain 20 imputations ($m = 20$). Every other argument is left to its default value as their specification is not particularly relevant for this demonstration.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Number of imputations (final data sets)\nm <- 20\n\n# Impute with Bayesian imputation (norm)\nimp <- mice(dt, m = m, print = FALSE)\n\n# Fit a model to the multiple imputations\nfit.imp <- with(imp, lm(y ~ X.1 + X.2 + X.3))\n\n# Pool statistics\npool.imp <- pool(fit.imp)\n```\n:::\n\n\n## FMI and variance ratios\n\nTo begin with, we need to compute the pooled estimates and measures of variability we need in the formulas of $\\lambda$ and $r$.\n\n### Estiamtes and variances\n\n#### $\\bar{Q}_l$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute manually ------------------------------------------------------------\n# Notes: page and equation numbers refer to van Buuren 2018\n\n# Extract the statistic of interest from every imputed data set\nQ_bar_l <- sapply(\n    fit.imp$analyses,\n    function(x) {\n        coef(x)[\"X.1\"]\n    }\n)\n```\n:::\n\n\n#### $\\bar{Q}$\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Compute Q_bar (p. 42, eq. 2.16) --------------------------------------------\n\n# Obtain the pooled parameter\nQ_bar <- mean(Q_bar_l)\n```\n:::\n\n\n#### $\\bar{U}_{l}$ and $\\bar{U}$\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Compute U_bar (p. 43, eq. 2.18) -------------------------------------------\n\n# Extract vector of standard errors\nU_bar_l <- sapply(\n    fit.imp$analyses,\n    function(x) {\n        (coef(summary(x))[\"X.1\", \"Std. Error\"])^2\n    }\n)\n\n# Obtain the pooled parameter\nU_bar <- mean(U_bar_l)\n```\n:::\n\n\n#### $B$\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Compute B (p. 43, eq. 2.19) -----------------------------------------------\n\nB <- sum((Q_bar_l - Q_bar)^2) / (m - 1)\n```\n:::\n\n\n#### $T$\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Compute T (p. 43, eq. 2.20) -----------------------------------------------\n\nT <- U_bar + B + B/m\n```\n:::\n\n\n### Variance ratios\n\nWe can now compute all of the variance ratios discussed.\nThe proportion of variation attributable to the missing data ($\\lambda$) can be computed with the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Lambda (p. 46, eq. 2.24) --------------------------------------------------\n\nlambda <- (B + B/m) / T\n```\n:::\n\n\nNote that, for infinite imputations $m \\rightarrow \\infty$, $\\lambda$ is equal to the ratio $B / T$, which is the proportion of the total parameter estimate variance that is attributable to between imputation variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Conceptual lambda\nB / T\n```\n:::\n\n\nThe computation of $r$ is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Relative increase in variance due to nonresponse (p. 47, eq. 2.25) --------\n\nr <- (B + B / m) / U_bar\n```\n:::\n\n\nand note again the conceptual meaning:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Conceptual meaning\nB / U_bar\n```\n:::\n\n\nand the relationship between $r$ and $\\lambda$ is as described\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# r relation to lambda\nr == lambda / (1-lambda)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nLet's now focus on the degrees of freedom.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Degrees of freedom (old) --------------------------------------------------\n#   Interpretation: number of observations after accounting for the number of \n#                   parameters in the model.\n\n    nu_old <- (m - 1) * (1 + 1 / r^2)\n    nu_old <- (m - 1) / lambda^2\n\n# > Degrees of freedom (com) --------------------------------------------------\n#   Interpretation: degrees of freedom of Q_bar in the hypothetically complete\n#                   data\n\n    # number of parameters\n    k <- 1 + 3\n\n    # Compute degrees of freedom\n    nu_com <- n - k\n\n# > Degrees of freedom (obs) --------------------------------------------------\n#   Interpretation: estimated observed data degrees of freedom accounting for \n#                   missing information\n\n    nu_obs <- (nu_com + 1) / (nu_com + 3) * nu_com * (1 - lambda)\n\n# > Degrees of freedom (adjusted) ---------------------------------------------\n#   Interpretation: adjusted degrees of freedom to be used for testing in\n#                   multiple imputation\n\n    nu <- nu_old * nu_obs / (nu_old + nu_obs)\n```\n:::\n\n\nWith all of the degrees of freedom computed, we can now calculate the Fraction of information missing due to nonresponse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# > Fraction of information missing due to nonresponse (p. 47, eq. 2.26) ------\n#   Interpretation: proportion of variation attributable to the missing data\n#                   -> ADJUSTED for the finite number of imputations\n\n    gamma <- (r + 2/(nu + 3)) / (1 + r)\n\n    # Relation to lambda\n    # 1. Interpretation: same + ADJUSTED for a finite number of imputations\n    # 2. Computation:\n    c(\n        gamma,\n        (nu + 1) / (nu + 3) * lambda + 2 / (nu + 3)\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2804727 0.2804727\n```\n:::\n\n```{.r .cell-code}\n    # 3. Use in the literature: used interchangeably, but only for large nu \n    #                           they are the same.\n\n# > Compare with mice ---------------------------------------------------------\n\n    # Results for B1\n    manual <- c(\n        Q_bar = Q_bar, U_bar = U_bar, B = B, T = T,\n        nu_com = nu_com, nu = nu,\n        r = r, lambda = lambda, gamma = gamma\n    )\n\n    # Mice results\n    mice_comp <- pool.imp$pooled[2, -(1:2)]\n\n    # Put together\n    rbind(manual = manual, mice_comp = mice_comp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          estimate     ubar          b         t dfcom      df       riv\nmanual    4.109899 0.223339 0.06538424 0.2919924    46 30.7308 0.3073958\nmice_comp 4.109899 0.223339 0.06538424 0.2919924    46 30.7308 0.3073958\n             lambda       fmi\nmanual    0.2351207 0.2804727\nmice_comp 0.2351207 0.2804727\n```\n:::\n:::\n\n\n\n# TL;DR, just give me the code!\n\n::: {.cell}\n\n```{.r .cell-code}\n# Environment set up -----------------------------------------------------------\n\n# Load mice package\nlibrary(mice)\n\n# Data generation --------------------------------------------------------------\n\n# Set seed\nset.seed(20230308)\n\n# Define data generation model parameters\nn <- 50     # sample size\n\n# Sample X data from a multivariate normal distribution\nX <- MASS::mvrnorm(\n    n = n,\n    mu = rep(0, 3),\n    Sigma = matrix(c(\n        1, .5, 0,\n        .5, 1, 0,\n        0, 0, 1\n    ), nrow = 3)\n)\n\n# Data generation model parameter values\nb0 <- 10    # intercept\nb1 <- 5     # regression coefficients\nb2 <- 5\nb3 <- 0\n\n# Sample Y from DGM\ny <- b0 + b1 * X[, 1] + b2 * X[, 2] + b3 * X[, 3] + rnorm(n)\n\n# Put together in a data frame\ndt <- data.frame(y = y, X = X)\n\n# Compute the probabilities of nonresponse:\nprobs <- plogis(X[, 2])\n\n# Return a logical nonresponse vector:\nwy <- (as.logical(rbinom(n = n, size = 1, prob = probs)))\n\n# Impose missingness\ndt$y[wy] <- NA\n# Number of imputations (final data sets)\nm <- 20\n\n# Impute with Bayesian imputation (norm)\nimp <- mice(dt, m = m, print = FALSE)\n\n# Fit a model to the multiple imputations\nfit.imp <- with(imp, lm(y ~ X.1 + X.2 + X.3))\n\n# Pool statistics\npool.imp <- pool(fit.imp)\n\n# Compute manually ------------------------------------------------------------\n# Notes: page and equation numbers refer to van Buuren 2018\n\n# Extract the statistic of interest from every imputed data set\nQ_bar_l <- sapply(\n    fit.imp$analyses,\n    function(x) {\n        coef(x)[\"X.1\"]\n    }\n)\n\n# > Compute Q_bar (p. 42, eq. 2.16) --------------------------------------------\n\n# Obtain the pooled parameter\nQ_bar <- mean(Q_bar_l)\n\n# > Compute U_bar (p. 43, eq. 2.18) -------------------------------------------\n\n# Extract vector of standard errors\nU_bar_l <- sapply(\n    fit.imp$analyses,\n    function(x) {\n        (coef(summary(x))[\"X.1\", \"Std. Error\"])^2\n    }\n)\n\n# Obtain the pooled parameter\nU_bar <- mean(U_bar_l)\n\n# > Compute B (p. 43, eq. 2.19) -----------------------------------------------\n\nB <- sum((Q_bar_l - Q_bar)^2) / (m - 1)\n\n# > Compute T (p. 43, eq. 2.20) -----------------------------------------------\n\nT <- U_bar + B + B/m\n\n# > Lambda (p. 46, eq. 2.24) --------------------------------------------------\n\nlambda <- (B + B/m) / T\n\n# Conceptual lambda\nB / T\n\n# > Relative increase in variance due to nonresponse (p. 47, eq. 2.25) --------\n\nr <- (B + B / m) / U_bar\n\n# Conceptual meaning\nB / U_bar\n\n# r relation to lambda\nr == lambda / (1-lambda)\n\n# > Degrees of freedom (old) --------------------------------------------------\n#   Interpretation: number of observations after accounting for the number of \n#                   parameters in the model.\n\n    nu_old <- (m - 1) * (1 + 1 / r^2)\n    nu_old <- (m - 1) / lambda^2\n\n# > Degrees of freedom (com) --------------------------------------------------\n#   Interpretation: degrees of freedom of Q_bar in the hypothetically complete\n#                   data\n\n    # number of parameters\n    k <- 1 + 3\n\n    # Compute degrees of freedom\n    nu_com <- n - k\n\n# > Degrees of freedom (obs) --------------------------------------------------\n#   Interpretation: estimated observed data degrees of freedom accounting for \n#                   missing information\n\n    nu_obs <- (nu_com + 1) / (nu_com + 3) * nu_com * (1 - lambda)\n\n# > Degrees of freedom (adjusted) ---------------------------------------------\n#   Interpretation: adjusted degrees of freedom to be used for testing in\n#                   multiple imputation\n\n    nu <- nu_old * nu_obs / (nu_old + nu_obs)\n# > Fraction of information missing due to nonresponse (p. 47, eq. 2.26) ------\n#   Interpretation: proportion of variation attributable to the missing data\n#                   -> ADJUSTED for the finite number of imputations\n\n    gamma <- (r + 2/(nu + 3)) / (1 + r)\n\n    # Relation to lambda\n    # 1. Interpretation: same + ADJUSTED for a finite number of imputations\n    # 2. Computation:\n    c(\n        gamma,\n        (nu + 1) / (nu + 3) * lambda + 2 / (nu + 3)\n    )\n    # 3. Use in the literature: used interchangeably, but only for large nu \n    #                           they are the same.\n\n# > Compare with mice ---------------------------------------------------------\n\n    # Results for B1\n    manual <- c(\n        Q_bar = Q_bar, U_bar = U_bar, B = B, T = T,\n        nu_com = nu_com, nu = nu,\n        r = r, lambda = lambda, gamma = gamma\n    )\n\n    # Mice results\n    mice_comp <- pool.imp$pooled[2, -(1:2)]\n\n    # Put together\n    rbind(manual = manual, mice_comp = mice_comp)\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}